========
01:overview
--------
Overview and Methods
--------
Read sections 1.1--1.3, also review Appendix
--------
% Physics defined

What is physics? It's actually a hard thing to define. Physics is the science of change. Physics is the study of motion. Physics is the study of matter and energy. What are things made of? What is the root cause of things? Physics is a natural science distinct from chemistry, astronomy and geology. Physics informs the other sciences: chemistry, astronomy, geology, biology, etc. Physics is the most mathematically ``pure'' natural science. 

Like any science it is a combination of deductive and inductive elements. Deduction works from evident principles to particular predictions. An example is Newton's laws of motion. Start with three laws and deduce the future motion of a particular situation. Deduction builds a hierarchy of laws and theorems each applicable to various branches of the science. So, hydrodynamics is a special case of Newton's laws applied to fluids.

Induction works the other way. From particular examples we tease out a pattern from the results. This almost always takes the form that when $x$ changes so does $y$. If both are quantified, this relationship is summarized by the function $y = f(x)$. If the driver variable $x$ occurs in a small range\footnote{How small? Small enough to make this statement true.}, this function can be written as $y = kx$. The value of $k$ is called a \jargon{proportionality constant}. Frequently the first inductive step is to identify the $x$ and $y$ and use the data to calculate $k$.

Sometimes these processes are divided into a kind of division of labor: theorists work on the deductive side, experimentalist work on the inductive side. Of course, the truth of the matter is not so cleanly divided. But \prep{roughly we can say that the experimentalists \hide{measure} the values of $k$ and the theorists try to derive the value of $k$ from first principles. The extent to which these two groups agree represents the success of the science.} 

The purpose of many of the labs in this class is to perform just this comparison. It is the nature of induction that no one single experience can prove anything.\footnote{But a single experiment can falsify it. This insight is often attributed to \href{http://en.wikipedia.org/wiki/Falsifiability}{Karl Popper}. However, not just any experiment will do. You will often find in lab that your experiments do not match the textbook theory. This is always a result of your lack of skill as an experimentalist. Sorry to be so blunt---one of the purposes of these labs is to develop these skills in you. Sometimes you'll just run out of time in a particular lab to get it right.} The only thing we can do is to build a preponderance of evidence. We run the experiment again and again, controlling as many variables as we can to isolate the $x$ and $y$ in which we are interested. If the data lines up, we are happy. But, of course, the data never does. In fact, each experiment itself is subject to some sort of unavoidable measurement error, so there really is no ``line''. It is the role of statistics to tease out the pattern in the data and estimate the size of the errors in this analysis.

% On measurement

So far, we have been describing the basic scientific method for any science. When we talk about physics, we focus on measuring simple things. Truly, this is the reason why physics is so ``pure'' and successful. We only focus on the very simplest of systems. No complications of living things, no historical accidents and lacuna to deal with, perfect repeatability. Physics has all of these advantages.\footnote{So does chemistry. In fact, these two sciences are a bit like twin brothers in the natural sciences. A lot of the topics overlap (thermodynamics, atomic theory)---there is even a kind of sibling rivalry between the two.}

Given this self-imposed restriction, it's not too surprising that physics is so accurate. What is surprising is the scope to which this accuracy extends. Today, this accuracy extends to all known physical experiments. In other words, there is no known experiment that cannot be explained by the current theories. There are areas for improvement, but the theories are predictive in \emph{every case} up to experimentally measured limits. Einstein once said,
\begin{quote}
The most incomprehensible thing about the world is that it is at all comprehensible.
\end{quote}
When you step back and think about it, this science is unreasonably accurate. Why is the universe rational at all? Go ahead and wrap your head around that question!

Now, when we talk about our $x$ and $y$, realize that \prep{ultimately every measurement (in physics) is either a measurement of \hide{distance or time}.} Whether it is the measurement of how far an object falls, or how far a needle moves on some meter, it is a distance. The measurement of time usually involves the comparison to some cycle: the earth around the sun, the vibration of quartz, etc.

% Class overview: high-level first

Characterizing physics as the study of matter and energy summarizes two fundamental questions:
\begin{items}
\item What are things made of?
\item Why does they do what they do?
\end{items}
The short answer is that everything is made of elementary particles (quarks and leptons) subject to four fundamental interactions (electromagnetism, gravity, and two nuclear forces). These interactions cause these particles to combine in certain ways (nuclei, atoms, molecules) and those combinations in turn interact in secondary ways subject to the science of mechanics. On a small scale we use quantum mechanics, when things get very fast or energetic we use relativity, otherwise we can use classical mechanics summarized in Newton's three laws of motion.

\prep{One of the amazing things about physics is the reduction of a huge variety of phenomena to the simple \hide{laws of mechanics}.} This story line is roughly aligned with the year-long structure of this class.
\begin{desc}
\item[Physics 201] \hfill \\ The study of idealized systems. Basic applications of Newton's laws of motion.
\item[Physics 202] \hfill \\ The properties of matter and energy. Elasticity, fluid flow, thermodynamics, acoustics and optics.
\item[Physics 203] \hfill \\ The microscopic source of force. Electromagnetism and relativity, quantum mechanics and nuclear science.
\end{desc}
In the first term, we learn the principles of mechanics including the ideas of energy and momentum. This term is quite linear: each lecture builds on the previous. The second term works in two directions: inductive and deductive. These branches each have unique ways to approach the subject. The first step will be to understand each inductive approach. The second step will start from Newton's laws in order to derive and support these independent approaches through atomic theory. Each of these branches has its own story, so this term is less linear than the first. The third term involves the study of electricity and magnetism which we will find underlies all the mechanical forces (except gravity and weight) studied previously. In addition, it is also a branch of physics in its own right. We will find we need to correct Newton's laws with those of Einstein's relativity. Finally we end with the solution to a serious problem: atoms that obey Newton's (or Einstein's) laws of motion and electromagnetic theory cannot exist! Quantum mechanics solves this problem and involves a more accurate (though counter-intuitive) understanding of the subatomic world.

So, we begin and end with mechanics. The goal is to explain the stuff in the middle with these laws. As such we start with analyzing rudimentary things like rocks in free-fall or balls rolling down slopes. Newton's laws are built on the concept of force as the cause of motion. We will also develop a second perspective: that of energy. We will use both perspectives as needed like different tools in a toolbox. But underneath both of these ideas is the more fundamental notion of motion. In order to quantify motion, we need to talk about how to precisely measure distance and duration. These precision measurements are what gives us the data to refine, verify, and use these laws of motion.\footnote{It is also true that hidden assumptions about these techniques of measurement are why we need to replace Newton's laws with relativity and quantum mechanics in the third term.}

% SI units and unit conversion

\prep{Measurement involves a comparison to some conventional unit. So there are two things to consider: the unit and the \hide{method of comparison}.} A well-chosen unit will ease the method of comparison by making the process universal, portable, and stable. This is why over the years, even though the \href{http://en.wikipedia.org/wiki/Metric_system}{metric system} of units doesn't change, sometimes the definition of this process will. For example, the unit of length (the \jargon{meter}) used to be defined via a platinum-iridium bar held in Paris,\footnote{In 1793, this bar was intended to be one ten-millionth of a quadrant of the earth's circumference. It was later determined that this bar was short by a fifth of a millimeter. This makes the point: which is the unit, the bar or the earth? The earth is universal, but the bar is easier to use. So the bar is the true standard even if it is built incorrectly. See \url{http://en.wikipedia.org/wiki/Meter} for more details.} but in 1960 this definition was replaced with 1,650,763.73 wavelengths of the orange-red emission line of the krypton-86 atom in a vacuum. In 1983 this definition was replaced with the length of the path traveled by light in vacuum during a time interval of 1/299,792,458 of a second. This fixes the definition of the meter to the definition of our unit of time. Originally, the \jargon{second} was defined as 1/86400 of a solar day. Now the definition of the second is 9,192,631,770 periods of the radiation corresponding to the transition between the two hyperfine levels of the ground state of the cesium-133 atom.

These considerations are irrelevant for us since our experiments and the problems we will discuss require nowhere near this kind of precision. A good old stop watch and meter stick will be sufficient. But all of this hoopla is a testament to the precision and accuracy of modern-day physical science. What is relevant to us is learning how to use the metric system: conversion from other systems of units (e.g, inches and miles) and scientific notation.

\label{ex:unit-conversion}

I can never quite remember how to do these conversion calculations. I always remember one basic idea: \prep{each conversion equation is equivalent to a \hide{fraction} equal to one.} In other words, we have
$$1 \unit{m} = 39.37 \unit{in} \iff 1 = \frac{1 \unit{m}}{39.37 \unit{in}}$$
Suppose I have something that is 12 inches long. The way to determine its length in meters is to ``multiply by one'':
$$12 \unit{in} = 12 \unit{in} \times \frac{1 \unit{m}}{39.37 \unit{in}} = 0.3048 \unit{m}$$
Notice how the units in the fraction are designed to ``cancel out''. So the process can work the other way too. What is the length of 0.8 meters in inches?
$$0.8 \unit{m} = 0.8 \unit{m} \times \frac{39.37 \unit{in}}{1 \unit{m}} = 31.50 \unit{in}$$
Here is a more complicated example. Convert 25 miles per hour into meters per second. We need to look up the conversion from miles to meters (or vice versa). I find 1 mile = 1609 meters. Since there are 3600 seconds in a hour, the calculation is:
\begin{align*}
25 \unit{mph} &= 25 \unit{$\frac{\text{mi}}{\text{hr}}$} \times \frac{1609 \unit{m}}{1 \unit{mi}} \times \frac{1 \unit{hr}}{3600 \unit{s}} \\
              &= 11.17 \unit{m/s}
\end{align*}
One mistake that people often make is the conversion of squared and cubed units. No matter how many times I explain it, someone always makes this mistake. But the approach is no different than the above. Suppose I want to know how many square centimeters are in one square inch. I have:
\begin{align*}
1 \unit{in$^2$} &= 1 \unit{in$^2$} \times \frac{2.54 \unit{cm}}{1 \unit{in}} \times \frac{2.54 \unit{cm}}{1 \unit{in}} \\
                &= 6.452 \unit{cm$^2$}
\end{align*}
Notice how there are two conversion factors since a square inch is really an inch multiplied by an inch. For a cubic unit there are three conversion factors. For example: there are one million cubic centimeters in a cubic meter.

% Scientific notation and the metric system

\prep{We also need a way of dealing with very large and very small numbers. This is necessary when one speaks of the number atoms in a glass of water, the distance to far-off galaxies, the size of wavelength of light, etc. There are two approaches: use \hide{scientific notation} or use metric prefixes.} In reality you will need to do both, although technically one could get by with only one approach. Scientific notation is a bit cumbersome to get used to, but it is also a bit easier to use once you get used to it, so this is really the preferred method---especially for very large or small numbers. A number in scientific notation looks like this:
$$\sci{1.23}{-45}$$
Sometimes this is also written as 1.23E-45 which is much easier to type and is usually how calculators display the number. I won't belabor this topic---I think you've all seen scientific notation before.

The other approach is to use the metric prefixes.\footnote{See \url{http://en.wikipedia.org/wiki/SI_prefix} for a complete list.} are in Table \ref{tbl:metric-prefixes} This is much easier to \emph{talk} about and sometimes easier to visualize. The basic idea is to attach a prefix to the unit which represents a multiple of 1000. So a kilometer is 1000 meters, a millisecond is 1/1000 of a second. The most commonly used prefixes.

\tbl[full]{metric-prefixes}{cccl}
{
Prefix & Symbol & $10^n$ & Example \\
\hline
tera  & T     & 12    & terabyte: size of large computer hard drive \\
giga  & G     & 9     & gigawatt: nearly enough energy to operate a flux-capacitor \\
mega  & M     & 6     & megahertz: frequency of radio waves \\
kilo  & k     & 3     & kilometer: largest commonly used length \\
\hline
milli & m     & $-3$  & millimeter: smallest commonly used length \\
micro & $\mu$ & $-6$  & micrometer (a.k.a. micron): size of transistor \\
nano  & n     & $-9$  & nanometer: size of the atom \\
pico  & p     & $-12$ & picosecond: speed of computer calculations \\
femto & f     & $-15$ & femtometer: size of the nucleus \\	
}{Commonly used metric prefixes}

Sometimes ``u'' is used as a simple text replacement for the $\mu$ in micro. In addition, there are also prefixes between $10^{-3}$ and $10^3$, but the only time you will ever see them is in the centimeter, which is 10 millimeters. For example, a cubic centimeter is a convenient unit of volume.

% Math prerequisites

One thing that intimidates many people who have never been exposed to physics class is the math. Most of the homework and exams involve word problems which are notoriously difficult for most students. But this is unavoidable. Physics without math is like music without notes, like football without the ball. Mathematics is the very language of physics. Going back to the ancient Greeks, the highest level of mathematics has always been brought to bear on physical questions. In some cases physical inquiry has driven mathematical development. To truly work in modern physics one must know about group theory, differential manifolds, and a host of other exotic mathematical concepts. In fact, it's not unreasonable to say that the limit of your math ability will be the limit of your physics ability. I don't think it is any coincidence that the rise of modern physics in the 16th century (usually \href{http://en.wikipedia.org/wiki/Galileo_Galilei}{Galileo Galilei} is chosen as a starting point) occurs about the same time as the rise of modern algebra (for example, see \href{http://en.wikipedia.org/wiki/Franciscus_Vieta}{Fran\c cois Vi\'ete}).

But here is the silver lining: these highly refined levels of math are only required to get to the very edge between what we know and what we don't. It is very possible to understand the central core of the science with basic algebra, geometry and a dollop of calculus. 

You'll need to know how to solve basic algebraic equations---we will be doing this all the time. Occasionally we will need to solve a system of equations: two equations with two unknowns. Occasionally we will need to solve an equation involving logarithms.\footnote{\prep{Exponential functions are used to describe processes that involve growth or decay. \hide{Logarithms} are typically used to solve these kind of equations.}} That's about the extent of the algebra. I'll assume you can do the basics and will table reviewing the ``occasionals'' until we need them.

You will also need to remember some geometry (or at least how to look them up). Circles, triangles, parallel lines. Things like $C = 2\pi r$, $A = \pi r^2$, the angles of a triangle add to 180$\dg$, the Pythagorean theorem, etc. One nice trick to remember is that when a third line is drawn across a pair of parallel lines, the opposite angles are equal---both on the inside of the parallel lines and across each intersection (see Figure \ref{fig:parallel-lines}). Another fact we will use frequently is that \prep{the angle between two lines is the same as the angle between their \hide{perpendiculars}} (see Figure \ref{fig:two-perpendiculars}). We will also use a lot of trig, but we will review all that in Lecture \ref{ch:vectors}.

\tikzfig[side]{parallel-lines}
{
\begin{tikzpicture}[scale=0.8]
\draw (-3,1) -- (3,1);
\draw (-3,-1) -- (3,-1);
\draw (-2,-2) -- (2,2);
\path (-1,-1) +(22.5:0.6) node {$\alpha$};
\path (-1,-1) +(202.5:0.6) node {$\alpha$};
\path (1,1) +(22.5:0.6) node {$\alpha$};
\path (1,1) +(202.5:0.6) node {$\alpha$};
\end{tikzpicture}
}{Equal angles with parallel lines}

\tikzfig[side]{two-perpendiculars}
{
\begin{tikzpicture}
\draw (-2,0) -- (2,0);
\draw (0,-2) -- (0,2);
\draw (0,0) rectangle (0.2,0.2);
\begin{scope}[rotate=30]
\draw (-2,0) -- (2,0);
\draw (0,-2) -- (0,2);
\draw (0,0) rectangle (0.2,0.2);
\end{scope}
\foreach \q in {0,90,180,270} \node at (15+\q:0.8) {$\theta$};
\end{tikzpicture}
}{Equal angles between pairs of perpendiculars}

As far as calculus goes---really we should know some. Don't worry: I know this is a non-calculus class. But \prep{physics is the study of change and \hide{calculus} is the branch of mathematics designed to describe change.} So, I'll mention a couple of things. As I said before, any causal relationship between measurable quantities can be expressed as a mathematical function, $y = f(x)$. Frequently we will be interested in the following question. If I change $x$ a small amount (call it $\Delta x$), how much does $y$ change (call it $\Delta y$)? In general, we have $\Delta y = k(x) \Delta x$. Now if I rewrite this as
\begin{equation} \label{dfn-derivative}
k(x) = \frac{\Delta y}{\Delta x}	
\end{equation}
we call $k(x)$ the \jargon{derivative} of $f(x)$. If I were to plot $f(x)$ on a graph, the value of $k(x)$ corresponds to the slope of the curve at that point (see Figure \ref{fig:derivative}). So, the derivative represents how sensitive $f(x)$ is to changes in $x$.

\tikzfig{derivative}
{
\begin{tikzpicture}
\clip (-0.1,-0.1) rectangle (6.1,4.1);
\draw [->,help lines] (0,0) -- (6,0);
\draw [->,help lines] (0,0) -- (0,4);
\draw [domain=0:6,samples=100] plot (\x,{0.2*(\x-1)*(\x-3)*(\x-5)+2});
%\draw [domain=0:6,samples=100,blue] plot (\x,{0.2*(\x^3-9*\x^2+23*\x-15)+2});
\fill (3,2) circle (0.1);
%\draw [dashed] (2,2.8) -- (4,1.2);
\draw [dashed] (1.5,3.2) -- (4.5,0.8);
\end{tikzpicture}
}{Definition of derivative}

The ways in which calculus are used in physics are wide ranging (you could argue that calculus was invented for the sake of solving physics problems). But one trick is particularly helpful (when you need it). If you know the value of a function at a particular point and the derivative at that point, the values in that neighborhood is given by
\begin{equation} \label{taylor-expansion}
f(x + \Delta x) = f(x) + k(x) \Delta x
\end{equation}
This is really just rewriting the definition of the derivative. But how do we calculate these derivatives? Well, you need to take a calculus class to know that. But I can tell you one thing. The derivative of $x^n$ equals $nx^{n-1}$. So, here's a trick: what's the square root of 40? In symbols:
$$y = \sqrt{40} = (36 + 4)^{0.5}$$
Now, the derivative of $x^{0.5}$ is $0.5x^{-0.5} = 0.5 / \sqrt{x}$, so
$$y = \sqrt{36} + \frac{0.5}{\sqrt{36}} \times 4 = 6 \tfrac{1}{3}$$
The real answer is 6.3246---an error of less than 0.2\%. Okay, that's enough for now. I'll let you know some more calculus tricks as we go along. But be assured: you won't be expected to really know these details for this class. Consider them the special spices in the luscious banquet that is this class.

One particularly important application of these ideas is in a formula called the \jargon{binomial theorem}. Using the idea of a derivative it is possible to show that
\begin{equation} \label{binomial-theorem}
(1 + x)^n = 1 + nx^{n-1}
\end{equation}
when $x$ is very small. This formula can quite useful in relativistic calculations.

% On significant figures

There is one last topic to touch upon: significant figures. These are just the number of digits we are willing to show in our final calculations. The point here is that every measurement involves some sort of uncertainty. When I use a meter stick to measure the length of an air track, is it reasonable to believe that I know this length down to the micron? No. Maybe down to the millimeter or so. If that's the case I better not write down that the length is 602.5 millimeters. The .5 is unjustifiable. In fact, \prep{the implied possible error associated with recording a measurement like 602 millimeters is $\pm 0.5$ millimeters. That is, I'm confident it's \hide{neither 603 nor 601}---but whether its 602.4 or 601.9, I simply don't know.} Now, if I use this number to calculate another---say I multiply by $\pi$---the result cannot be \emph{more} accurate than the numbers going in! So even if your calculator says the answer is 1,891.2386 millimeters, this number conveys too much accuracy. We need to round the number to 1,890 millimeters. The basic rule is to round to the number of digits going in (in this case three). The zeros can sometimes make this confusing, but the basic rule is fairly straight-forward. If you can't figure any of this out, round to three digits---it'll be the right choice 80\% of the time.\footnote{However, you should keep more digits when performing intermediate calculations. Rounding can introduce an error that propagates through the calculation. In general, keep five digits until the very end. Then round to three.}

% Preview of next week

Next week we will talk more about measuring distances and learn some new math called vectors. We will see that we can apply these ideas to objects in equilibrium under several forces. This will give us the chance to talk about force, mass and weight.
========
02:vectors
--------
Vectors and Statics
--------
Read sections 1.4--1.8, sneak a peak at sections 4.11, 7.4, 9.2, 18.5, and 21.2
--------
% Why vectors?

We live in a three-dimensional world. So, as we start to describe how things move in space we need to take into account both distance and direction. Since geometry studies the properties of space, it's natural to expect the language of physics to be geometric. If you pull a copy of Newton's \href{http://en.wikipedia.org/wiki/Philosophiae_Naturalis_Principia_Mathematica}{Principia} from the library or \href{http://en.wikisource.org/wiki/The_Mathematical_Principles_of_Natural_Philosophy_(1846)}{Internet}, you will see that it is dominated by classical geometric theorems and reasoning. Fortunately, we don't need to know that much geometry. The invention of vectors and vector notation (usually associated with \href{http://en.wikipedia.org/wiki/Josiah_Willard_Gibbs}{Josiah Gibbs}) greatly simplifies the reasoning required to solve physics problems.

\prep{The reason why vectors are so much easier is that they convert \hide{geometric} problems into algebra.} The archetypal example of a vector is a simple displacement from here to there. This is usually drawn as a little arrow from point A to point B. The arrow is important because we want to maintain a distinction between the displacement that goes from A to B and that which goes from B to A. Typographically some authors use bold letters to represent a vector, but I prefer to use a letter with an arrow over it, like $\vect{a}$, which is pretty easy to write.

% Vector algebra: vector addition and scalar multiplication

Now consider a two-fold movement from point A to point B then to point C. We can represent this motion as two vectors in space, $\vect{a}$ pointing from A to B and $\vect{b}$ pointing from B to C. The whole motion can be captured in a vector pointing from A to C---we'll call it $\vect{c}$. See Figure \ref{fig:vector-addition}. When three vectors are associated in this way we say that $\vect{a}$ and $\vect{b}$ add up to $\vect{c}$. In symbols we write
$$\vect{c} = \vect{a} + \vect{b}$$
which looks just like adding numbers. The suggestion is deliberate, but remember: \prep{vectors are not numbers! Every vector equation like this has behind it a \hide{triangle}} like Figure \ref{fig:vector-addition}.

\tikzfig[side]{vector-addition}{
\vspace{-2in}
\begin{tikzpicture}[scale=0.7]
\node (A) [fill,circle,inner sep=0.5mm,label=225:{$A$}] at (0,0) {};
\node (B) [fill,circle,inner sep=0.5mm,label=315:{$B$}] at (4,0) {};
\node (C) [fill,circle,inner sep=0.5mm,label= 45:{$C$}] at (6,4) {};
\draw [->] (A) -- (B) node [midway,below] {$\vect{a}$};
\draw [->] (B) -- (C) node [midway,below right] {$\vect{b}$};
\draw [->] (A) -- (C) node [midway,above left] {$\vect{c}$};
\end{tikzpicture}
}{Vector addition}

\tikzfig[side]{vectors-commute}{
\vspace{0.5in}
\begin{tikzpicture}[scale=0.7]
\coordinate (A) at (0,0);
\coordinate (B) at (4,0);
\coordinate (C) at (6,4);
\coordinate (D) at (2,4);
\draw [->] (A) -- (B) node [midway,below] {$\vect{a}$};
\draw [->] (B) -- (C) node [midway,below right] {$\vect{b}$};
\draw [->] (A) -- (D) node [midway,above left] {$\vect{b}$};
\draw [->] (D) -- (C) node [midway,above] {$\vect{a}$};
%\draw [->,gray] (A) -- (C) node [midway,above left] {$\vect{c}$};
\end{tikzpicture}
}{Vector addition commutes}

The reason we call this \jargon{vector addition} is that this way of combining vectors obeys the laws of arithmetic. For example, it commutes: 
$$\vect{a} + \vect{b} = \vect{b} + \vect{a}$$
In order show this, I need to clarify one thing. \prep{The essence of the vector is its distance and direction, not \hide{where it sits}.} In order to represent this equation we need to move the arrows so that the tail of the second is on top of the head of the first. In other words, draw the first vector with the proper length in the correct direction then draw the second vector in the same way. If we do this with the vectors we were using previously we would get a diagram something like Figure \ref{fig:vectors-commute}. Notice how the pairs both end up in the same spot. You can see from this figure why vector addition is sometimes said to obey the \jargon{parallelogram law}.

Vector addition is also associative, has a zero and inverses. The zero vector has no length and no direction. The inverse of a vector is the vector that points in the exact opposite direction, so if $\vect{b}$ is the inverse of $\vect{a}$, we have $\vect{a} + \vect{b} = 0$.\footnote{I am too lazy to write the zero vector as $\vect{0}$ even though I probably should.}

There is also another thing we can do with vectors called \jargon{scalar multiplication}. Suppose I take a vector $\vect{a}$ and add it to itself. I get another vector in the same direction, with twice the length. In fact, I can write 
$$\vect{a} + \vect{a} = 2\vect{a}$$
The two is kind of ``multiplied'' into the vector just like in basic arithmetic: $5 + 5 = 2 \times 5$. \prep{Geometrically, scalar multiplication stretches (or shrinks) the size of the arrow, but algebraically it acts like \hide{multiplication} and obeys the standard laws of arithmetic.} In particular, negative one will flip the direction of the arrow making it point in the opposite direction. This even allows us to subtract vectors. Refer back to Figure \ref{fig:vector-addition}. I can write the following vector subtraction from this diagram: $\vect{c} - \vect{b} = \vect{a}$. The equation says: run up $\vect{c}$ then move backward on $\vect{b}$ and you end up where $\vect{a}$ ends up. I think you can start to see how these little arrows are forming a true algebra.

% Vector basis and vector components

It's useful to have this vector representation for understanding the basic concepts of physics. However, there is one more step we need to take to unleash their full power. We need to talk about \jargon{vector components}. This approach is similar to the use of \href{http://en.wikipedia.org/wiki/Cartesian_coordinate_system}{Cartesian coordinates} to describe where a point is in the plane. Each Cartesian grid defines a couple of unique vectors. Consider a vector that points in the $x$-direction with a length of one unit. \prep{Usually this vector is denoted $\vhat{x}$ (pronounced ``x-hat''). The little caret on top indicates that this is a \hide{unit vector}---a vector with the length of one.} Similarly there is the unit vector that points in the $y$-direction denoted $\vhat{y}$. 

These two vectors are called a \jargon{vector basis} for the plane because they are sufficient to describe any other vector in the plane. For example consider the vector $\vect{v} = 5\vhat{x} + 3\vhat{y}$ (see Figure \ref{fig:vector-basis}). We say that its $x$-component is five and its $y$-component is three. These quantities are usually denoted $v_x$ and $v_y$ respectively.

\tikzfig[side]{vector-basis}{
\begin{tikzpicture}[scale=0.8]
\coordinate (v1) at (0,0);
\coordinate (v2) at (5,3);
\coordinate (vx) at (5,0);
\coordinate (vy) at (0,3);
\draw [dashed,gray] (-0.5,-0.5) grid (5.5,3.5);
\draw [->] (v1) -- (v2) node [midway,above left] {$\vect{v}$};
\draw [->] (v1) -- (vx) node [midway,below] {$5\vhat{x}$};
\draw [->] (vx) -- (v2) node [midway,right] {$3\vhat{y}$};
\draw [->,very thick] (0,0) -- (1,0) node [midway,below] {$\vhat{x}$};
\draw [->,very thick] (0,0) -- (0,1) node [midway,left] {$\vhat{y}$};
\end{tikzpicture}
}{Vector basis in action}

Every vector that can be drawn in the plane can be completely specified by these components. In almost every problem, we will be utilizing the components of vectors to perform our necessary calculations. The reason for this is that \prep{every vector equation implies an equality between \hide{components}.} In other words,
$$\vect{a} = \vect{b} \implies a_x = b_x \quad \text{and} \quad a_y = b_y$$
In general, each vector equation creates a component equation for each dimension of the problem.

\label{ex:vector-addition}

This makes adding two vectors easy once I know their components. Let's take $\vect{a} = 6\vhat{x} + 2\vhat{y}$ and $\vect{b} = -3\vhat{x} + 4\vhat{y}$ and call their sum $\vect{c}$:
$$\vect{c} = \vect{a} + \vect{b}$$
Using components, it's easy to see what $\vect{c}$ is:
\begin{align*}
c_x &= a_x + b_x = 6 + (-3) = 3 \\
c_y &= a_y + b_y = 2 + 4 = 6
\end{align*}
So, $\vect{c} = 3\vhat{x} + 6\vhat{y}$. You can draw the triangle to double-check. You should get something like Figure \ref{fig:vector-addition-components}.

\tikzfig[side]{vector-addition-components}{
\begin{tikzpicture}[scale=0.7]
\coordinate (0) at (0,0);
\coordinate (a) at (6,2);
\coordinate (b) at (-3,4);
\coordinate (c) at ($(a)+(b)$);
\draw [dashed,gray] (-0.5,-0.5) grid (6.5,6.5);
\fill [fill opacity=0.10] (0) -| (a);
\fill [fill opacity=0.10] (a) |- (c);
\fill [fill opacity=0.10] (0) |- (c);
\draw [->] (0) -- (a) node [midway,below right] {$\vect{a}$};
\draw [->] (a) -- (c) node [midway,above right] {$\vect{b}$};
\draw [->] (0) -- (c) node [midway,above left] {$\vect{c}$};
\draw [->,very thick] (0,0) -- (1,0) node [midway,below] {$\vhat{x}$};
\draw [->,very thick] (0,0) -- (0,1) node [midway,left] {$\vhat{y}$};
\end{tikzpicture}
}{Vector addition using components}

% Vector magnitude and direction

\label{ex:vector-magnitude}

What is the length of this vector $\vect{c}$? This also is easy to answer now that we know its components. Look again at Figure \ref{fig:vector-addition-components}. Notice how the shaded triangle next to the vector $\vect{c}$ is a right triangle? In fact, the hypotenuse of this triangle is the length we are interested in---and we know the length of the sides because they are the components we just calculated. 

Using the Pythagorean theorem, the length\footnote{The length of a vector is commonly denoted by the same letter without the little arrow on top.} is
$$c = \sqrt{c_x^2 + c_y^2} = \sqrt{(3)^2 + (6)^2} = 6.7$$
What about its direction? Now we need to talk trig\ldots

Remember for any right triangle, the three basic trig functions relate the sides of the triangle to the angle inside the triangle. By definition, the sine of an angle is the ratio of the side adjacent to the angle and the hypotenuse (which is opposite to the right angle). The cosine is the ratio of the opposite side and the hypotenuse. The tangent is the ratio of the opposite and the adjacent (which is also the ratio of the sine and cosine). These relations are summarized in the familiar Figure \ref{fig:trig-definitions}.

\tikzfig{trig-definitions}{
\begin{tikzpicture}
\coordinate (A) at (0,0);
\coordinate (B) at (4,0);
\coordinate (C) at (0,3);
%\draw (A) rectangle ($(A)+(45:0.5)$);
\draw ($(B)+(180:0.7)$) arc (180:143:0.7);
\node at ($(B)+(161:1.0)$) {$\theta$};
\draw (A) -- node [below] {$a$} (B) -- node [above right] {$c$} (C) -- node [left] {$b$} (A);
%\node [right] at (4.5,1.5) {
\node [right] at (4,2) {
\begin{minipage}{30mm}
\begin{align*}
\sin \theta &= a/c \\
\cos \theta &= b/c \\
\tan \theta &= a/b
\end{align*}
\end{minipage}
};
\end{tikzpicture}
}{Trig function definitions}

So, if we want to know the direction of our vector $\vect{c}$ in Figure \ref{fig:vector-addition-components}, we can use the tangent function. The components are the adjacent and opposite sides, so we have:
$$\theta = \tan^{-1} (c_y/c_x) = \tan^{-1} (6/3) = 63.4\dg$$

We can also turn things around. If we only know the direction and length of a vector $\vect{v}$, the components are given by the other trig functions:
\begin{align*}
v_x &= v \cos \theta \\
v_y &= v \sin \theta
\end{align*}
You will use these equations again and again in this class, so make sure you understand them.

% Vectors are not just displacements...

Until now I have been using displacements in the plane as my example of vectors. These are not the only physical quantities that can be represented by vectors. \prep{Anything involving a \hide{direction} can typically be represented by a vector.} One quantity of particular importance is force. As I mentioned in the Lecture \ref{ch:overview}, the idea of force runs through all of classical mechanics; Newton's laws are built to understand the effects of various forces. All that I have said up to now also can be applied to the forces operating on an object with one subtle distinction.

\prep{In describing vector addition with displacements I asked you to imagine the two vectors being combined as head-to-tail, or consecutive. With force it is more appropriate to imagine the vectors combining \hide{simultaneously}.} In the end, this distinction is not important in our calculations, but it does change how we draw the combinations. See Figure \ref{fig:vector-addition-two-ways} for what I mean.

\tikzfig[side]{vector-addition-two-ways}{
\vspace{-4.5in}
\begin{tikzpicture}
\begin{scope}[yshift=20mm]
%\node at (2,4) {\textbf{Consecutive}};
\coordinate (A) at (0,0);
\coordinate (B) at (3,0);
\coordinate (C) at (4,3);
\coordinate (D) at (1,3);
\draw [dotted] (A) -- (B) -- (C) -- (D) -- cycle;
\draw [->] (A) -- (B) node [midway,below] {$\vect{a}$};
\draw [->] (B) -- (C) node [midway,below right] {$\vect{b}$};
\draw [->] (A) -- (C) node [midway,above left] {$\vect{c}$};
\end{scope}
\begin{scope}[yshift=-20mm]
%\node at (2,4) {\textbf{Simultaneous}};
\coordinate (A) at (0,0);
\coordinate (B) at (3,0);
\coordinate (C) at (4,3);
\coordinate (D) at (1,3);
\draw [dotted] (A) -- (B) -- (C) -- (D) -- cycle;
\draw [->] (A) -- (B) node [midway,below] {$\vect{a}$};
\draw [->] (A) -- (D) node [midway,above left] {$\vect{b}$};
\draw [->] (A) -- (C) node [midway,above left] {$\vect{c}$};
\end{scope}
\end{tikzpicture}
}{Consecutive versus simultaneous vector addition}

\label{ex:three-forces}

A typical force problem is like this: An object is pulled in three directions by three forces (see Figure \ref{fig:three-forces}). The force $\vect{a}$ has a magnitude of 2 at an angle of 200$\dg$ and the force $\vect{b}$ has a magnitude of 3 at an angle of 300$\dg$. What must the magnitude and angle of the third force be to balance the other two? 

\tikzfig[side]{three-forces}{
\begin{tikzpicture}
\fill (0,0) circle (0.1);
\draw [->] (0,0) -- (200:2) node [midway,above] {$\vect{a}$};
\draw [->] (0,0) -- (300:3) node [midway,above right] {$\vect{b}$};
\draw [->] (0,0) -- (83.4:3.31) node [midway,below right] {$\vect{c}$};
\end{tikzpicture}
}{An object pulled by three forces}

In vector notation, the answer is simple. We want all three forces to balance---in other words, we want them all to add to zero:
$$\vect{a} + \vect{b} + \vect{c} = 0$$
We solve for $\vect{c}$ and we are done:
$$\vect{c} = -(\vect{a} + \vect{b})$$
But not really. We want to know both the magnitude and direction of $\vect{c}$. We will get those by calculating components. The components of $\vect{a}$ are:
\begin{align*}
a_x &= a \cos \theta = (2)(\cos 200\dg) = -1.88 \\
a_y &= a \sin \theta = (2)(\sin 200\dg) = -0.684
\end{align*}
Notice how they are both negative. This is as it should be because the positive $x$-direction is to the right but this vector points to the left. Similarly, the positive $y$-direction is up but this vector points down. It's always a good quick double-check to make sure these signs are right. The components of $\vect{b}$ are:
\begin{align*}
b_x &= b \cos \theta = (3)(\cos 300\dg) = 1.50 \\
b_y &= b \sin \theta = (3)(\sin 300\dg) = -2.60
\end{align*}
So, the components of $\vect{c}$ are:
\begin{align*}
c_x &= -(-1.88 + 1.50) = 0.38 \\
c_y &= -(-0.684 + -2.60) = -3.28
\end{align*}
Therefore its magnitude and direction are
\begin{align*}
c &= \sqrt{(0.38)^2 + (-3.28)^2} = 3.31 \\
\theta &= \tan^{-1} (-3.28/0.38) = 83.4\dg
\end{align*}

Those are the basics on vectors. As you can see, \prep{most of the time you will be calculating the components of given vectors, \hide{adding} those components, and occasionally converting these answers back into a magnitude and direction.} The hardest part is keeping the trig straight.

% Beyond the book: dot products, cross products, tensors and four-vectors

But I find it hard to stop here without covering a few supplemental topics\ldots

There are other ways to combine vectors. These are also called multiplication, but I think that this is just a way to distinguish them from the more fundamental operation of vector addition.\footnote{Although they do distribute over vector addition, so this nomenclature is not without merit.} The first is called the \jargon{dot product} and it has two equivalent definitions:
$$\vect{a} \cdot \vect{b} = ab \cos \theta$$
where $\theta$ is the angle between the two vectors. This is the ``geometric'' definition in terms of lengths and angles. The ``algebraic'' definition is in terms of components:
$$\vect{a} \cdot \vect{b} = a_x b_x + a_y b_y$$
It's not obvious that these two definitions are equivalent but they are. This vector combination is useful when talking about work and energy in Lecture \ref{ch:energy}.

A second combination is called the \jargon{cross product} (a.k.a. the \jargon{vector product}). The ``geometric'' definition is:
$$\vect{a} \times \vect{b} = (ab \sin \theta) \vhat{n}$$
where $\vhat{n}$ is the unit vector that points perpendicular to the plane defined by $\vect{a}$ and $\vect{b}$. The ``algebraic'' definition is
$$\vect{a} \times \vect{b} = (a_x b_y - a_y b_x) \vhat{n}$$
(This assumes that $\vect{a}$ and $\vect{b}$ lie in the $xy$-plane, $\vhat{n}$ points out of the page). Notice that the dot product produces a number but the cross product produces a vector. This vector combination is useful when talking about torque and rotation in Lecture \ref{ch:torque} and also magnetism in Lecture \ref{ch:dc-and-magnetism}.

A few introductory physics texts mention these two vector products, but none talk about tensors. I'm not sure why since they aren't too hard to understand. A \jargon{tensor} is a linear function between vectors. Remember, a function represents a causal relationship between variables. If the variables are represented by vectors, you may have a tensor on your hands. For this relationship to be a tensor it must be linear in the sense that it must preserve both vector addition and scalar multiplication. In symbols, a vector function $f$ is a tensor when the following are true:
\begin{gather*}
f(\vect{v} + \vect{u}) = f(\vect{v}) + f(\vect{u}) \\
f(a\vect{v}) = a f(\vect{v})
\end{gather*}
It can be shown that the basis in the underlying vector space also allows us to define tensor components to describe these functions. In our case there would be four (or nine if we are talking 3D). Tensors can be helpful in discussing rotation, elastic stress and electromagnetism. 

Finally, it's worth mentioning \jargon{four-vectors}. \prep{One particularly concise way to deal with the complications of \hide{relativity} is to use the idea of a four-dimensional vector.} This is related to the fact that Einstein showed that it is not appropriate to consider space and time as separate entities but rather as a combined space-time continuum. This combination of the three dimensions of space with the fourth dimension of time propagates through the various concepts of physics in a way that is both elegant and surprising.

% Preview of next week

Next week we will develop some fundamental concepts that will allow us to describe motion in a way that will fit in with Newton's three laws of motion (Lecture \ref{ch:newtons-laws}). In particular we will find out the path of a projectile under the influence of gravity.
========
03:kinematics
--------
The Analysis of Motion
--------
Read sections 2.1--2.7 and sections 3.1--3.3
--------
% Reference frames and position

Any physical system is specified mechanically by its configuration: the relative position and orientation of its parts. The motion of the system is defined when its configuration is specified over time. What we need is a way to record this configuration. This is usually very difficult\footnote{And frequently impossible when we talk about atomic theory.} and requires great cleverness on the part of the experimentalist. \prep{But some systems are simpler to characterize than others. The simplest of all is the one whose internal configuration is \hide{negligible}. This system is called a \jargon{particle} and is defined by its position in space.} A contraption that will record this position in space is called a \jargon{reference frame}.\footnote{I am trying to emphasize the fact that this reference frame is not a mental construction but a physical one. We use the frame to construct a mental inventory of our system, but the raw data is coming from rulers and clocks subject to the laws of physics. These statements will become important when we talk about the need for modifying Newton's laws with Einstein's relativity in Lecture \ref{ch:em-and-relativity}.}

Suppose we set up a reference frame and begin to record the position of our particle. Obviously the values we get will depend upon the details of the reference frame---we will assume this frame is perpendicular, uniform and stationary. For now let's restrict ourselves to motion in a plane. Then the position is specified by the two numbers associated with the Cartesian grid in that frame. As we monitor the motion of the particle, these two numbers change. In other words, they are functions of time: $x(t)$ and $y(t)$.

% Velocity defined: average and instantaneous

Now consider the displacement of the particle between two moments of time. Let's agree to call the first instant $t_0$ and the second simply $t$. The position of the particle at each of these moments in time define a displacement vector which we will call $\Delta \vect{x}$. The $x$-component is given by $x(t) - x(t_0)$ or in more compact notation, $x - x_0$. Similarly for the $y$-component.

\prep{Notice that the length of the displacement $\Delta \vect{x}$ represents the net motion of the particle. The overall \hide{path-length} traversed cannot be smaller and may be much longer than the net displacement.} We will see that both the path-length and the net displacement are important quantities to track, but the displacement is more important. Above all, we must remember the distinction between the two!

The rate at which the position changes is called \jargon{velocity}. Velocity is a vector, so it has both direction and magnitude. The faster the speed of the object, the larger the magnitude of the velocity. The rate of change of any quantity is the ratio of the size of the change to its duration, so velocity is simply the displacement $\Delta \vect{x}$ divided by $\Delta t = t - t_0$.\footnote{Technically this is not a division, but a scalar multiplication of $\Delta \vect{x}$ by $1/\Delta t$.}

What I have just described is called the \jargon{average velocity}. Because the displacement $\Delta \vect{x}$ represents the net motion of the object, this velocity is a kind of average of the speed during the motion of the object. For example, if the object moves in a complete circle, the net displacement will be zero and so will the average velocity. This is because the velocity takes into account both the speed and direction. The velocity on the upper half of the circle is canceled out by the lower half.

More frequently we are interested in the velocity of an object at a particular moment in time. The problem we now face is that our definition of velocity requires us to consider two moments in time.\footnote{So does the lab. In the lab, velocity measurements always involve measuring the length traveled in a specific period of time and dividing the two.} Clearly if we shrink the interval in time between these two moments, we get closer to what we want. This is where the calculus comes in. We want to ``take the limit'' as this interval $\Delta t$ goes to zero. The challenge is that as the denominator of the velocity shrinks, so does the numerator---the displacement involved becomes smaller and smaller---we are going to end up with the value 0/0. Well, the purpose of calculus is to make sense of this nonsense.

But we don't need to know the technical details involved. Take it for granted that this process is well-defined. We call the velocity defined in this way the \jargon{instantaneous velocity}. As I mentioned above, this is what we will typically be interested in, so \prep{when you see the word velocity you should assume it refers to the \hide{instantaneous} velocity of the object.} 

If we take the position of a particle and plot it against time we get a curve. We can say that the position is a function of time. Then the velocity is its derivative as defined in the Lecture \ref{ch:overview}. The velocity is the slope of the line at a particular point in time (see Figure \ref{fig:dfn-vel}).

\tikzfig[full]{dfn-vel}{
\begin{tikzpicture}
\begin{scope}[xshift=-40mm]
%\draw [dashed,gray] (0,0) grid (6,4);
\draw [->] (0,0) -- (6,0) node [right] {$t$};
\draw [->] (0,0) -- (0,4) node [above] {$x$};
\draw [domain=0:6,samples=100] plot (\x,{0.2*(\x-1)*(\x-3)*(\x-5)+2});
\coordinate (a) at (2,2.6);
\coordinate (b) at (4,1.4);
\fill (a) circle (0.1);
\fill (b) circle (0.1);
\draw [dashed] ($(a)!-0.5!(b)$) -- ($(a)!1.5!(b)$);
\draw (2,-0.1) -- (2,0.1);
\draw (4,-0.1) -- (4,0.1);
\draw [decorate,decoration=brace] (4,-0.2) -- (2,-0.2) node [midway,below=1mm] {$\Delta t$};
\draw (-0.1,2.6) -- (0.1,2.6);
\draw (-0.1,1.4) -- (0.1,1.4);
\draw [decorate,decoration=brace] (-0.2,1.4) -- (-0.2,2.6) node [midway,left=1mm] {$\Delta x$};
\node at (3,4.5) {\textbf{Average}};
\node at (3,4) {
\begin{minipage}{20mm}
$$\avg{v} = \frac{\Delta x}{\Delta t}$$
\end{minipage}
};
\end{scope}
\begin{scope}[xshift=40mm]
%\draw [dashed,gray] (0,0) grid (6,4);
\draw [->] (0,0) -- (6,0) node [right] {$t$};
\draw [->] (0,0) -- (0,4) node [above] {$x$};
\draw [domain=0:6,samples=100] plot (\x,{0.2*(\x-1)*(\x-3)*(\x-5)+2});
\fill (3,2) circle (0.1);
\draw [dashed] (1.5,3.2) -- (4.5,0.8);
\draw (3,0.1) -- (3,-0.1) node [below] {$t$};
\node at (3,4) {
\begin{minipage}{40mm}
\begin{center}
\textbf{Instantaneous}
$$v(t) = \lim_{\Delta t \rightarrow 0} \frac{\Delta x}{\Delta t}$$
\end{center}
\end{minipage}
};
\end{scope}
\end{tikzpicture}
}{Velocity defined as the slope of the space-time curve}

Frequently in these motion-based physics problems we will be given the initial velocity of an object and our goal will be to describe some characteristic of the motion. The velocity tells us the direction in which the object will move and its speed. If it is moving at 30 m/s, we know that in one second it will have moved 30 meters. After two seconds it will have moved 60 meters. The formula for this is
\begin{equation} \label{const-vel}
x = vt
\end{equation}
I like to call equation \eqref{const-vel} the ``constant velocity equation''. You can see it is really a rearranging of the definition of velocity with $x_0$ and $t_0$ set to zero. Remember this formula only works if the velocity does not change. If either the speed or direction of the object changes during its motion, equation \eqref{const-vel} will not work.

% Acceleration defined

\prep{If the velocity does change, its \hide{rate of change} is called \jargon{acceleration}. You might be less familiar with the notion of acceleration, but this quantity is the most important one for understanding motion.} This is not immediately obvious and this insight is one of the keys to understanding Newton's laws of motion. We will see that a constant force will generate a corresponding constant acceleration in an object. 

An important special case of this is an object's weight. This is the gravitational force the earth exerts trying to pull an object to its center. Newton discovered the laws that govern gravitation and was able to explain the workings of the solar system with it---we will talk about that in Lectures \ref{ch:equilibrium}, \ref{ch:newtons-laws}, and \ref{ch:torque}. But on the surface of the earth the force of gravity is fairly constant.\footnote{Even in Newton's time it was possible to measure the slight variations in the force of gravity on the earth.} Because of this, \prep{the weight of an object causes it to fall with a constant acceleration of \hide{9.8} meters per second squared, symbolized by $g$.}

% Equations of constant acceleration

So it is worth spending some time on understanding the motion of particles with constant acceleration. Since the definition of acceleration parallels the definition of velocity, we must have a formula that parallels equation \eqref{const-vel}. It is
\begin{equation} \label{const-acc}
v = v_0 + at
\end{equation}
Remember that this formula depends upon the acceleration being constant---which is not always the case. We will see an example of that in Lecture \ref{ch:circular-motion} with uniform circular motion. In that case we need a different formula.

But how do we relate equation \eqref{const-acc} to position? Calculus is designed to deal with this type of problem---how do we calculate the position if the velocity is changing? However, there is another trick we can use because the rate at which the velocity is changing is constant. If a quantity increases (or decreases) at a constant rate, its average value is the average of the initial and final values.\footnote{I won't prove this statement, but consider the following example. Take the series 1,3,5,7,9,11. The average of these numbers is 6 which is also the average of the ends. Now take the series 2,4,8,16. The average of these numbers is $7\half$ while the average of the ends is 9.} So,
$$\avg{v} = \half(v + v_0)$$
Now the average velocity by definition is the displacement divided by time, so we can rewrite this as
\begin{equation} \label{pos-avg-vel}
x = \half(v + v_0)t
\end{equation}
By combining equations \eqref{const-acc} and \eqref{pos-avg-vel} we can derive three more equations:
\begin{equation} \label{pos-ini-vel}
x = v_0 t + \half at^2
\end{equation}
and
\begin{equation} \label{pos-fin-vel}
x = vt - \half at^2
\end{equation}
and
\begin{equation} \label{pos-vel-sqr}
v^2 = v_0^2 + 2ax
\end{equation}
Equations \eqref{const-vel}--\eqref{pos-vel-sqr} are the main results of this lecture. The rest of the lecture will be about applying them.

\label{ex:dropped-from-rest}

A typical problem is a object dropped from rest. Suppose we let a rock fall for two seconds. How far does it fall? In these constant acceleration problems there are five possible quantities to consider: $t$, $x$, $v_0$, $v$, and $a$. Notice how each of the equations \eqref{pos-avg-vel}--\eqref{pos-vel-sqr} involve four of these five quantities. So one of the first steps in solving these problems is to identify the four quantities in the problem. For the rock problem we are told explicitly that the time involved is two seconds. We also know that the acceleration of the rock is $-9.8$ meters per second. Notice the negative sign. This is there to indicate that the acceleration due to gravity is down. What else? The initial velocity is zero. Occasionally you will need to tease this kind of implicit data from these problems. So we have three of four. The final quantity is the distance $x$---we don't know it, but we want to know it. The equation that involves $t$, $a$, $v_0$, and $x$ is \eqref{pos-ini-vel}. We have:
\begin{align*}
x &= (0)(2) + \half (-9.8)(2)^2 = -19.6
\end{align*}
In this case the negative sign is there because the net displacement is down. See Figure \ref{fig:free-fall-no-drag} for the space-time diagrams associated with this problem.\footnote{Notice how when we have an object accelerated from rest, the distance it travels is given by equation \eqref{pos-ini-vel} as $$d = \half at^2$$}

\tikzfig{free-fall-no-drag}{
\begin{tikzpicture}[scale=0.8]
\begin{scope}[xshift=0mm]
\draw [dashed,help lines] (0.01,-2.99) grid (2.99,0.99);
\draw [->] (0,0) -- node [above] {$t$} (3,0);
\draw [->] (0,-3) -- (0,1) node [above] {$a$};
\node [left] at (0,0) {0};
\draw [->] (0,-2) -- (2.5,-2) node [right,fill=white] {$-9.8$};
\node at (1.5,-3.5) {$a = -9.8$};
\end{scope}
\begin{scope}[xshift=40mm]
\draw [dashed,help lines] (0.01,-2.99) grid (2.99,0.99);
\draw [->] (0,0) -- node [above] {$t$} (3,0);
\draw [->] (0,-3) -- (0,1) node [above] {$v$};
\node [left] at (0,0) {0};
\draw [->] (0,0) -- (2.5,-2.5);
\node at (1.5,-3.5) {$v = -9.8t$};
\end{scope}
\begin{scope}[xshift=80mm]
\draw [dashed,help lines] (0.01,-2.99) grid (2.99,0.99);
\draw [->] (0,0) -- node [above] {$t$} (3,0);
\draw [->] (0,-3) -- (0,1) node [above] {$x$};
\node [left] at (0,0) {0};
\draw [->] (0,0) parabola (2.5,-2.5);
\node at (1.5,-3.5) {$x = -4.9t^2$};
\end{scope}
\end{tikzpicture}
}{Space-time diagrams for free-fall with no air drag}

So the general procedure is to identify the three pieces of data given (perhaps implicitly). Then look for the equation that involves those three and the one quantity you need. Then solve it.

% What about air drag?

Until now we have deliberately left out the idea of air drag. We have left it out not because it is negligible but because it is hard to deal with. Usually air drag introduces a deceleration\footnote[-0.35in]{When the acceleration opposes the direction of motion (or velocity) we call it deceleration. Notice this is not the same as negative acceleration which indicates its direction in space. When an object falls, the deceleration from air drag points up.} that is related to speed (the faster the speed, the larger the drag\footnote[0.35in]{This is why you can't shoot fish in a barrel. The drag on the bullet is so great it can actually destroy the bullet itself. In fact, the higher caliber the more likely this will happen.}). To solve these problems exactly requires some calculus. But we can get an approximate solution using a spreadsheet. The project for this term walks you through how to do this. In fact, the spreadsheet approach will work even for those problems when the calculus won't.

Although the detail of free-fall with air drag are complicated, its final state is easy enough to understand. \prep{Depending upon the details of the object and the air, a certain velocity will produce just enough \hide{drag} to counter-balance the weight of the object.} This is called the \jargon{terminal velocity} of the object. If the object starts with a velocity smaller than terminal (at rest, for example) then the net acceleration will increase the velocity. As the velocity increases, the drag will oppose more of the weight reducing the acceleration (slowing the \emph{rate} at which velocity increases) until it reaches a steady-state at terminal velocity. See the space-time graphs in Figure \ref{fig:free-fall-with-drag} and compare them with those in Figure \ref{fig:free-fall-no-drag}.

\tikzfig{free-fall-with-drag}{
\begin{tikzpicture}[scale=0.8]
\begin{scope}[xshift=0mm]
\draw [dashed,help lines] (0.01,-2.99) grid (2.99,0.99);
\draw [->] (0,0) -- node [above] {$t$} (3,0);
\draw [->] (0,-3) -- (0,1) node [above] {$a$};
\node [left] at (0,0) {0};
\draw [->,in=180,out=60] (0,-2) to (2.5,0);
\node at (1.5,-3.5) {$a \rightarrow 0$};
\end{scope}
\begin{scope}[xshift=40mm]
\draw [dashed,help lines] (0.01,-2.99) grid (2.99,0.99);
\draw [->] (0,0) -- node [above] {$t$} (3,0);
\draw [->] (0,-3) -- (0,1) node [above] {$v$};
\node [left] at (0,0) {0};
\draw [->,in=180,out=-45] (0,0) to (2.5,-1);
\node at (1.5,-3.5) {$v \rightarrow v_\text{terminal}$};
\end{scope}
\begin{scope}[xshift=80mm]
\draw [dashed,help lines] (0.01,-2.99) grid (2.99,0.99);
\draw [->] (0,0) -- node [above] {$t$} (3,0);
\draw [->] (0,-3) -- (0,1) node [above] {$x$};
\node [left] at (0,0) {0};
\draw [->,in=135,out=0] (0,0) to (2.5,-1.5);
\end{scope}
\end{tikzpicture}
}{Space-time diagrams for free-fall with air drag}

% Projectile motion

Until now we have only been discussing motion in one dimension. However, we can also discuss the motion of a projectile flying under the influence of gravity with these same equations. \prep{The problem of understanding the motion of projectiles goes back to antiquity and wasn't really solved until Galileo began to analyze the idea of \hide{acceleration}.} His main insight is that the vertical component of the motion is under the constant acceleration (due to gravity) while the horizontal motion has no acceleration---the horizontal motion obeys equation \eqref{const-vel}. This means that the trajectory in space is a parabola.

\label{ex:projectile-range}

For example, suppose we launch a projectile at a 60$\dg$ angle with an initial speed of 45 meters per second. How far will it fly? Ignore air resistance. See Figure \ref{fig:range-prob} for reference.

\tikzfig{range-prob}{
\begin{tikzpicture}[scale=0.8]
\coordinate (p) at (1,-4);
\coordinate (dp) at (1,2);
\coordinate (q) at (9,-4);
\fill (p) circle (0.05);
\draw [->] (p) -- node [above left] {$v_0$} ($(p)+(dp)$);
\draw (p) +(0:0.3) arc (0:60:0.3);
\node at ($(p)+(30:0.6)$) [right] {$\theta = 60\dg$};
\draw (1,-4) parabola bend (5,0) (9,-4);
\fill (q) circle (0.05);
\draw [dotted] (0,-4) -- (10,-4);
\draw [|-|] (1,-4.4) -- (9,-4.4) node [midway,fill=white] {$R$};
\end{tikzpicture}
}{Calculating the range of a projectile}

The first step is to break the data into horizontal and vertical components. In the horizontal we know that we will use equation \eqref{const-vel} which involves $x$, $v_{0x}$, and $t$. We are interested in solving for $x$ and we are given enough information to solve for $v_{0x}$. This means we will be able to solve for $t$. This is common because \prep{the duration $t$ is the same for the vertical and horizontal components. So the time is frequently a problem \hide{solving} ``bridge'' between the information contained in the horizontal and vertical components.} In our case we need to calculate $v_{0x}$ first:
$$v_{0x} = v_0 \cos \theta = (45)(\cos 60\dg) = 22.500$$
But we can't calculate the time because we don't know the range. Since we have exhausted the information contained in the horizontal motion, let's turn to the vertical. We know $v_{0y}$ is given by:
$$v_{0x} = v_0 \sin \theta = (45)(\sin 60\dg) = 38.971$$
Of course, $a = -9.8$ since this is a free-fall problem (no air drag). We want to determine $t$ in order to use it in the horizontal calculation, so we need one more vertical quantity from the problem statement. The implicit data here is that $y = 0$ because we are asked about the range---the distance the projectile travels until it comes back to its original level. This is a net vertical displacement of zero. Given this information, we can use equation \eqref{pos-ini-vel} to solve for $t$.
\begin{gather*}
(0) = (38.971)(t) + \half(-9.8)(t)^2 \\
\implies t = 7.9533
\end{gather*}
Since the duration of the vertical motion is the same as the horizontal, we can finally solve for the total $x$-displacement. Thus,
$$x = (22.500)(7.9533) = 178.95$$
The original data was given with two significant digits, so we should round this final answer to 180 meters.

It is sometimes convenient to know the range of a projectile without going through the logic of the previous example. We can summarize the results in the formula\footnote{You can derive this formula by simply using the same logic as our example problem but use letters without putting the numbers in. You'll need to remember the trig identity $\sin 2\theta = 2 \sin \theta \cos \theta$.}
\begin{equation} \label{range-eqn}
R = (v_0^2 / g) \sin 2\theta
\end{equation}
This is called the \jargon{range equation}. Deriving formulas for every permutation of the projectile problem is tiresome, but this one can be useful on occasion.

There are a number of different of projectile questions that can be asked and sometimes finding the implicit data can get tricky. One trick in particular to note is that \prep{at the top of the trajectory the vertical velocity $v_y$ is \hide{zero}.} Occasionally you'll need to use the quadratic equation. But the principles you will need to solve them are all laid out in this example.

% Projectile motion with air drag

Anyone who has played 30 seconds of golf will know that these problems are completely unrealistic and don't represent the true motion of the ball. The air not only resists the motion (air drag) but any spin on the ball will curve its path as well. The dynamics of spin and its curving effect are extremely complicated\footnote{Ultimately it is based on Bernoulli's principle---something we will talk about in Lecture \ref{ch:fluids}.} but if we focus our discussion on just the air drag, we can say a couple of things.

First, the range of the ball is much shorter than without drag. The longer the time the ball is in the air the longer the effects of air resistance so the effect is most pronounced on projectiles with large initial velocities (there is also a correspondingly larger air drag as well). It follows that the maximum height and the time of flight are also shorter. See Figure \ref{fig:cartoon-traj}

\tikzfig{cartoon-traj}{
\begin{tikzpicture}[scale=0.8]
\coordinate (p) at (1,-4);
\coordinate (dp) at (1,2);
\coordinate (q) at (9,-4);
\fill (p) circle (0.05);
\draw [->] (p) -- ($(p)+(dp)$);
\draw [->] (p) -- node [above left] {$v_0$} ($(p)+(dp)$);
\draw (p) +(0:0.3) arc (0:60:0.3);
\node at ($(p)+(30:0.6)$) {$\theta$};
\draw [help lines] (1,-4) parabola bend (5,0) (9,-4);
%\draw [help lines] (q) +(180:0.3) arc (180:120:0.3);
\fill [help lines] (q) circle (0.05);
\draw [dotted] (0,-4) -- (10,-4);
\begin{scope}[xshift=10mm,yshift=-40mm]
\draw plot [smooth] coordinates {
(0.00, 0.00)
(0.48, 0.89)
(0.90, 1.56)
(1.26, 1.98)
(1.56, 2.20)
(1.81, 2.25)
(2.01, 2.15)
(2.19, 1.93)
(2.33, 1.62)
(2.45, 1.21)
(2.56, 0.74)
(2.64, 0.21)
%(2.71,-0.37)
};
\draw [->] (2.64,0.21) -- (2.71,-0.37);
\coordinate (r) at (2.68,0);
\fill (r) circle (0.05);
\end{scope}
\end{tikzpicture}
}{Projectile trajectory with heavy air drag}

Second, notice how the angle with which the ball falls is nearly straight down. This is because the direction of the air drag is in the opposite direction of the motion. In the horizontal we have a deceleration without any corresponding acceleration. So \prep{the air drag slows down the horizontal motion. Of course it does the same to the vertical, but the vertical motion has \hide{gravity} to help out. What happens is that the projectile basically stops its lateral motion and falls downward at a steeper angle than it goes up.} Anyone who has played an outfield position in baseball can attest to the fact that catching a ball hit out that far usually involves looking nearly straight up to catch it.

This is the real motion of projectiles and is the main reason it was so difficult to determine the true motion of a projectile. In the Middle Ages it was thought that a quantity called \jargon{impetus} was transferred to the object when it was thrown. After that, the motion was considered to be in a straight line as this impetus was used up (kind of like a wind-up toy). After the impetus was exhausted, the object would fall straight down following a trajectory like a triangle. I like to call this a ``cartoon trajectory'' because this is how things work in the cartoons: the bad guy runs straight off the cliff for a while then, all of a sudden (usually with a puff of smoke), he falls straight down to his doom. The moral here is that there is more truth to the cartoon trajectory than the clean parabolic motion the textbooks show.

% Preview of next week

Next week we will introduce the key concept of force into our vocabulary. Before we dive into the deep end of Newton's laws of motion we start by building some skills working with forces and vectors. We will learn the basic mechanical forces (weight, tension, support, and friction) and how they work. We will also learn what it means for these forces to be in equilibrium.
========
04:equilibrium
--------
Force and Equilibrium
--------
Read sections 4.6--4.11, sneak a peak at sections 10.1, 18.5, 21.2, and review Lecture \ref{ch:vectors}
--------
% Definition of force, pressure, torque, and stress

When an object is subject to a force there are four physical quantities to distinguish: the net force, torque, stress and pressure. Technically, pressure can be seen as a special case of stress, but we'll set that consideration aside for now.

Force is the total amount of push or pull to which our object is subjected. The \jargon{pressure} is the force divided by the area across which it is applied. This is why the swami can lie of a bed of nails without getting hurt. The force of his weight is distributed, so that the pressure of support from any single nail is insufficient to pierce the skin. We won't need the concept of pressure again until Lectures \ref{ch:elasticity} and \ref{ch:fluids}. We will assume that any force is applied at a particular point on the object. Just recognize that this is an approximation: every real force is applied over a certain area.

Consider an object that is subject to a variety of forces all applied at different points. \prep{Each of these forces will have a tendency to do three things: (1) push the object in the direction of the force, (2) twist the object around its \hide{center of mass}, and (3) deform the shape of the object.}

If the direction of the force is precisely toward or away from the center of mass this force will not produce any kind of twisting or rotation. Otherwise the force is said to produce \jargon{torque} which will be discussed in detail in Lecture \ref{ch:torque}.

\prep{An object is said to be in \jargon{equilibrium} when all the forces and \hide{torques} balance out.} However, even if the object is in equilibrium it may still suffer deformation as a result of these forces. The amount of deformation is quantified by \jargon{strain} and the combination of forces causing this strain is called \jargon{stress}. We will talk a bit about these concepts in Lecture \ref{ch:elasticity} on elasticity. As you can guess, the details can get pretty hairy so we will only cover the high points.

For now we will ignore all of these issues. If we focus our attention on physical systems with negligible configuration (i.e., a particle) then there is no deformation to consider. In fact, the system has no extension, so the idea of torque doesn't even apply. All we are left with is the simpler notion of force and its effects.

% Vector review and examples of equilibrium

Obviously an object subject to a single force cannot be in equilibrium. We need two or more forces and they need to balance. Two forces must be equal and opposite in order to create equilibrium. In vector notation we may say:
$$\vect{F}_1 + \vect{F}_2 = 0$$
Because of the way we have defined vectors in Lecture \ref{ch:vectors}, this same formula works for an arbitrary number of forces:
$$\sum \vect{F}_i = 0$$
Here the summation is implied to run over all the values of $i$. If there are four forces then the summation is a shorthand for
$$\vect{F}_1 + \vect{F}_2 + \vect{F}_3 + \vect{F}_4 = 0$$
If necessary we may put a subscript on the summation symbol for clarity:
$$\sum_i \vect{F}_i = 0$$
or even more explicitly:
$$\sum_{i=1}^4 \vect{F}_i = 0$$
But I'll usually be sloppy about this notation unless it is likely to cause confusion.

We walked through a typical force equilibrium problem in Lecture \ref{ch:vectors}. It might be worth reviewing that example now (see page \pageref{ex:three-forces}).

There are also different kinds of equilibrium: stable versus unstable. When forces vary in time, the equilibrium they create may be destroyed. Typically the forces in a system depend upon its configuration (usually the distance between its parts). So, any motion in the system can change these forces. \prep{If these forces are such that any \hide{displacement} tends to cause the system to return to equilibrium, this is \jargon{stable equilibrium}.} A simple example is a marble in a bowl. If we displace the marble away from the center of the bowl it will be pushed back to center. Turn the bowl upside-down and you have \jargon{unstable equilibrium}. A pencil standing on it's point is another example. You may have seen a person holding a broom upside-down with the palm of their hand. This is an example of \jargon{dynamic equilibrium}. In this case the forces are not dependent on the configuration but on a feedback loop (i.e., the person doing the balancing). Dynamic equilibrium is often used to combat unstable equilibrium, but if one is not careful it can lead to literally explosive results.

For now we only consider forces that are constant. So if they are in equilibrium they will remain that way.

There is one other point to make regarding equilibrium. \prep{No net force on a object does not imply that the object is stationary. What it implies is that the acceleration is zero---the object may be moving with \hide{constant velocity}.} We saw an example of this with air drag and terminal velocity in Lecture \ref{ch:kinematics}. Although it is not common to make this distinction, it may be worth calling equilibrium on a moving object \jargon{kinetic equilibrium} as opposed to \jargon{static equilibrium} for an object at rest.

% Mechanical forces: weight

In our inventory of mechanical forces to consider, the simplest is \jargon{weight}.\footnote{Our book discusses weight in the context of the Newton's law of gravity (section 4.7). I prefer to wait and talk about the law of gravity in Lecture \ref{ch:circular-motion}.} In the English system of units the pound is a primary unit. However, the influence of gravity can vary slightly depending on where you are on the surface of the planet. This means that the weight will vary as well. In the metric system, mass is primary and weight is secondary. Mass is a difficult quantity to define precisely without using Newton's laws (to be discussed in the next lecture). However, the weight of an object is simply related to its mass via
$$W = mg$$
If the gravitational acceleration increases slightly so does the weight. The SI unit for weight is called the \jargon{newton} and the metric unit for mass is the \jargon{kilogram}. Under standard earth gravity, a one kilogram mass will weigh about 9.8 newtons which is equivalent to about 2.2 pounds.

% Mechanical forces: tension

\label{ex:block-and-tackle}

Tension will come up again when we discuss elasticity in Lecture \ref{ch:elasticity}, but for now we only consider it in the context of an \jargon{ideal string}. A string is ideal if it has negligible weight and does not stretch at all. A string like this essentially transmits the force from one end to the other. Combine this with an \jargon{ideal pulley} (friction-less, negligible mass) and you can create a block-and-tackle. Take for example Figure \ref{fig:block-and-tackle}. Notice how the larger weight is supported by two strings. But the two strings are really the same string, so the force that supports the weight is actually the tension multiplied by two. The tension is in balance with the smaller weight. This block-and-tackle system essentially multiplies force by two. This is called the \jargon{mechanical advantage} of the system. Actually, this is the ideal mechanical advantage. The true mechanical advantage will take into account the friction and the masses of the pulleys and strings. In fact, \prep{the ratio of actual to ideal \hide{mechanical advantage} is called the \jargon{efficiency} of this simple machine.}

\tikzfig[side]{block-and-tackle}{
\begin{tikzpicture}
\draw (-0.2,-0.4) circle (0.2); 
\fill (-0.3,0) -- (-0.2,-0.4) -- (-0.1,0) -- cycle;

\draw (0.2,-2.4) circle (0.2); 
\fill (0.1,-2.8) -- (0.2,-2.4) -- (0.3,-2.8) -- cycle;
\draw (0.0,-2.8) rectangle (0.4,-3.2);
\draw (0.0,-3.2) rectangle (0.4,-3.6);

\fill (0.4,0) circle (0.1);
\draw (0.4,0) -- (0.4,-2.4);
\draw (0,-0.4) -- (0.0,-2.4);
\draw (-0.4,-0.4) -- (-0.4,-2.8);
\draw (-0.6,-2.8) rectangle (-0.2,-3.2);

\draw [fill=black!20] (-1,0) rectangle (1,0.2);
\end{tikzpicture}
}{Simple block and tackle with mechanical advantage of two}

% Mechanical forces: support

The third mechanical force we will consider is a \jargon{support force}. Put a 10 kilogram mass on the table. The table supports this mass by holding it up against its weight. \prep{This force of support is ultimately from elastic forces: the weight actually \hide{deforms} the surface of the table slightly.} The table resists this deformation with a support force. Understanding this is important because there is no ``formula'' that governs the support force---it is a reaction to the other forces in the problem. The magnitude of the support is simply that which is required to balance the forces against it.

These forces are sometimes called \jargon{constraint forces} because the surface that provides the support constrains the motion of the object. The motion can only occur parallel to the surface because the force resists any motion into the surface. I prefer to call them support forces because that seems to me to describe them best. However, it is much more common to call these \jargon{normal forces}. The reason for this is that in mathematical jargon the word ``normal'' means perpendicular and these forces always operate perpendicular to the surface doing the supporting.

\label{ex:plane-and-pulley}

A more involved example of the use of support forces in a problem is a weight supported by an inclined plane. Review Figure \ref{fig:plane-and-pulley}. Because the support is perpendicular to the slope of the plane, only a component is available to counter-balance the weight. The remaining component wants to push the block down the slope. However, the tension in the string tied to the smaller mass holds it back. This tension is coming from the weight of the smaller mass pulling down across the pulley. If the masses are in the right combination, these forces will balance in equilibrium.

\tikzfig[side]{plane-and-pulley}{
\begin{tikzpicture}
\draw (0,0) -| (30:6) -- cycle;
\draw (0.5,0) arc (0:30:0.5);
\node at (13:1) {$30\dg$};
\draw (30:6) -- (5.4,3.35);
\draw (5.4,3.35) circle (0.2);

\draw (5.6,3.35) -- (5.6,1.0);
\draw (5.32,1.0) rectangle +(0.56,-0.56);

\begin{scope}[rotate=30]
\draw (3.5,0) rectangle +(-0.8,0.8);
\draw (3.5,0.4) -- (6.4,0.4);
\node (t) at (3.6,0.4) [forcearrow,rotate=30,right,minimum height=10mm] {};
\node (n) at (3.1,0.9) [forcearrow,rotate=120,right,minimum height=17mm] {};
\end{scope}

\node (w) at ($(30:3.1)+(120:0.4)+(270:0.0)$) [forcearrow,rotate=270,right,minimum height=20mm] {};

\node at (w.east) [below=1mm] {Weight};
%\node at (t.north east) [above right,fill=white] {Tension};
\node at (t.south east) [right=1mm,fill=white] {Tension};
\node at (n.east) [above=1mm] {Support};
\end{tikzpicture}
}{Inclined plane with pulley}

I have redrawn these three forces in Figure \ref{fig:plane-and-pulley-free-body}. When we collect all the forces acting on one part of the system, it is called a \jargon{free-body diagram}. \prep{It is almost always best to align your coordinate system with any \hide{forces of constraint}.} Usually the constraints are the most difficult forces to calculate in a problem. By properly orienting the coordinates we can usually begin the calculation in the dimension perpendicular to the constraint to get more information before tackling the constraint itself. In fact, it is sometimes possible to solve a problem without even solving for the constraint.

In this case it is pretty simple. Notice how the components of the weight correspond exactly with the tension and support forces. This shows that the masses are in equilibrium.

\tikzfig[side]{plane-and-pulley-free-body}{
\begin{tikzpicture}[scale=2]
\begin{scope}[rotate=30]
\draw [->,dashed] (2.6,0.4) +(-1.5,0) -- +(1.5,0) node [right] {$x$};
\draw [->,dashed] (2.6,0.4) +(0,-1.5) -- +(0,1.5) node [above] {$y$};

%\draw [help lines] (3.0,0) rectangle +(-0.8,0.8);
\node (t) at (2.6,0.4) [forcearrow,rotate=30,right,minimum height=20mm] {};
\node (n) at (2.6,0.4) [forcearrow,rotate=120,right,minimum height=34mm] {};
\draw [dotted] (2.6,0.4) rectangle +(0.5,0.85);
\draw [dotted] (2.6,0.4) rectangle +(-0.5,-0.85);
\end{scope}
\node (w) at ($(30:2.6)+(120:0.4)$) [forcearrow,rotate=270,right,minimum height=40mm] {};

\node at (w.east) [below=1mm] {Weight};
\node at (t.east) [below right] {Tension};
\node at (n.east) [left=1mm] {Support};
\end{tikzpicture}
}{Free-body diagram from Figure \ref{fig:plane-and-pulley} (magnified 2x)}

If we call the larger mass \#2, the component of its weight that points down the plane to the left is given by
$$W_2 \sin 30\dg = 0.500 W_2$$
This must equal the tension in the rope and that tension equals the weight of the smaller mass (which we will call \#1). We have $0.500 W_2 = W_1$. The ideal mechanical advantage of this inclined plane is two. This can be seen by 
$$MA = W_2 / W_1 = 2$$
In general, the ideal mechanical advantage of the inclined place is given by $1/\sin \theta$.

% Mechanical forces: friction

The fourth mechanical force to consider is friction which occurs whenever two surfaces are in contact. The amount of friction depends on two factors: (1) the amount of support force that is pressing them together, and (2) the nature of the two surfaces in contact. The effect of the second factor is captured in the \jargon{coefficient of friction} and is given the symbol $\mu$. Its value is between 0 and 1. The formula for friction is\footnote{This is our first example of an \href{http://en.wikipedia.org/wiki/Constitutive_equation}{\jargon{constitutive equation}}. I mentioned in the first lecture about how one of the roles of the deductive approach is to explain from first principles the values obtained for equalities such as these. This one, however, is nearly impossible and is dependent on a variety of factors. As such, these numbers for various combinations of surfaces can only be derived on average from the lab.}
$$F = \mu N$$

Now, there are two varieties of friction: static and kinetic. If the block is sliding, \jargon{kinetic friction} applies and the force is given by $F_k = \mu_k N$ where $\mu_k$ is the coefficient of kinetic friction. Remember that the forces on a moving object may still be in equilibrium (previously we called this kinetic equilibrium). \prep{You may encounter a homework problem or two where an object is \hide{sliding} at constant speed. In that case, you know two things: (1) the friction is kinetic and (2) the forces all balance.}

If the block is not sliding, then clearly the forces are in static equilibrium. In this case \prep{the \jargon{static friction} is whatever it needs to be to maintain balance---just like the support forces we studied earlier. However, the static friction has a \hide{maximum} value.} If the force required to maintain balance exceeds this maximum value, the block won't be able to resist moving. Thus, if the block is stationary we know the static friction is less than this maximum value. This upper bound is given by the formula $F_s \le \mu_s N$, where $\mu_s$ is the coefficient of static friction---a number greater than its kinetic cousin. 

\label{ex:plane-and-friction}

As an example, consider Figure \ref{fig:plane-and-friction}, which is essentially the same as Figure \ref{fig:plane-and-pulley} with the tension replaced by friction. We will assume that this object is in equilibrium, so the free body diagram is essentially the same as Figure \ref{fig:plane-and-pulley-free-body}. 

\tikzfig[side]{plane-and-friction}{
\begin{tikzpicture}
\draw (0,0) -| (30:6) -- cycle;
\draw (0.5,0) arc (0:30:0.5);
\node at (13:1) {$30\dg$};
%\draw (30:6) -- (5.4,3.35);
%\draw (5.4,3.35) circle (0.2);

%\draw (5.6,3.35) -- (5.6,1.0);
%\draw (5.32,1.0) rectangle +(0.56,-0.56);

\begin{scope}[rotate=30]
\draw (3.5,0) rectangle +(-0.8,0.8);
%\draw (3.5,0.4) -- (6.4,0.4);
\node (t) at (3.6,0.4) [forcearrow,rotate=30,right,minimum height=10mm] {};
\node (n) at (3.1,0.9) [forcearrow,rotate=120,right,minimum height=17mm] {};
\end{scope}

\node (w) at ($(30:3.1)+(120:0.4)+(270:0.0)$) [forcearrow,rotate=270,right,minimum height=20mm] {};

\node at (w.east) [below=1mm] {Weight};
\node at (t.north east) [above right,fill=white] {Friction};
\node at (n.east) [above=1mm] {Support};
\end{tikzpicture}
}{Inclined plane with friction}

Therefore the magnitude of the normal support force is equal to 
$$W \cos 30\dg = 0.866 W$$
and the magnitude of the friction force is equal to
$$W \sin 30\dg = 0.500 W$$
Since the static friction force is related to the support force according to $F_s \le \mu_s N$, we have a constraint placed upon the coefficient $\mu_s$:
$$\mu_s \ge 0.577$$
In other words, if the coefficient of static friction is less than 0.577 (in general, $1/\tan \theta$), the block will slide because there won't be enough static friction to hold it in place.

% What about the other forces?

This is the last constant mechanical force for us to consider. However, we will see more forces in the upcoming lectures. For example, in Lecture \ref{ch:elasticity} we will discover the formula for elastic forces. Truly, elastic forces are the cause of both tension and support, but in that lecture we will focus on the role of deformation in elasticity which we are neglecting here.

\prep{All of these forces that I've classified as ``mechanical'' (including elastic forces) require the objects to be \hide{in contact}. In contrast, gravity and the electromagnetic forces are \jargon{long-range} forces which act at a distance.} We will talk about the electric and magnetic forces in Lectures \ref{ch:electric-field} and \ref{ch:dc-and-magnetism}, respectively. The law for the electric force is quite similar to Newton's law of gravity which we will study in Lecture \ref{ch:circular-motion}. The magnetic force is unique in that it causes a deflection that is perpendicular to the motion of the particle. Using results from Lecture \ref{ch:circular-motion} we will see that this produces a characteristic spiral motion. This perpendicular deflection is also a characteristic of the Coriolis force we will mention in Lecture \ref{ch:rotation}.\footnote{There is a peculiar fascination with the distinction between contact forces and long-range forces in the history of physics. The long-range nature of gravity really bugged Newton: he called it ``occultish''. Prior to Newton, it was felt that any force had to be a contact force: for example, Descartes filled the solar system with a fluid that kept the planets in motion. As a consequence of the study of electromagnetism in the 19th century, a kind of middle ground was established: the force field. We say that space is filled with gravitational and electromagnetic fields which operate as media for the transmission of these forces. But the field is not mechanical---they obey laws of their own independent of mechanics. However, the modern development of quantum field theory has written a new chapter in the debate between long-range and contact forces which comes nearly full circle.}

In Lectures \ref{ch:nuclear-energy} and \ref{ch:high-energy} we will also encounter the existence of two nuclear forces. This is really a misnomer though because at that level we cannot avoid using quantum mechanics and the idea of force must be replaced with the more general notion of ``interaction''. We will lay the ground work for moving beyond force in Lectures \ref{ch:energy} and \ref{ch:momentum} when we talk about energy and momentum.

% Preview of next week

Next week we will introduce Newton's three laws of motion. The first law will cause us to consider reference frames in motion. We will find that if we are not careful choosing these frames we may introduce ``fictitious forces'' into the laws of motion. We will also see where Einstein's relativity touches the laws of motion. Newton's second law establishes the connection between force and acceleration alluded to in Lecture \ref{ch:kinematics}. Finally, the third law will introduce us to systems and the role of internal and external forces.
========
05:newtons-laws
--------
Newton's Laws of Motion
--------
Read sections 4.1--4.5 and 4.11, sneak a peak at sections 28.1--28.2
--------
% Newton's first law and inertia

\jargon[inertia]{Inertia} is the property of a system to maintain its state of motion. When an object is moving it has a tendency to keep moving. This is why you never want to stand in front of a moving train. This principle of inertia may seem obvious but it has not always been that way. The critical modern insight is to set aside the realities of friction and weight. Without this conceptual distinction, Aristotle taught that every object has its place. In other words, objects have an intrinsic tendency based on their composition to move until they come to rest in their place. Things made of earth fall down, things made of air float up.

Galileo was the first person to apply the idea of inertia to objects in motion in a quantitative way. He was able to see the central point that once an object is set in motion the only reason it stops is friction and that friction is external to the object. Whether it is dragging against air resistance or dragging across a surface, if this friction is eliminated there is nothing to stop the motion. In situations where the effect of friction is minimized (an icy road, a rolling ball) this inertia is more obvious.

\prep{This principle of \hide{inertia} is quantified in the notion of \jargon{mass}. If an object is in motion, the larger mass is harder to stop. This works in reverse too: the more massive an object, the more difficult it is to push it into motion.} If we decide on a particular object as our unit of mass we can measure the force required to get it to move at a particular rate. If twice the force is required to get a second object to move at the same rate, we say it has twice the mass. So mass measures the amount of resistance an object will have to changing its state of motion.

\jargon{Newton's first law} of motion is Galileo's principle of inertia. Newton's wording is as follows:
\begin{quote}
Every body perseveres in its state of rest, or of uniform motion in a right line, unless it is compelled to change that state by forces impressed thereon.
\end{quote}

When first exposed to this idea it is easy to associate it with something like pushing a box across the floor: when you start out, with just a small amount of force, the box does not move at all. Only after a certain critical level of pushing has been reached will the box move. This is not inertia. This is friction. It is better to think of the force required to stop an object in motion---this is tied to the idea of inertia more directly than considering the force required to start the motion.

% Moving frames and the principle of relativity

Galileo also recognized something we now call the \jargon{principle of relativity}.\footnote{Not the theory of relativity---that was Einstein. See Lecture \ref{ch:em-and-relativity}.} Imagine you are watching boats sail across a calm lake. There is a man hanging off the mast of a ship making repairs. The wrench he is holding slips and drops 30 feet straight down striking the base of the mast (we are going to ignore air drag). Since the wrench has a bright orange handle you see it clearly tumble down as the ship drifts across your field of view. But from your viewpoint, the path of the wrench is not straight but a parabola. Of course you agree that the wrench strikes the base of the mast, but to you the ship just happens to catch it on its way down.

Well, ``just happens'' is an overstatement because the reason the wrench is not falling straight down is that before it was dropped, it was moving with the drift velocity of the ship. The wrench continues to drift with this velocity while it undergoes acceleration downward due to gravity.

Here's the point: is the ship moving? Yes, you say, of course it is moving: it is drifting across the lake. What does the repairman say? Yes, he says, I can look out at the shore and see the ship is moving. Fine: everyone agrees. Later, below deck, he is eating lunch and drops his fork. The fork falls straight down like the wrench---is the ship moving? Yes, but without a reference frame tied to shore, the repairman cannot tell. All motion is always measured \emph{relative} to some reference frame. And this is the principle of relativity: within a reference frame moving with constant velocity, it is not possible to determine this drift velocity based on the relative observations made within that frame. The laws of physics are independent of the velocity of the frame.

This abstract symmetry is broken by the fact that we live on earth. \prep{There is a distinct up-and-down direction due to gravity and a distinct state of rest due to friction and air drag. But take away gravity and friction and you have this kind of free-fall world where the principle of \hide{relativity} rules.}\footnote{This is one of the reasons why a pool table is such a good place to learn physics. The horizontal nature of the table eliminates the effect of gravity and the balls roll so the effects of friction are minimized.}

There is a positive way to state the principle of relativity, too. Since the laws of physics work in any frame (moving with constant velocity), you are free to choose whichever you like as your rest frame. In fact, in order to do any kind of calculating, you must start by choosing this frame. The point is that the choice is arbitrary---there is no ``natural'' choice.

But not completely arbitrary. It may seem like the airplane is at rest when you are at cruising speed, but hit some turbulence and you're not at rest any more. \prep{The key is that the frame must move with constant velocity: no \hide{acceleration}. A reference frame in which Newton's first law holds is called an \jargon{inertial frame}.} Non-inertial frames like a car making a turn will have pushes and pulls which are due to the non-constant velocity (either speed or direction) of the frame. We use Newton's first law to identify an inertial frame. The principle of relativity implies that any frame moving relative to another inertial frame with constant velocity is also inertial.

% Newton's second law and acceleration

\jargon{Newton's second law} of motion presumes we are working in an inertial frame defined by the first law. According to Newton we have:
\begin{quote}
The alteration of motion is ever proportional to the motive force impressed; and is made in the direction of the right line in which that force is impressed.
\end{quote}

This is commonly written as 
\begin{equation} \label{n2l}
\vect{F} = m\vect{a}
\end{equation}
This formulation is due to \href{http://en.wikipedia.org/wiki/Leonhard_Euler}{Euler}.\footnote{Euler's contributions to both mathematics and physics are extensive. In a sense Euler completed Newton's laws by \href{http://en.wikipedia.org/wiki/Euler\%27s_laws}{extending them} to rigid objects---cf. Lectures \ref{ch:rotation} and \ref{ch:torque}.} Notice how neither acceleration nor mass are mentioned in Newton's formulation. He uses the phrase ``alteration of motion'' which may seem vague, but earlier he defined this ``quantity of motion'' as:
\begin{quote}
The quantity of motion is the measure of the same, arising from the velocity and quantity of matter conjointly.
\end{quote}
Today we use the term mass for ``quantity of matter'' and the ``quantity of motion'' we call momentum (see Lecture \ref{ch:momentum}). In other words, \prep{Newton's second law as originally formulated states that force changes \hide{momentum}.} Now if the mass of the object is constant, the part of the momentum that changes is the velocity, so this is equivalent to Euler's formulation. But if the mass is not constant (a rocket ship is a good example) the more general law based on momentum is needed. 

Unless otherwise stated, assume the mass is constant and use equation \eqref{n2l}.

If an object is under the influence of several forces, we need to calculate the vector sum of these forces to determine the direction of acceleration. Clearly \prep{the object can only move in one direction, so we need one \hide{net force} vector to put on the left side of the second law. This is often the most difficult part in solving these problems: identifying the forces and adding them up to some net force.} Of course, the forces may all balance. In this case the vector sum is zero. Accordingly equation \eqref{n2l} implies $\vect{a} = 0$, so the object in equilibrium will either move with constant velocity or remain at rest. You can see how the problems from the previous lecture are now a special case of the more general second law.

% Examples, examples, examples

\label{ex:atwood-machine}

\prep{Another way to express Newton's second law is that any \hide{unbalanced} force will produce acceleration.} This emphasizes the initial step of calculating the net force on an object. A classic example problem is the \jargon{Atwood machine} which is simply two weights hanging over a pulley (see Figure \ref{fig:atwood-machine}). Just by looking at the diagram you can see what will happen: the larger weight will drop but slower than normal because it will have to pull the smaller weight up. We now need to calculate the result.

\tikzfig[side]{atwood-machine}{
\begin{tikzpicture}
\draw (0,0) circle (0.5);
\draw (-1,0.6) -- (1,0.6);
\fill (-0.1,0.6) -- (0,0) -- (0.1,0.6);
\draw (-0.5,0) -- (-0.5,-2);
\draw (0.5,0) -- (0.5,-1.5);
\draw (-0.7,-2) rectangle (-0.3,-2.4);
\draw (0.8,-1.5) rectangle (0.2,-2.1);
\draw [->] (1.1,-2.0) -- (1.1,-1.6) node [pos=0.5,right] {$a$};
\draw [->] (-1,-2.0) -- (-1,-2.4) node [pos=0.5,left] {$a$};
\end{tikzpicture}
}{Atwood machine}

One important thing to realize here is that this is a system with two parts (three if you count the string). Each weight has a different net force acting on it and each weight corresponds to an application of equation \eqref{n2l}. Let's call the mass of the smaller weight $m$ and the mass of the larger weight $M$. Therefore the weight of each is $mg$ and $Mg$ respectively. 

The force that opposes the weight of each is the tension in the string, which we will label $T$ and it is equal on both sides. But recognize that the tension is undetermined---it is equal to neither the smaller nor larger weight. This is an easy mistake to make. I think this is because we draw the diagram and forget that it represents a snapshot in time---the objects are actually moving and the forces are out of balance. I try to draw a little arrow with an $a$ to remind myself the objects are accelerating.

So, we are ready to apply Newton's second law. This problem is simple so we will jump the result. We'll walk a bit more slowly in the next problem to show all the steps. From the smallest weight we have:
$$T - mg = ma$$
and from the larger weight we have:
$$T - Mg = -Ma$$
Notice the signs. You must be deliberate with the signs because these quantities are vectors. In both cases the tension from the string pulls up, so they get positive signs. Similarly the weights pull down, so they get negative signs. The smaller block will accelerate up so it is positive, and the larger block will accelerate down so it is negative. The magnitude of the acceleration of the two blocks are the same because they are tied together.

From a mathematical standpoint we have two equations with two unknowns ($T$ and $a$). This means we can solve for both. In order to solve for the acceleration we will use the first equation to eliminate the $T$ from the second. This yields
$$(ma + mg) - Mg = -Ma$$
Solving for $a$ gives
$$a = \frac{M - m}{M + m} \; g$$
It is sometimes helpful to look at some extreme cases as a double check. If $m = M$, then we have $a = 0$ which makes sense---the weights balance. If $m = 0$ then $a = g$ which also makes sense because if there is no smaller weight the larger will simply fall under the influence of gravity. Intermediate cases are in between, so this answer checks out.

\label{ex:plane-and-pulley-falling}

Now for a more complicated example. Examine the situation in Figure \ref{fig:plane-and-pulley-falling}. This is similar to Figure \ref{fig:plane-and-pulley}, but the hanging weight is smaller (and the tension is less) so the larger mass will slide to the left. Suppose the larger mass is 10 kilograms and the smaller mass is 3 kilograms. How long will it take the block to slide down the incline from rest if the plane is one meter long? What will be its final velocity?

\tikzfig[side]{plane-and-pulley-falling}{
\begin{tikzpicture}[scale=0.9]
\draw (0,0) -| (30:6) -- cycle;
\draw (0.5,0) arc (0:30:0.5);
\node at (13:1) {$30\dg$};
\draw (30:6) -- (5.4,3.35);
\draw (5.4,3.35) circle (0.2);

\draw (5.6,3.35) -- (5.6,1.0);
\draw (5.4,1.0) rectangle +(0.4,-0.4);
\draw [->] (6.0,0.8) -- (6.0,1.3) node [above] {$a$};

\begin{scope}[rotate=30]
\draw (3.5,0) rectangle +(-0.8,0.8);
\draw (3.5,0.4) -- (6.4,0.4);
\node (t) at (3.6,0.4) [forcearrow,rotate=30,right,minimum height=7mm] {};
\node (n) at (3.1,0.9) [forcearrow,rotate=120,right,minimum height=17mm] {};
\draw [->] (2.5,0.4) -- (2.0,0.4) node [left] {$a$};
\end{scope}

\node (w) at ($(30:3.1)+(120:0.4)+(270:0.0)$) [forcearrow,rotate=270,right,minimum height=20mm] {};

\node at (w.east) [below=1mm] {Weight};
%\node at (t.north east) [above right,fill=white] {Tension};
\node at (t.south east) [right=2mm,fill=white] {Tension};
\node at (n.east) [above=1mm] {Support};
\end{tikzpicture}
}{Inclined slide with pulley}

\prep{The first step in any of these problems is to draw a good \hide{free-body diagram} for each piece of the system.} Fortunately for me we have already done this in the Lecture \ref{ch:equilibrium} (see page \pageref{ex:plane-and-pulley}) except that the tension is a bit smaller now. In this problem the tension is not equal to the smaller weight because the forces are not in balance. In fact we know that the tension is larger than the smaller weight because it will need to lift the smaller weight up as the larger mass slides down the incline. The situation on this smaller mass is similar to the previous example, so we have
$$T - mg = ma$$
just as before. This gives us a formula for tension, $T = m(a + g)$, which we can use in the analysis of the motion of the larger mass.

Looking back at the free body diagram in Figure \ref{fig:plane-and-pulley}, we can see that the tension opposes the $x$-component of the weight. We know that these will not balance, but we can still use Newton's second law. In this case, the weight is 98 newtons. The $x$-component of the weight in this inclined coordinate system is
$$W_x = (98)(\cos 240\dg) = -49$$
The 240$\dg$ is measured from the positive $x$-direction. The sign of this component is negative because it points to the left. Notice how the positive $x$-direction for our coordinate system is pointing up the incline. This also means we should expect the acceleration of the larger block to be negative.

So, from the $x$-component of the larger mass we have
$$-49 + (3)(a + 9.8) = (10)(-a)$$
which we can solve for $a$. Thus,
$$a = 1.5077$$
We have not yet answered the question, however. We were asked about time and final velocity. We were given the initial velocity (``at rest'') and the displacement, so we should consider using equation \eqref{pos-ini-vel} to get the time. Thus,
$$(-1) = (0)(t) + \half (-1.5077)(t)^2$$
The negative signs are there because the motion is to the left. The final answer is 1.15 seconds. In order to determine the final velocity, we use equation \eqref{pos-vel-sqr}. Solving yields 1.74 meters per second.

The various combination of possible problems are endless. Add friction into the mix and you have a really hard problem. But in each case the procedure is the same. Focus first on getting the acceleration of the objects by applying Newton's second law. Thus,
\begin{enum}
\item Identify all the forces in play.
\item Draw a free-body diagram for each part of the system (remember to align your coordinates along any natural constraint).
\item Determine the components of the net force in each diagram.
\end{enum}
Each part and each dimension will yield an equation via Newton's second law. Sometimes you won't need all of these equations but they are all valid. Once you have the formulas, calculate the acceleration of the objects.\footnote{If the system has multiple parts usually the accelerations are the same, but sometimes not---the parts of a block and tackle systems will not have the same acceleration, for example.} From there use the techniques from Lecture \ref{ch:kinematics} to answer the specific question.

% On inertial frames and inertial forces

So far we have used Newton's law to calculate acceleration given a certain set of forces. The process can work the other way too. We can investigate the character of a force from the acceleration it causes on the objects it influences. For example, we can do experiments with static electricity do determine the way that the electric force is dependent upon distance.

One interesting example of using the second law this way is in dealing with \jargon{inertial forces}. I have said before how the second law is only valid in an inertial frame. So a particle free from the influence of outside forces will move in a straight line at constant speed. If we are in a non-inertial frame, the frame will move underneath the force-free particle. From the point of view of someone tied to the frame, the particle will experience an acceleration. Being a good student of Newton, this person would be led to postulate the existence of some force that causes this acceleration. However, this force is not due to outside forces but is an artifact of the non-inertial frame. This is why these kind of ``forces'' are called fictitious forces.

The most common example of such is the \jargon{centrifugal force}. If you stand on a merry-go-round you will feel a force that wants to fling you off---out from the center of rotation. Your inertia is propelling you in a straight line which, relative to the rotating merry-go-round, is out. You must overcome your inertia by pushing in to stay on the rotating frame. You interpret this as counter-balancing some centrifugal force. \prep{But this centrifugal force has no source: no object is pulling you out. It is merely a manifestation of the principle of \hide{inertia}.}

\prep{These inertial forces are always proportional to the \hide{mass} of the object. This is because they are enforcing the principle of inertia.} The greater the mass of an object, the larger its inertia. These forces always take the form $ma$ from equation \eqref{n2l}, so that the resulting acceleration is independent of the object. This is because the acceleration is due to the nature of frame rather than the object. Another way to recognize an inertial force is that it will disappear if the right frame of reference is chosen. These frames are precisely the inertial frames we talked about earlier.

Notice that gravity has these same qualities. We infer the force of gravity from the acceleration we see in falling objects. This acceleration is independent of the object. The force of weight is given by the formula $mg$. The fact that the mass which appears in the weight formula is the same as the inertia that appears in Newton's second law is called the \jargon{equivalence principle}. When Einstein went looking for a place to rebuild a new theory of gravity consistent with relativity, he started with this principle. He imagined a physicist in a falling elevator. In this frame, gravity would appear to be turned off. Therefore, a reference frame accelerating in free-fall is actually an inertial frame of reference. This thought experiment only works for a small space (for instance, you can't find a frame that will ``turn off'' gravity for the whole planet), but that was enough of a starting point to build the general theory of relativity.

% Newton's third law and interacting systems

\jargon{Newton's third law} of motion is often a bit confusing because the context is different than the first two. In the first two laws we deal with a single particle. Even when we used the second law to analyze a system, the second law only applies for one part at a time. The third law deals with pairs of particles. Newton sez\ldots
\begin{quote}
To every action there is always opposed an equal reaction: or the mutual actions of two bodies upon each other are always equal, and directed to contrary parts.
\end{quote}
Until now we have discussed forces that come from outside. Now we talk about forces internal to the system of particles---forces of interaction. The third law is telling us that every interaction in nature involves an equal and opposite pair of forces. It is a statement about the nature of force itself.

In practice, the third law is not very helpful. It's one of those things that make the whole conceptual structure work, but the hard work is done by the second law. It does imply something that is very important however. \prep{Since every force changes momentum and every interaction involves equal and opposite forces, every interaction involves equal and opposite changes in momentum. In other words, we can conceive of the \hide{interaction} as consisting in the \emph{exchange} of momentum.} This viewpoint forms a perfect compliment to the idea of energy and we will explore this perspective more in Lectures \ref{ch:energy} and \ref{ch:momentum}.\footnote{It is also a key element of quantum field theory---see Lecture \ref{ch:quantum-mechanics}.}

% Preview of next week

But for now we will stick with Newton's laws for a bit. Next week we will explore our first non-constant force: the force required to maintain circular motion. We will talk a bit about circles and the velocity and acceleration involved in circular motion. This will lead into the idea of centripetal force. We will discover that the force of gravity which holds the planets in place is also centripetal. Newton's law of gravity will be introduced and we do some prep work for the Lecture \ref{ch:celestial-mechanics} on celestial mechanics.
========
06:circular-motion
--------
Circular Motion and Gravity
--------
Read sections 5.1--5.5, review section 4.7, and sneak a peak at sections 10.1--10.2
--------
% The magic of circles and cycles

The ancient Greeks had a love affair with circles and spheres. These are the only shapes that can change without changing. Looking out at the night sky, they imagined astronomically large transparent spheres spinning around the earth. In each was lodged a planet which rotated with them like a embedded jewel.

Though we no longer think that way about the night skies, there is still something magical about the circle. We can talk about the paradoxical ratio $\pi$, the complications of abstract geometry, or complex numbers---behind every cycle in nature is a circle waiting to be found. We will exploit this fact in Lecture \ref{ch:harmonic-motion} when we talk about simple harmonic motion. But for now we will talk about some basics.

% Uniform circular motion defined (foreshadows simple harmonic motion)

The most important point of the circle is not on the circle: its center. The circumference is related to the radius of the circle by $C = 2\pi r$. So \prep{the average speed of an object rotating in a circle is given by $v = 2\pi r / T$ where $T$ represents the amount of time required to complete one \hide{cycle} which we call its \jargon{period}.} We will call the motion \jargon{uniform circular motion} if the speed has this average value the whole time.

We will normally talk about uniform circular motion in the context of a full circle, but it does not have to be that way. A car making a right turn can move with uniform circular motion for a quarter of a circle. The results from this lecture will be applicable to that motion as well. Whenever a path is curved that curvature can be characterized by a circle with the same curvature. Since the circle is characterized by its radius, \prep{we can quantify this curvature by its \jargon{radius of curvature}. The \hide{smaller} the radius of curvature, the tighter the curvature of the path.}\footnote{In fact, the curvature is related to the reciprocal of the second derivative of the path. One way to see this is that the first derivative is related to the slope or direction of the path. The second derivative will quantify how much this slope or direction changes.}

% Acceleration required for uniform circular motion

\prep{We know from the principle of inertia that circular motion cannot be maintained without a \hide{force}.} It would be helpful to know what acceleration is required to maintain a particular state of uniform circular motion. The formula
\begin{equation} \label{ucm}
a = v^2 / r
\end{equation}
can be derived by comparing the velocity vectors at two different points in the motion. See Figure \ref{fig:ucm}. By definition, the acceleration is the difference between these two velocity vectors divided by the time it takes to get between them. These three vectors form a triangle. In the meantime, the radius vector that sweeps from one point to the other also forms a triangle. The other side of this triangle is almost the same as the arc-length of the circle traveled.\footnote{This approximation becomes better the smaller the duration involved.} These two triangles are similar, so the ratio of the sides are equal. In particular
$$\frac{at}{v} = \frac{vt}{r}$$ 
From this formula equation \eqref{ucm} follows directly. These considerations also show the direction of the required acceleration: toward the center of the circle.

\tikzfig[side]{ucm}{
\begin{tikzpicture}[scale=0.9]

\clip (-0.5,-1) rectangle (5.5,3);
\draw (0,0) circle (2.5);

\begin{scope}[rotate=-90]
\fill (0,2.5) circle (0.05);
\node at (0.25,1.25) {$r$};
\draw [->] (0,2.5) -- +(-1.5,0);
\node at (-0.75,2.8) {$\vect{v}_0$};
\coordinate (v0) at (0,2.5);
\end{scope}
\begin{scope}[rotate=-30]
\fill (0,2.5) circle (0.05);
\node at (-0.20,1.25) {$r$};
\draw [->] (0,2.5) -- +(-1.5,0);
\node at (-0.75,2.8) {$\vect{v}$};
\coordinate (v1) at (0,2.5);
\end{scope}

\draw [fill=black,fill opacity=0.1] (0,0) -- (v0) -- (v1) -- cycle;

\node at (30:0.5) {$\theta$};

\begin{scope}[xshift=2cm,yshift=1.1cm]
\begin{scope}[rotate=-90]
\coordinate (0) at (0,2.5);
\draw [->] (0,2.5) -- +(-1.5,0);
\node at (-0.75,2.8) {$\vect{v}_0$};
\coordinate (v0) at (-1.5,2.5);
\end{scope}
\begin{scope}[xshift=1.25cm,yshift=-2.165cm]
\begin{scope}[rotate=-30]
\draw [->] (0,2.5) -- +(-1.5,0);
\node at (-0.75,2.25) {$\vect{v}$};
\coordinate (v1) at (-1.5,2.5);
\end{scope}
\end{scope}
\end{scope}

\draw [help lines,dashed] (30:0.8) -- (30:3.5);
\draw [->,very thick] (v0) -- node [above=1mm] {$\vect{a}t$} (v1);
\fill [black,fill opacity=0.1] (0) -- (v0) -- (v1) -- cycle;
\node at ($(4.5,1.1)+(120:0.5)$) {$\theta$};
%\node [forcearrow,rotate=210] at (30:2.5) {};

\node [left] at (5,3.5) {$\vect{v} = \vect{v}_0 + \vect{a}t$};

\end{tikzpicture}
}{Acceleration required for uniform circular motion}

% Confusion about centripetal forces, examples (eg. magnetic spirals)

So any force that is going to produce this motion will need to be equal to $mv^2 / r$. You will often see the equation
\begin{equation} \label{centripetal-force}
F_\text{cent} = \frac{mv^2}{r}
\end{equation}
There is nothing wrong with this equation, \foreign{per se}. It just gives the wrong impression like we have discovered a new fundamental force. No, what this formula represents is the net force required to maintain uniform circular motion. You see, we are working backwards relative to the work we did in the previous lecture. Previously we had the forces and inquired concerning the motion. But now \prep{we have a preconceived motion and want to know the constraint on the net force producing this motion. For \hide{uniform} circular motion this net force is called \jargon{centripetal force}.}

\label{ex:banked-slide}

For example, suppose we have a twisting slide and we want to know at what angle to bank the curve. Let's also suppose the typical velocity of the person on the slide is 10 meters per second and we want the radius of curvature to be 5 meters. In this problem there are two forces: the weight of the person and the normal support force from the slide. See Figure \ref{fig:banked-slide}. Where is the centripetal force? It is the net force from these two that causes the circular motion. 

\tikzfig[side]{banked-slide}{
\begin{tikzpicture}
\draw (2,-1) -- (-2,-1) -- (2,1);
\draw [->,dashed] (-2.5,0) -- (2.5,0) node [right] {$x$};
\draw [->,dashed] (0,-3) -- (0,3) node [above] {$y$};
\fill (0,0) circle (0.2);
\draw (-1.5,-1) arc (0:26:0.5);
\node at ($(-2,-1)+(13:1)$) {$\theta$};
\node (w) [forcearrow,right,rotate=270,minimum height=40mm] at (0,0) {};
\node (n) [forcearrow,right,rotate=116,minimum height=45mm] at (0,0) {};
\node (c) [forcearrow,right,rotate=180,minimum height=20mm,fill opacity=0] at (0,0) {};
\node at (w.east) [below,fill=white] {$W = mg$};
\node at (n.east) [above,fill=white] {$N$};
\node at (c.east) [left,fill=white] {$F_\text{cent}$};
%\node (n2) [forcearrow,right,rotate=90,minimum height=40mm,fill opacity=0] at (0,0) {};
\draw [dotted] (0,0) rectangle (-1,2);
\end{tikzpicture}
}{Slide banked to produce uniform circular motion}

In this problem, the centripetal force is coming from the $x$-component of the support force. The $y$-component balances the weight. How do I know they balance? Because the net force is horizontal. I have aligned the coordinates with the motion of the system.\footnote{This may look like an exception to the rule of aligning the coordinates with the constraint. Perhaps it is, but the point is you want to align them in order to make the math simple. In this case it is simpler to align it with the centripetal force. You can set the coordinates up however you want. Sometimes you can't help it but usually you can set things up to avoid a bunch of spaghetti math.}

The angle the support force makes to vertical is the the same $\theta$ that the incline makes to horizontal. We know the $y$-component of the support is $mg$, and the two components are related to the tangent via
$$\tan \theta = N_y / N_x$$
So,
$$N_x = \frac{mg}{\tan \theta}$$
The whole point was to set this horizontal force equal to $mv^2 / r$. Therefore
$$\frac{mv^2}{r} = \frac{mg}{\tan \theta}$$
Notice how the mass cancels from both sides, so the angle of incline does not depend on the mass. We know all the rest of these variables, so we can solve for $\theta$. We get
$$\theta = \tan^{-1}(gr/v^2) = 26.1\dg$$

As another example, consider an ion traveling in a magnetic field. We will find in Lecture \ref{ch:dc-and-magnetism} that there is a magnetic force proportional and perpendicular to its velocity. Because the force is perpendicular it deflects the path without changing its speed. The path of particle is circular. The magnetic force is given by $F = qvB$ where $q$ is the charge of the ion, $v$ is its speed, and $B$ is the strength of the magnetic field. The radius of the circular path can be determined by setting this equal to $mv^2 / r$ and solving for $r$. One gets
$$r = \frac{mv}{qB}$$
If the particle comes in at an angle oblique to the magnetic field, the component of the velocity parallel will be unaffected so the particle actually spirals up or down the field. 

This happens in the earth's magnetic field. The solar wind is composed of ions of hydrogen. When they enter the earth's magnetic field they begin a spiraling motion and are funneled along the magnetic field lines. As they get closer to the poles, the magnetic field becomes more dense and the radius of the spiral decreases. The collision of these particles with the atmosphere causes the \href{http://en.wikipedia.org/wiki/Aurora_\%28astronomy\%29}{Aurora Borealis}, more commonly known as the northern lights.

% The inverse square law of gravity

\prep{We know that every particle in uniform circular motion does so because it is under the influence of a \hide{centripetal} force of some sort.} This also applies to the solar system. Now, even to the ancient Greeks \href{http://en.wikipedia.org/wiki/Epicycle}{it was known} that the planets do not orbit around the sun in a perfect circle.\footnote{Mercury and Mars have the least circular orbits of the eight planets in the solar system.} But once the transparent spheres were definitively shattered by Galileo, the nature of the centripetal force holding the planets in place came into question. \prep{By Newton's time it was a common assumption that this force obeyed an \hide{inverse-square} law. That is, the force of gravity between two objects is inversely proportional to the distance between them. What Newton did was to prove it.}

The application of Newton's laws of motion to the motion of the the planets dominates the \src{Principia}. Along with his three laws of motion, he lays out the universal \jargon{law of gravity} as 
\begin{equation} \label{n4l}
F = \frac{GMm}{r^2}
\end{equation}
We will limit ourselves to the special case when $M \gg m$ though Newton himself did not. This means that the larger mass $M$ is basically unaffected by the motion of the smaller mass $m$. The value of $G$ is a universal constant characterizing the force of gravity. In SI units it has a value of $\sci{6.673}{-11}$.

% Polar coordinates

For Newton the force of gravity was the archetypal centripetal force. However, for him the term meant something different than it does for us. We reserve the notion of centripetal force for that associated with circular motion. \prep{For Newton a centripetal force was any force whose direction was always toward a particular \hide{point} in space. Today we would use the term a \jargon{central force} to describe such a thing. So we say that gravity is a central force.}

For any central force it makes sense to describe motion in terms of \jargon{polar coordinates}. In polar coordinates we describe the location of an object by its distance from a particular point in space and its angle from a particular line from that point. This is an example of a non-Cartesian coordinate system that can be helpful in the analysis of orbital mechanics. Compare the systems in Figure \ref{fig:polar-grid}. We will mention this again in the Lecture \ref{ch:celestial-mechanics}.

\tikzfig[side]{polar-grid}{
\begin{tikzpicture}
\begin{scope}[yshift=25mm]
%\clip (-2.2,-2.2) rectangle (2.2,2.2);
\draw [dashed,gray] (-1.9,-1.9) grid (1.9,1.9);
\draw [->] (-2.1,0) -- (2.1,0) node [right] {$x$};
\draw [->] (0,-2.1) -- (0,2.1) node [above] {$y$};
\end{scope}

\begin{scope}[yshift=-25mm]
%\clip (-2.2,-2.2) rectangle (2.2,2.2);
\draw [dashed,gray] (0,0) circle (1);
\draw [dashed,gray] (0,0) circle (2);
\foreach \q in {30,60,...,330} \draw [dashed,gray] (0,0) -- (\q:2.5);
\fill [white] (0,0) circle (0.15);
\fill (0,0) circle (0.1);
\draw [->] (0,0) -- (2.2,0) node [right] {$r$};
\draw [->] (0:1.25) arc (0:45:1.25) node [above right] {$\theta$};
\end{scope}
\end{tikzpicture}
}{Cartesian versus polar coordinates}

% Kepler's laws

A generation before Newton, \href{http://en.wikipedia.org/wiki/Kepler}{Kepler} had painstakingly examined the best known astronomical data of his day (mostly from the study of the motion of Mars). He was able to distill their pattern into what is now known as \href{http://en.wikipedia.org/wiki/Kepler's_laws}{\jargon{Kepler's three laws}} of planetary motion. They are:
\begin{enum}
\item The orbit of the planets are elliptical with the sun located at one of the foci.
\item The rate of area swept out by the line from the sun to the planet is constant.
\item The square of the orbital period is proportional to the cube of the radius of the orbit.
\end{enum}
\prep{It is easy to show that Kepler's \hide{third} law is a consequence of the law of gravity by simply setting the inverse-square law equal to $mv^2 / r$.} Thus,
$$\frac{GMm}{r^2} = \frac{mv^2}{r} \implies GM = rv^2$$
But the orbital period is related to the velocity by $v = 2\pi r / T$, so we have
\begin{equation} \label{123-law}
GMT^2 = 4\pi^2 r^3
\end{equation}
This is Kepler's third law.\footnote{In 1934 the analysis of the rate at galaxies spin was determined to violate Kepler's third law. The speed of the stars on the outer edges is much too fast. This implies that there is a lot more mass in the galaxies holding them together than can be inferred from the stars we see. This and other astronomical observations lead many to postulate the existence of \jargon{dark matter} in the universe (another way of dealing with the problem is to assert that the inverse-square law of gravity does not hold for these extreme distances). It's a bit embarrassing to admit that we have no clue about the composition of approximately 80\% of the known universe. See \href{http://en.wikipedia.org/wiki/Dark_matter}{here} for more info.} Newton was also able to show that the other two laws followed from the law of gravity, but those proofs are a bit more complicated.\footnote{In Lecture \ref{ch:celestial-mechanics} we will see how the second law follows from the central nature of the force of gravity}

\label{ex:geostationary-orbit}

\prep{Another example of the use of these formulas is in calculating \jargon{geostationary orbit}. This the distance in which a satellite will have an orbital \hide{period} of exactly one day.} This means that the satellite will simply remain overhead and is useful for communication satellites. Since there are 86,400 seconds in a day, we can calculate this orbit distance using Kepler's third law. For the earth we have $GM = \sci{3.99}{14}$, so
$$r = \sci{4.22}{7}$$
or 42,200 kilometers from the center of the earth. This corresponds to an altitude of 35,800 kilometers above sea level. \href{http://en.wikipedia.org/wiki/Gps\#System_segmentation}{GPS satellites} orbit at an altitude of 20,200 kilometers so they orbit about twice a day.

% Gravity and weight

\prep{Historically one of the great paradigm shifts in science occurred when Newton tied the concept of universal gravity to the common notion of \hide{weight}.} We can apply equation \eqref{n4l} to the surface of the earth. We know that the radius of the earth is 6380 kilometers. Therefore the force of gravity on the surface of the earth is
$$\frac{GMm}{r^2} = mg \implies g = \frac{GM}{r^2}$$
Plug in the numbers and you get our familiar 9.8 meters per second squared. This allows us to calculate the acceleration due to gravity on other planets. On the moon it's 1.6 meters per second squared. In this way Newton was able to unite motion in the heavens with motion on the earth.

% Preview for next week

Next week we will introduce the idea of energy. The concept is motivated by a study of the force-multiplying power of machines. We will see that, if we ignore friction, energy is a conserved quantity. The advantages of having a conserved quantity will allow us a much easier way to solve certain mechanical problems. We will find that energy comes in three basic forms: kinetic, potential, and heat. Finally, we will introduce the idea of least action.
========
07:energy
--------
Energy and Action
--------
Read sections 6.1--6.9
--------
% Machines, mechanical advantage and work

Back in Lecture \ref{ch:equilibrium} we touched on the idea of mechanical advantage. The purpose of any mechanical machine is to multiply the input force in order to create a much larger force for useful work. It is possible to break the analysis of a machine into components each connected together. These components are called \jargon{simple machines} and are traditionally classified as
\begin{items}
\item Lever 
\item Wheel and axle 
\item Pulley 
\item Inclined plane 
\item Wedge 
\item Screw 
\end{items} 
This list could be reduced to two: the lever and the inclined plane. The first three all operate based on a twisting motion around a pivot, while the second three operate based on splitting the support force that counter-balances a perpendicular force. We've already talked about the inclined plane on page \pageref{ex:plane-and-pulley}. We will talk about the lever again in Lecture \ref{ch:torque} with the idea of torque, but we will soon see in this lecture a different way to analyze the problem.

\prep{The multiplication of force from these machines is not without a cost. The cost is \hide{displacement}.} Refer back to the block-and-tackle system in Figure \ref{fig:block-and-tackle} for a moment. This system is in equilibrium, so the smaller block is supporting twice its weight. Now imagine you were to pull down the smaller block by 10 millimeters. Because of the way the pulleys and strings are set up the larger block will rise only 5 millimeters. So, the mechanical advantage of two corresponds to a two-fold reduction in the distance we can raise the weight. This implies that there is some sort of conservation happening here. The product of the weight and displacement is the same on the input and output (ignoring friction). This product we define as \jargon{work}.\footnote{Be careful not to confuse this technical definition with its looser English equivalent. Work is not synonymous with effort. In particular, if there is no movement there is no work done.} The SI unit is called the \jargon{joule} and is equivalent to the newton multiplied by the meter.

Now consider the lever in Figure \ref{fig:simple-lever}. The three blocks on the left are balanced by the one block on the right. But notice that the block on the right is three times the distance from the fulcrum as the three blocks on the left. Because of this, when the three blocks move down one millimeter the lone block will move up three. So a force that is on the right side must move the lever three times as far in order for its force to be multiplied three-fold on the left. Again the work is equal on both sides. This approach of analyzing the forces in a system by determining how a small displacement propagates through the system is called the principle of \jargon{virtual work}.

\tikzfig[side]{simple-lever}{
\begin{tikzpicture}
\fill (-0.1,-0.2) -- (0,0) -- (0.1,-0.2);
\draw (-1.5,0) -- (3.5,0);
\foreach \x in {-1,0,...,3} \draw (\x,-0.05) -- (\x,0);
\draw (-1.1,0) rectangle +(0.2,0.2);
\draw (-1.1,0.2) rectangle +(0.2,0.2);
\draw (-1.1,0.4) rectangle +(0.2,0.2);
\draw (3.1,0) rectangle +(-0.2,0.2);
\end{tikzpicture}
}{A simple lever}

Both force and displacement are vectors, so we need to say what we mean in the general case where they point in different directions. We only want to have the component of the force that contributes to the displacement considered. If $\theta$ represents the angle between the two vectors then we want to use the formula\footnote{We have already used the symbol $W$ for weight but we will now use it for work. This is a potential source of confusion. When they both appear in a problem, I will substitute $mg$ for the weight and use $W$ for work.}
\begin{equation} \label{dfn-work}
W = Fd \cos \theta
\end{equation}
Notice that work can be negative if the force opposes the displacement. 

You may remember the dot product I mentioned in Lecture \ref{ch:vectors}. We can use that to express this definition as $\vect{F} \cdot \vect{d}$. Note in particular that when the force and displacement are perpendicular, the work done is zero because that force does not contribute to the motion.

So for any simple machine the work done by the input force is equal to the work done by the output force. Chain them together and the same is true for a more complex compound machine. But there are always friction effects. The ratio of the output work to the input work is equivalent to what we have previously defined as the \jargon{efficiency} of the machine.

% Energy is the ability to do work, power is the rate at which it is done

The ability to do work is a valuable quality in any machine. Therefore, \prep{for any physical system we define this ability to do \hide{work} as its \jargon{energy}.} You should think of the energy of a system as a property of the system. Whenever a system does work on another system, this represents a transfer of energy from one to the other. The energy level of one decreases while the energy level of the other increases. 

\prep{It is sometimes overlooked that in the calculation of work, time is not a factor. It does not matter whether the displacement involved takes one second or one year, the physical work is \hide{identical}.} If we want to take the duration of the motion into account, we need a new quantity. We define \jargon{power} to be the rate at which a machine or an engine performs work. The SI unit of power is called the \jargon{watt}.

It can also be said that the work performed by a system is the amount of energy produced by it (and power is the rate of its production). Approaching the definition of energy this way gives it a priority over the notion of work. We will see that this subtle change in perspective offers a completely different way of approaching mechanics---a way that does not use the notion of force.

% Work and motion: kinetic energy defined

When a force is applied to a particle otherwise free, the particle increases in speed. The work done by a constant force to accelerate a particle up to a given final speed from can be derived from equation \eqref{pos-vel-sqr} and Newton's second law \eqref{n2l}. If we multiply the first by the mass $m$ and the second by the displacement $x$ we can combine them to yield 
$$W = Fd = mad = \half mv^2$$
This work done by the force increases the energy of the particle. Since this energy is manifest in motion we give it the name \jargon{kinetic energy}.\footnote{This is sometimes given the symbol $T$.} This means that any particle in motion has a certain amount of energy by virtue of this motion. Thus, we have derived a formula for this kinetic energy:\footnote{The subscript ``lin'' stands for linear. In Lecture \ref{ch:torque} we will see in kinetic energy due to rotation. Until then we will generally drop the subscript.}
\begin{equation} \label{kin-ene-lin}
KE_\text{lin} = \half mv^2
\end{equation}
When we explore the theory of relativity in Lecture \ref{ch:em-and-relativity} we will see a need to revise this formula for particle speeds approaching the speed of light.

% Work and equilibrium: potential energy defined

Work done on a system can manifest itself in a different way too. If a system is in stable equilibrium, its internal forces tend to pull it back to its equilibrium state. \prep{We do work against these \hide{internal} forces when we displace the system away from this equilibrium. When a system is pushed out of stable equilibrium in this way we say that it has \jargon{potential energy}.} The system has the ability to do work because when released its motion back to equilibrium can be leveraged to perform other useful work.

One simple but important example of creating potential energy is lifting a weight. In order to raise an object against the pull of gravity, a force must be provided that pushes up. This lifting force must do work against the force of weight. Its magnitude is $mg$ so the work done by the lifting force is $mgh$ where $h$ is the height of the lift. Therefore, we define the potential energy\footnote{This is sometimes given the symbol $U$.} of an elevated weight to be
\begin{equation} \label{pot-ene-wgt}
PE_\text{wgt} = mgh
\end{equation}
In general, the forces in a system are not constant. In these cases, we continue to define the potential energy as the amount of work required to move the system from equilibrium to the particular state of interest. In general, this calculation will involve some integral calculus.

Suppose we release the system and allow it to return to equilibrium. The work done by the system will be at the expense of its potential energy as it reverses the displacements required to create the non-equilibrium state. This work creates the kinetic energy involved in the motion of the system. \prep{In other words, the internal forces of equilibrium \hide{transform} the energy from potential into kinetic---the total sum of kinetic and potential energy is always the same.} This is the \jargon{conservation of energy}. Note that due to the way potential energy is defined, the total energy of an isolated system is conserved by definition. 

% Uses of the conservation of energy

Reconsider the example of the block sliding down an inclined plane in Figure \ref{fig:plane-and-pulley-falling} from page \pageref{ex:plane-and-pulley-falling}. Let us use energy considerations to determine the final speed.

In the initial state, the larger mass is elevated 0.5 meters. We know this because it slides done the slope one meter inclined at 30$\dg$. 
$$PE = mgh = (10)(9.8)(0.5) = 49$$
Since the system starts at rest, this is the only element of energy that is non-zero so the total initial energy of the system is 49 joules.

Now consider the final state of the system. The larger mass has released all of its potential energy. It still has some kinetic energy due to its motion, which we need to determine. So we have 
$$KE = \half mv^2 = (5)(v)^2$$
In addition, the smaller mass rises one meter, so it has some potential energy.
$$PE = mgh = (3)(9.8)(1) = 29.4$$
This mass is also moving with the same velocity as the larger mass. So it also has some kinetic energy:
$$KE = \half mv^2 = (1.5)(v)^2$$
This means that the final energy of the system is given by
$$E = 29.4 + (6.5)(v)^2$$

Since the total energy is conserved, we know that the energy level of the final state is still 49 joules. Setting our equation for the final energy of the system to 49 allows us to solve for $v$. We get an answer of $v = 1.74$ just as in the previous analysis.

Clearly this approach using energy is much simpler than the previous approach using force. This is a perfect example of the advantages in using energy. The disadvantage is that we cannot answer every mechanical question this way. For example, we do not know the direction of the velocity. Certainly we know from simply looking at the diagram, but not from the energy calculations. In addition, questions involving time and duration require going back to the analysis with force. But questions about displacement and speed are usually able to be answered in this way.

% Work and friction: conservative and non-conservative forces

So, work against inertia creates kinetic energy. Work against stable equilibrium creates potential energy. What about friction? Work against friction produces \jargon{heat}. We will study heat as a form of energy in Lectures \ref{ch:heat-temperature}--\ref{ch:thermodynamics}. Although it is not wrong to say that this is a third form of energy, it is should be emphasized that this form of energy is not interchangeable with the other two mechanical forms of energy. We will see that it is possible to recover some of this heat energy but for now we will simply consider it lost. We say that friction is a \jargon{non-conservative force} because it destroys rather than conserves mechanical energy.

Because the work that is done by a non-conservative force is lost there is no potential energy associated with it. \prep{The way to determine whether a force is \hide{conservative} or not is by calculating the work done on a round trip. If the total work done is zero, energy is conserved because all the work consumed by the system is eventually recovered.}

A corollary is that the work done to move a conservative system between two states is independent of the path taken. If the work were different we could combine the two paths to make a round trip with non-zero work. This is another way to determine if a force is conservative: the work depends only on the initial and final states of the system and not on what happens in between.

In summary, external forces and non-conservative internal forces change the total energy level of a system. Conservative internal forces convert the energy in the system from one form into another. \prep{So if we ignore \hide{friction}, we can say that energy is conserved in any isolated system.}

% Different perspectives: energy diagrams, phase space

Suppose we choose a particular state of the system as a reference point. The choice is arbitrary, but you will see that it makes sense to pick a point of stable equilibrium. If the forces in the system are conservative, when we calculate the work done to move to another state we know that this is equal to the potential energy of that state and that the number is unique---it does not depend on how we get from the reference state to the other state.

\prep{Formally we say that the potential energy is a function of the \hide{state} of the system. In the simplest case we have a particle under the influence of a conservative force which depends only upon its position.} Examples include the elastic force of a spring and the long-range force of gravity. For the force of gravity, the potential energy function is\footnote{Gravity is a bit of a special case because there is no natural equilibrium point to use as a reference. Instead we choose to use the point where the interaction is zero---which is infinitely far away. Because gravity is attractive it always takes work to get away. This is why the gravitational potential energy is always negative.}
\begin{equation} \label{n4l-potential}
PE_\text{grav} = -\frac{GMm}{r}
\end{equation}

A much simpler, almost trivial, example is the force of weight. Since the force is constant, the potential energy function is simply $mgh$. On a graph this is a straight line with a slope of $mg$, which is just the weight again. In general, we can recover the force from the potential energy by taking the derivative of the potential energy function:
$$F = -\frac{dU}{dx}$$
The negative sign is there because a system will always tend to release its potential energy unless some obstacle stands in the way.\footnote{If you rearrange this formula as $F \; dx = -dU$ it is easier to see how this formula is a corollary of the definition of potential energy.}

Consider the potential energy plot in Figure \ref{fig:energy-diagram}. The white dot represents a point of stable equilibrium and the $\times$ marks a point of unstable equilibrium. Remember that force points against the slope, so the system is always pushed in the direction that reduces its potential energy. At the point of stable equilibrium, the forces point in while the force point out at the point of unstable equilibrium.

\tikzfig{energy-diagram}
{
\begin{tikzpicture}
\draw [->] (0,0) -- (6,0) node [right] {$x$};
\draw [->] (0,0) -- (0,4) node [above] {$U$};
\draw [domain=0:6,samples=100] plot (\x,{0.2*(\x-1)*(\x-3)*(\x-5)+2});
%\draw [domain=0:6,samples=100,blue] plot (\x,{0.2*(\x^3-9*\x^2+23*\x-15)+2});
\coordinate (a) at (4.155,1.384); % stable equilibrium
\coordinate (b) at (1.845,2.616); % unstable equilibrium
\coordinate (c) at (2.500,2.375); % turning point, left
\coordinate (d) at (5.203,2.375); % turning point, right
\coordinate (e) at (0,2.375); % energy level
\draw [fill=white] (a) circle (0.1);
%\node at (a) [pin=225:{Stable equilibrium}] {};
\draw (b) +(0.1,0.1) -- +(-0.1,-0.1) +(-0.1,0.1) -- +(0.1,-0.1);
%\node at (b) [pin=-90:{Unstable equilibrium}] {};
\fill (c) circle (0.1);
%\node at (c) [pin=90:{Turning point}] {};
\fill (d) circle (0.1);
%\node at (d) [pin=90:{Turning point}] {};
\draw [dashed] (e) -- ($(e)+(6,0)$) node [pos=0,left] {$E$};
%\draw (c) -- (d);
\fill [fill opacity=0.1] (2.5,0) rectangle (5.203,5);
\draw (2.500,0) +(0,0.1) -- +(0,-0.1) node [below] {$x_0$};
\draw (5.203,0) +(0,0.1) -- +(0,-0.1) node [below] {$x_1$};
\end{tikzpicture}
}{An example of an energy diagram. The white circle and $\times$ mark points of stable and unstable equilibrium, respectively. The black dots represent turning points where the motion of the system reverses. Outside the shaded area is ``forbidden'' to the system because the kinetic energy cannot be negative.}

It is tempting to think of the energy diagram like a ball on a slope with the ball rolling down into the potential well. But the vertical axis represents the energy of the system. In this picture, the energy level is represented by the dashed line. If the energy is conserved, it is better to think of the system as shuttling back and forth on this dotted line.

Notice the black dots in the diagram. These are called \jargon{turning points}. Why? Remember that the graph represents the potential energy of the system. Since the dotted line represents the total energy, the gap in between the two must represent the kinetic energy. However, unlike potential energy, the kinetic energy can never be negative. This implies that the motion of the particle is constrained to be within the shaded region. The set of states for which the potential energy function exceeds the total energy of the system are ``forbidden'', and these areas are called the \jargon{forbidden regions} for the motion of the system. On the boundary of this forbidden region the potential energy equals the total energy and the kinetic energy equals zero.

What happens is this. Suppose the particle is moving toward a turning point. The force is opposing the motion because the slope is up in this direction. The kinetic energy of the particle is becoming smaller and smaller---it is slowing down. It does so until it reaches the turning point then, for a moment, it comes to rest. The force pushes it back and turns the motion around. This repeats over and over with the particle bouncing between the two turning points. In Lecture \ref{ch:harmonic-motion}, we will learn that small displacements about stable equilibrium always exhibit simple harmonic motion.

\label{ubiquity-of-stable-equilibrium}

\prep{We can take this one step further by incorporating a bit of friction. The effect of friction is to \hide{reduce} the overall energy level.} In other words, the dotted line will get lower over time. This has the effect of pulling the turning points closer to equilibrium until eventually the energy level settles down to the point of stable equilibrium. Thus, in the real world where friction is present, systems will always settle down to rest into the closest state of stable equilibrium. Once there they remain unless they are knocked out by some external force.

% Phase space? Sources and sinks? %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%I'd like to introduce you to one other perspective on energy called \jargon{phase space}. Put simply, this is a plot of the motion of a system with respect to both displacement and velocity. As we follow a particle along it traces out a path in phase space. If the energy is conserved in the system then these paths build up a kind of contour map in which the lines never cross. This is analogous to the way fluids flow (see Lecture \ref{ch:fluids}). If we include friction then points of unstable equilibrium act as sources of this motion flow and points of stable equilibrium act as sinks. The use of phase space is sometimes used in the study of deterministic chaos and advanced mechanics. We, however, will have little use for it.

% Principle of least action

The principle of least action is a statement that physical systems move in such a way that they minimizes a certain property. Both Newton's first law and the principle of virtual work can be summarized by minimal principles. If we set the potential energy to zero, we are describing a force-free particle. The average kinetic energy multiplied by the total time is minimized by the shortest path---which is produced by a particle moving with constant velocity. In addition, if the kinetic energy is set to zero, we are describing a static system. In that case, the potential energy is minimized because the system is sitting at equilibrium in a potential well.

Since both the potential and kinetic energies obey a minimal principle, it is natural to suspect the total energy to do so also. But consider the projectile range problem. What prevents the particle from simply moving horizontally? Energy is conserved this way. Perhaps the particle moves along a path where is it minimized? No, the energy is actually minimized for a path that drops underground. Lagrange\footnote{\href{http://en.wikipedia.org/wiki/Joseph_Louis_Lagrange}{Joseph Louis Lagrange [1736--1813]}. Chiefly known for this reconstruction of Newton's laws.} found the answer: subtract the potential energy rather than add it to the kinetic energy. This combination now bears his name: the \jargon{Lagrangian}. The average Lagrangian multiplied by the total duration is called \jargon{action} and depends upon the path. 
$$L = KE - PE \quad \text{and} \quad S = \sum_\text{path} L \; \Delta t$$
The path with the smallest action is the true path. This is called the \jargon{principle of least action}.

We can at least indicate how to prove that Newton's second law and the principle of least action are equivalent. The simplest non-trivial example of using action is the step-potential. On either side of the potential we have a free-particle, so we expect the path to be straight. The only question is when does the particle encounter the step? We expect the particle to spend more time in the higher potential since this reduces the action. On the other hand, if the particle moves too quickly in the low potential region the kinetic energy will be too high. The optimal path is refracted (see Figure \ref{fig:particle-refraction}) from the constant velocity path. It can be shown that this path conserves energy, which we know comes from Newton's laws.

\tikzfig{particle-refraction}
{
\begin{tikzpicture}
\node at (0.5,3.5) [right] {High potential};
%\node at (5.5,0.5) [left] {Low potential};
\draw [->] (0,0) -- (6,0) node [right] {$t$};
\draw [->] (0,0) -- (0,4) node [above] {$x$};
\coordinate (1) at (0.5,0.5);
\coordinate (2) at (5.5,3.5);
\fill (1) circle (0.1);
\fill (2) circle (0.1);
\foreach \x in {1,2,...,5} \draw [dashed] (1) -- (\x,2) -- (2);
\draw [thick] (1) -- (2,2) -- (2);
%\draw [gray] (1) -- (3,2) -- (2);
\path (1) -- (1,2) node [pos=0.5,pin=180:{$KE$ is too high}] {};
\path (5,1) -- (2) node [pos=0.5,pin=-45:{Not enough $PE$}] {};
\path (3,2) -- (3,2) node [pos=0.5,pin={[pin distance=10mm]-45:{Constant $v$}}] {};
\fill [fill opacity=0.1] (0,2) rectangle (6,4);
\end{tikzpicture}
}{Refraction of a particle off of a potential step. Compare with optical refraction in Figure \ref{fig:snells-law}.}

\prep{So the principle of least action not only fixes the energy, but also isolates the \hide{path}. This principle is therefore more powerful than the energy approach.} But that's only the beginning. This principle has applications to optics, wave motion, electromagnetism, general relativity, and even quantum mechanics.

%There is also an important consequence of least action called \jargon{Noether's theorem}. This is the statement that every symmetry in the Lagrangian corresponds to a conserved quantity in the motion of the system. For example, energy is conserved whenever the Lagrangian is independent of time.

%This Lagrangian formulation is the language of high-energy physics. Noether's theorem is often used backwards by finding conserved qualities in sub-atomic collisions and working backward into the structure of the Lagrangian. So, the principle of least action sits behind many of the more obscure properties in high energy physics. Frequently, knowing the symmetries of a system's Lagrangian is sufficient to define it.

% Preview for next week

For next week we will define momentum, a concept we mentioned in the discussion of Newton's second law back in Lecture \ref{ch:newtons-laws} as the ``quantity of motion''. This will lead into a discussion about collisions and how to classify and analyze them using the idea of the center of mass. We will talk a bit about how to deal with multiple particles interacting. Finally we will get a sneak-peak at what quantum field theory looks like by discussing exchange particles and quasi-particles.
========
08:momentum
--------
Momentum and Collisions
--------
Read sections 7.1--7.5, sneak a peak at section 14.3, review Lecture \ref{ch:newtons-laws}
--------
% A change in perspective: interaction versus force, Newton's third law

In the 17th century there was quite a vigorous discussion about how to quantify motion. The debate ran across national lines with Newton in England and \href{http://en.wikipedia.org/wiki/Gottfried_Leibniz}{Leibniz}\footnote{These two also had a priority dispute over who invented calculus. We still have competing notations that go back to these two men.} in France. We have seen in Lecture \ref{ch:newtons-laws} that Newton based his work on the product of mass and velocity, which today we call \jargon{momentum}:\footnote{Don't ask me why the symbol for momentum is $p$. I've never been able to figure it out.}
\begin{equation} \label{lin-mom}
p = mv
\end{equation}
It combines the idea of inertia and motion, and because it is a vector also captures the direction of motion.

Leibniz, on the other hand, advocated the use of what he called \foreign{\jargon{vis viva}}. Primarily based on observations of collisions, Leibniz noted that the product of mass and velocity squared is conserved under certain conditions. We can see now that this is twice the kinetic energy that we introduced in Lecture \ref{ch:energy}. So, both traditions are alive and well.

\prep{Momentum is directly related to the notion of force through Newton's second law. This essentially states that the \hide{rate} at which momentum changes is equal to the net force on the object.} We have also noted how Newton's third law can be interpreted as the statement that every interaction involves an exchange in momentum. One could also argue that Newton's first law can also be rewritten as a statement about momentum: in an inertial frame with no external forces, momentum is constant.

% Impulse defined; rewriting Newton's second law

So, the idea of momentum is threaded throughout mechanics. We can take this one step further by rewriting the second law as:
\begin{equation} \label{impulse}
F \; \Delta t = \Delta p
\end{equation}

There are two things to say about this equation. The first is that the quantity on the left is called \jargon{impulse}. Impulse is usually only used for fast-acting forces, like contact forces in a collision. In this formula, the $F$ represents the average force applied over the time frame.

The second thing is that this formula is similar to the formula between work and energy:
$$F \; \Delta x = \Delta E$$
In other words, every increment of work corresponds to an increase (or decrease) in the energy level of the system. Because of this similarity, the problem solving methods in this lecture are similar to those of the previous lecture. We identify the initial and final states of the system and the path in between is ignored. \prep{This is the great advantage of using the energy-momentum perspective: we don't need to know the \hide{details} of the interaction. We can't answer every question but the solution is much easier for those we can.}\footnote{There is also another reason to notice the parallel between these two formulas. In Lecture \ref{ch:em-and-relativity} on special relativity we will see the concepts of time and space merge together into a single space-time continuum. At the same time we will see the ideas of energy and momentum merge together as well. This parallel is the reason for it.}

% Machine-gun pressure

\label{ex:machine-gun-pressure}

Imagine a bullet embeds itself into a wall. The initial momentum of the bullet suddenly becomes zero. This happens because the wall provides the force necessary to stop this momentum. Now imagine a \href{http://en.wikipedia.org/wiki/M16_rifle}{machine gun} which fires 4.0 gram bullets at 940 meters per second at a rate of 720 rounds per minute. What is the average force per second required to stop these bullets?

It's easy to see that the average momentum of each bullet is\footnote{What is the SI unit for momentum? It is one of the few units in physics with no name. It one kilogram-meter-per-second. I usually just say ``unit of momentum'' rather than that mouth-full.}
$$p = (0.004)(940) = 3.76$$
So the wall provides the force against this momentum for each bullet. But in order to use equation \eqref{impulse} we need a time frame. What do we use in this case? We do not know how long it takes for the wall to stop each bullet. But we are not asked for the force to stop a bullet. We are asked for the \emph{average force}. If we were to plot the force from the wall over time we would just see a bunch of spikes (see Figure \ref{fig:machine-gun-pressure}). The average level of force is not the height of these spikes but somewhere below depending on how far apart the spikes are and how thick they are.

\tikzfig[side]{machine-gun-pressure}{
\begin{tikzpicture}
\draw [->] (0,0) -- (4,0) node [right] {$t$};
\draw [->] (0,0) -- (0,3.5) node [above] {$F$};
%\foreach \t in {1,...,20} \draw (6*rnd,0) -- +(0,3);
\foreach \t in {1,...,12} \draw (6/20*\t,0) +(-0.02,0) rectangle ++(0.04,3);
\draw [dashed] (0,0.48) -- +(4,0) node [pos=0,left] {$\avg{F}$};
\end{tikzpicture}
}{Average force required to stop the bullets}

Fortunately these things all average out over time. What we need to do is just pick a time frame---say one second. How many bullets strike the wall in one second? The answer is 12. So the wall must provide the momentum to stop 12 bullets, or
$$p_\text{tot} = (12)(3.76) = 45.12$$
Since the wall does this in one second we can use equation \eqref{impulse} to solve for the average force. In this case the time frame is simply one, so the final answer is 45 newtons per second.

\prep{Though generally associated with electronics, the idea of a \hide{stream} of particles occurs several times in physics and is called \jargon{current}} (see Lecture \ref{ch:dc-and-magnetism}). We will use the ideas from this problem again in Lecture \ref{ch:kinetic-theory} to derive the ideal gas law.

% Collisions exchange momentum through an interaction

\label{ex:inelastic-collision}

Momentum is also helpful in analyzing collisions. Consider a 2000 kilogram car moving at 20 meters per second that strikes another at rest. The second car has a mass of 2500 kilograms. How far they slide if they end up entangled together? Assume the coefficient of kinetic friction is 0.70.

Since the second car is at rest, it has no momentum. So the initial momentum of the system is just the momentum of the first car: 40,000 kilogram-meters per second. The collision does not change the overall momentum, so after the collision the momentum is the same. But now the momentum moves a total mass of 4500 kilograms. This implies that the speed after the collision will be 8.89 meters per second. 

But this is only the first half of the problem. Now we need to know what it will take to bring this mass to rest. There are two ways to solve it: we can use force and friction from Lecture \ref{ch:newtons-laws} or the ideas of work and energy from Lecture \ref{ch:energy}. Let's do it both ways. We will start with force.

The force of friction is given by $\mu N$ where the support force is counterbalancing the weight of the mass. So,
$$F = (0.70)(4500)(9.8) = 30780$$
By Newton's second law this will cause the mass to decelerate:
$$a = \frac{F}{m} = \frac{(30780)}{(450)} = 6.86$$
Since we know the velocities and we are interested in a distance, we should use equation \eqref{pos-vel-sqr} to answer the question. We have:
$$x = \frac{v^2}{2a} = 5.7589$$
Now let's turn to energy. The kinetic energy of the mass just after the collision is:
$$KE = \half mv^2 = \sci{1.7778}{5}$$
This energy is consumed by the work done by the friction. This work is directly related to the distance, by definition. Thus,
$$x = \frac{W}{F} = \frac{(177780)}{(30780)} = 5.7757$$
So, the final answer is 5.8 meters.\footnote{The difference between these answers is a rounding error---which is why we need to pay attention to significant digits!}

% Types of collisions: elastic, inelastic

Not all collisions end with the objects stuck together: sometimes they bounce. There is a whole spectrum of collisions possible between the two extremes. On the one side you have an \jargon{elastic collision}. Suppose you take a ball and drop it from a certain height. If the ball returns to the same height the collision is said to be elastic. Of course it does not normally make it back. In that case we say the collision is inelastic. So an elastic collision is an ideal: the typical case is inelastic. If the ball drops and stops (like a sloppy piece of mud), we call this a \jargon{completely inelastic collision}.

This spectrum is quantified by the \jargon{coefficient of restitution} (COR) which is related to the speed prior to and after the impact.\footnote{The bounce height is related to the (potential) energy of the ball, so the COR is equal to $\sqrt{h/h_0}$.}. An elastic collision will have a COR equal to one and a completely inelastic collision will have a COR equal to zero.

\prep{The important thing to remember is that the momentum in any collision, no matter how inelastic, is always conserved. \hide{Kinetic energy} is what is lost in an inelastic collision, not momentum.}

Based on this insight, we can derive a couple of useful formulas relating the initial and final velocities of a collision. In general, the mathematics is pretty hairy, so we will confine ourselves to problems in which one of the objects is initially at rest. This is not as restrictive as it may sound. According to the principle of relativity, we have the freedom to choose our inertial frames. We can choose the frame that follows the particle, effectively making it at rest. This is called the \jargon{lab frame} for the collision.

A couple of conventions first. It is usual to label the first particle as the one moving and the second particle as the one at rest. In order to not get lost in a sea of subscripts I prefer to use different letters to represent the initial and final velocities. This is not usual but neither is it unheard of in the literature. We will use $v$ to represent the initial velocities and $u$ the final velocities. So, what we seek is a formula for $u_1$ and $u_2$ given the fact that $v_2 = 0$.

For every collision we have the conservation of momentum. 
$$m_1 v_1 = m_1 u_1 + m_2 u_2$$
Since we are looking for two unknowns we need another (assume the masses are given). In general this involves the coefficient of restitution, but for the extreme cases we have a simpler fall-back. For a completely inelastic collision we have $u_1 = u_2$ since they stick and travel together. This allows us to derive:
\begin{equation} \label{inelastic}
u_1 = u_2 = \left( \frac{m_1}{m_1 + m_2} \right) v_1
\end{equation}

\prep{For a (perfectly) \hide{elastic} collision the total kinetic energy is conserved.} This follows from the fact that the COR is equal to one.\footnote{We will be able to establish this after we have discussed the center of mass.} If we multiply the kinetic energy equality by two we get
$$m_1 v_1^2 = m_1 u_1^2 + m_2 u_2^2$$
You can see here the origin of Leibniz' \foreign{vis viva}. The math is a bit messy, but after a while we get
\begin{equation} \label{elastic}
\begin{split}
u_1 = \left( \frac{m_1 - m_2}{m_1 + m_2} \right) v_1 \\
u_2 = \left( \frac{2m_1}{m_1 + m_2} \right) v_1
\end{split}
\end{equation}
Notice that if $m_1 < m_2$, the incoming particle will bounce backward. If $m_1 \ll m_2$, the particle will bounce back with nearly the same speed and the struck particle will hardly move---like a wall.

% Explosive collisions and rocket motion. http://en.wikipedia.org/wiki/Rocket_equation

Another example of the use of momentum is rocketry. People often ask: in space, how can a rocket move---what does it push against? The answer is that it pushes against its own exhaust. Consider a kid sitting in a wagon at rest. Suppose she takes a baseball and throws it. She and the wagon recoil slightly. This is the same recoil which drives a rocket. The momentum calculation is the same as a completely inelastic collision, just in reverse. In fact, we can even incorporate this explosive type of interaction on our COR spectrum if we let the numbers exceed one because an explosion is an increase in the total kinetic energy of the system.

\prep{The complication with rocketry is that it requires a lot of \hide{fuel} to push the rocket. This means that it is not reasonable to assume the mass of the rocket is constant.} So, at each instant the momentum calculation will change. If one does the math,\footnote{This is an example of an application of Newton's second law with variable mass.} one gets the \href{http://en.wikipedia.org/wiki/Rocket_equation}{rocket equation} which describes the overall increase in speed.
\begin{equation} \label{rocket-equation}
%\Delta v = v_e \ln (m_0 / m)
\Delta v = v_e \ln (1 + \Delta m / m)
\end{equation}
where $v_e$ is the speed of the exhaust, $\Delta m$ is the total mass of the fuel, and $m$ is the final mass (without the fuel). This \jargon{delta-v} is important in calculating orbital maneuvers in space. In general, the mass of fuel required far outweighs the mass of the payload.

% Multi-dimensional collisions; the center of mass

So far we have only spoken of these collisions in one dimension. Consider again a collision with an incoming particle colliding with another at rest. Imagine the approach of the moving particle to be off-center like a billiards shot (see Figure \ref{fig:collision-lab}). The contact forces line up with the point of contact so they are at an angle. This deflects the first ball and sends the second down the line creating a truly two-dimensional problem.

\tikzfig[full]{collision-lab}{
\begin{tikzpicture}

\begin{scope}[xshift=-55mm]
\clip [draw] (-2.5,-2.5) rectangle (2.5,2.5);
\draw [dotted] (-3,-3) grid (3,3);
\coordinate (1a) at (-1.7,0.5);
\coordinate (2a) at (0,0);
\node (b1) [draw,fill=white,circle,inner sep=2mm] at (1a) {1};
\node (b2) [draw,fill=white,circle,inner sep=2mm] at (2a) {2};
\draw [->] (b1) -- +(1.2,0) node [pos=0.5,above] {$v_1$};
\end{scope}

\begin{scope}[xshift=0]
\clip [draw] (-2.5,-2.5) rectangle (2.5,2.5);
\draw [dotted] (-3,-3) grid (3,3);
\coordinate (1a) at (-1.7,0.5);
\coordinate (2a) at (0,0);
\coordinate (1b) at (-0.7,0.5);
\coordinate (2b) at (0,0);
\draw [dashed] (1a) -- (1b);
\draw [dashed] (2a) -- (2b);
\node [draw,starburst] at ($(1b)!0.5!(2b)$) {};
\node (b1) [draw,fill=white,circle,inner sep=2mm] at (1b) {1};
\node (b2) [draw,fill=white,circle,inner sep=2mm] at (2b) {2};
\node (f1) [forcearrow,right,rotate=145] at ($(1b)!-0.6!(2b)$) {};
\node (f2) [forcearrow,right,rotate=-35] at ($(1b)!1.6!(2b)$) {};
\draw [gray] ($(1b)!-2!(2b)$) -- ($(1b)!3!(2b)$);
\end{scope}

\begin{scope}[xshift=55mm]
\clip [draw] (-2.5,-2.5) rectangle (2.5,2.5);
\draw [dotted] (-3,-3) grid (3,3);
\coordinate (1a) at (-1.7,0.5);
\coordinate (2a) at (0,0);
\coordinate (1b) at (-0.7,0.5);
\coordinate (2b) at (0,0);
\coordinate (1c) at ($(1b)+(0.5,0.7)$);
\coordinate (2c) at (0.7,-0.5);
\draw [dashed] (1a) -- (1b) -- (1c);
\draw [dashed] (2a) -- (2b) -- (2c);
\node (b1) [draw,fill=white,circle,inner sep=2mm] at (1c) {1};
\node (b2) [draw,fill=white,circle,inner sep=2mm] at (2c) {2};
\draw [->] (b1) -- +(0.5,0.7) node [pos=0.5,below right] {$u_1$};
\draw [->] (b2) -- +(0.7,-0.5) node [pos=0.5,above right] {$u_2$};
\end{scope}

\end{tikzpicture}
}{Two-dimensional collision (lab frame)}

\prep{In any scattering problem like this, the final angle of \hide{deflection} depends upon the nature of the interaction between the particles.} Particle accelerators probe the inner working of the nucleus by analyzing deflection patterns in order to infer the nature of the interaction.

Deflection will even occur for an attractive force. \prep{This is how a \jargon{gravitational sling-shot} works. Passing by a planet, a space probe can steal \hide{momentum} from the planet and be deflected along a new trajectory.} This is one way to pick up delta-v without expending fuel.

\prep{For any collision problem, it is usually easiest to perform the analysis in the \jargon{center of mass frame} (or \hide{CM frame}). This is the inertial frame in which the system's center of mass is at rest.} The \jargon{center of mass} is defined as
$$x_\text{cm} = \frac{m_1 x_1 + m_2 x_2}{m_1 + m_2}$$
where $x_1$ and $x_2$ are the positions of objects.\footnote{Sometimes we are only told the distance between the two objects. In that case, let $x_1$ equal zero, and let $x_2$ be the distance given. The center of mass will then be given as a distance from the first object.} It can be seen that the velocity of the center of mass is constant because we have by definition:
$$v_\text{cm} = \frac{m_1 v_1 + m_2 v_2}{m_1 + m_2}$$
The numerator is the total momentum of the system and the denominator is the total mass of the system. In any collision, elastic or not, both of these quantities are conserved.

The reason the CM frame is helpful is that the velocity of the CM is zero so the total momentum is zero. This implies that the momenta of the particles are equal and opposite before and after (see Figure \ref{fig:collision-cm}).

\tikzfig[full]{collision-cm}{
\begin{tikzpicture}

\begin{scope}[xshift=-55mm]
\clip [draw] (-2.5,-2.5) rectangle (2.5,2.5);
\draw [dotted] (-3,-3) grid (3,3);
\coordinate (1a) at (-0.85,0.25);
\coordinate (2a) at (0.85,-0.25);
\node (b1) [draw,fill=white,circle,inner sep=2mm] at (1a) {1};
\node (b2) [draw,fill=white,circle,inner sep=2mm] at (2a) {2};
\draw [<-] (b1) -- +(-0.85,0) node [pos=0.5,above left] {$v_1$};
\draw [<-] (b2) -- +(0.85,0) node [pos=0.5,above right] {$v_2$};
\node [draw,cross out] at (0,0) {};
\end{scope}

\begin{scope}[xshift=0]
\clip [draw] (-2.5,-2.5) rectangle (2.5,2.5);
\draw [dotted] (-3,-3) grid (3,3);
\coordinate (1a) at (-0.85,0.25);
\coordinate (2a) at (0.85,-0.25);
\coordinate (1b) at (-0.35,0.25);
\coordinate (2b) at (0.35,-0.25);
%\draw [dashed] (1a) -- (1b);
%\draw [dashed] (2a) -- (2b);
\node [draw,starburst] at ($(1b)!0.5!(2b)$) {};
\node (b1) [draw,fill=white,circle,inner sep=2mm] at (1b) {1};
\node (b2) [draw,fill=white,circle,inner sep=2mm] at (2b) {2};
\node (f1) [forcearrow,right,rotate=145] at ($(1b)!-0.6!(2b)$) {};
\node (f2) [forcearrow,right,rotate=-35] at ($(1b)!1.6!(2b)$) {};
\draw [gray] ($(1b)!-2!(2b)$) -- ($(1b)!3!(2b)$);
\end{scope}

\begin{scope}[xshift=55mm]
\clip [draw] (-2.5,-2.5) rectangle (2.5,2.5);
\draw [dotted] (-3,-3) grid (3,3);
\coordinate (1a) at (-0.85,0.25);
\coordinate (2a) at (0.85,-0.25);
\coordinate (1b) at (-0.35,0.25);
\coordinate (2b) at (0.35,-0.25);
\coordinate (1c) at ($(1b)+(-0.2,0.7)$);
\coordinate (2c) at ($(2b)+(0.2,-0.7)$);
\draw [dashed] (1a) -- (1b) -- (1c);
\draw [dashed] (2a) -- (2b) -- (2c);
\node (b1) [draw,fill=white,circle,inner sep=2mm] at (1c) {1};
\node (b2) [draw,fill=white,circle,inner sep=2mm] at (2c) {2};
\draw [->] (b1) -- +(-0.2,0.7) node [pos=0.5,above right] {$u_1$};
\draw [->] (b2) -- +(0.2,-0.7) node [pos=0.5,below right] {$u_2$};
\node [draw,cross out] at (0,0) {};
\end{scope}

\end{tikzpicture}
}{Two-dimensional collision (CM frame)}

% More than two particles

So far we have only considered two particles interacting. What if there are more? The definition of the center of mass extends to include all the particles. It's still true that the momentum of the total system is conserved (and the total mass), so the velocity of the center of mass is constant. In the CM frame, all the velocities are measured relative to the center of mass so the aggregate whole does not move. But the parts move all over. \prep{Internal forces are responsible for \hide{redistributing} the energy and momentum of the system but they cannot change the motion of the whole.}

We will see in Lecture \ref{ch:kinetic-theory} that the total kinetic energy of the molecules in the center of mass frame for a macroscopic system is directly related to its temperature.

% Exchanges particles and quantum field theory

\jargon[quantum field theory]{Quantum field theory} (QFT) describes the fundamental interactions of nature as occurring through the exchange of intermediate particles. These particles exchange momentum, energy, and other subatomic qualities. Figure \ref{fig:feynman-diagram-example} shows a \jargon{Feynman diagram} used in a QFT calculation. At each vertex momentum, energy, and all the other subatomic qualities are conserved. See Lectures \ref{ch:quantum-mechanics} and \ref{ch:high-energy} for more details.

\tikzfig[side]{feynman-diagram-example}{
\begin{tikzpicture}[scale=0.75]

%\draw [fill=black!10] (-4.2,-4.2) rectangle (4.2,4.2);
\draw [->] (-3,-3) -- (3,-3) node [right] {$x$};
\draw [->] (-3,-3) -- (-3,3) node [above] {$t$};
\node (a1) [actual] at (-1.8,-2.4) {};
\node (b1) [actual] at ( 1.8,-2.4) {};
\node (a2) [actual] at (-1.2, 2.4) {};
\node (b2) [actual] at ( 2.4, 2.4) {};
\node (a3) [virtual] at (-0.6, 0.3) {};
\node (b3) [virtual] at ( 1.2,-0.3) {};
\path (a1) edge [electron] node [pin=-45:{Electron}] {} (a3)
      (a3) edge [electron] (a2);
\path (b1) edge [electron] (b3)
      (b3) edge [electron] (b2);
\path (a3) edge [photon] node [pin=90:{
\begin{minipage}{12mm}
\centering
Virtual Photon
\end{minipage}
}] {} (b3);

\end{tikzpicture}
}{A simple Feynman diagram}

%There is one last rather obscure mechanical quantity worth mentioning: \jargon{virial}. Virial is usually associated with a centripetal force and is the product of the distance from the source and the radial component of the momentum.\footnote{This is easier to say with the dot product: $G = \vect{r} \cdot \vect{p}$.} 

%The usefulness of virial is primarily confined to its use in the \href{http://en.wikipedia.org/wiki/Virial_theorem}{virial theorem}. The rate of change of virial is connected to the kinetic and potential energies of the system. If the system is bound (i.e., its energy trapped in some potential well), then the virial will also be trapped in a certain range. So, over a long time frame, the virial's rate of change become negligible.\footnote{This is a bit similar to the fact that the average velocity of circular motion is zero.} This means there is a connection between the average kinetic energy and average potential energy of a bound system. 

%The virial theorem is useful in establishing certain facts in celestial mechanics (Lecture \ref{ch:celestial-mechanics}) and the kinetic theory of heat (Lecture \ref{ch:kinetic-theory}).

% Preview for next week

Next week we will expand our mechanics for the first time beyond the particle and consider the rotation of a rigid object. We will see an immediate parallel with the kinematics in Lecture \ref{ch:kinematics}. This parallel will tee up an advanced topic called generalized coordinates. The idea of rotation will be seen as a special example of generalized coordinates and we will talk about rotating coordinate systems.
========
09:rotation
--------
Rotation and Non-Inertial Frames
--------
Read sections 8.1--8.6
--------
% Rigid objects and degrees of freedom

In Lecture \ref{ch:equilibrium} we discussed the way in which force can affect an object. We agreed to focus on the motion of a particle and systems of particles. In this lecture we will broaden that focus to include objects with extension. We will still ignore the possibility of deformation (see Lecture \ref{ch:elasticity}). \prep{An object in which the deformation is \hide{negligible} is called a \jargon{rigid object}.}

A rigid object may be composed of an arbitrary number of parts. But those parts are constrained to move in such a way that their relative distances are unchanged in time. For any system, the various ways in which it can move are called its \jargon{degrees of freedom}. A single particle has three for the three dimensions of space. A collection of $N$ independent particles will have $3N$ degrees of freedom. A rigid object has six: three for its bulk motion in space and three for its rotation about the center of mass.

In general, when an object is tumbling through space it typically has a wobble in its rotation. This \jargon{free rotation} is due to some lack of symmetry in the object. We will touch on ways to analyze this general case in Lecture \ref{ch:torque}, but for now we will start simple. \prep{We will assume that the axis of rotation is fixed so that the motion the parts are in parallel \hide{circles} centered on the axis. This is called \jargon{fixed rotation} and will be the 90\% of what we will consider in this class.}

% Angles and arc-length

Our previous considerations of the motion of the center of mass are valid for rigid objects. For example, in the absence of external forces the center of mass of the rigid object will move with constant velocity so the CM frame is inertial. Effectively this allows us to ignore the bulk motion of the object and focus our attention on just its rotation.

Since the parts all rotate together, it is sufficient to watch the motion of one point---the rest will follow. We already mentioned that the motion of this point will be in a circle with its center along the axis of rotation. So everything you know about circles is relevant. We will review the concept of arc-length.

\prep{The \jargon{arc-length} is the curved \hide{distance} along the circumference of the circle between two points on the circle.} There is a one-to-one correspondence between the angle formed between these points from the center and this arc-length. It is easier to characterize the rotation of the object by this angle since the parts form a consistent angle as the object rotates, but the arc-lengths may be quite different.

However, the angle is not a distance---the arc-length is. And mechanics is mostly about tracking displacements over time. So we need to be able to convert between the two ideas. The arc-length is clearly proportional to both the angle and the radius of the circle. Also, if the angle is 360$\dg$, we know the arc-length is the full circumference of the circle, $2\pi r$. So the formula is
$$s = (2\pi r)(\theta / 360\dg)$$
We can simplify this formula by introducing a new unit to measure angles called the \jargon{radian}. If we define the radian such that $2\pi$ radians equals 360 degrees, the formula becomes
\begin{equation} \label{arc-length}
s = r\theta
\end{equation}
where $\theta$ is now measured in radians. \prep{This means that an angle of one \hide{radian} will produce an arc-length equal to the radius of the circle.} This new unit is just a different way to measure angles---like the difference between centimeters and inches. One radian is a smidge less than 60$\dg$. The radian also simplifies other calculations involving angles: for example, in Lecture \ref{ch:harmonic-motion} we will use the fact that $\sin \theta \approx \theta$, a trick which only works with radians.

Another common unit for measuring angles is the revolution---as in rpm, revolutions per minute. The conversion factors between the three units of angle are simply
\begin{equation} \label{angle-units}
1 \unit{rev} = 2 \pi \unit{rad} = 360 \dg
\end{equation}

% The angular analogy with translation

If we consider our arc-length to have a direction (i.e., from point A to point B), it starts to sound like a vector. Technically it is not because vector addition will not work with arc-lengths,\footnote{It kind of works in two dimensions, but it breaks down for free rotation. It is possible to construct a vector space, but only for infinitesimally small arc-lengths and rotations} but we do want to keep the idea of ``directionality'' for our analysis of motion. So we will avoid calling these vectors, but we will still want to use the idea of a directed arc-length.

In addition, we want to associate a direction to our angles. This is called \jargon{angular displacement}. Remember, \prep{when we talk about angular \hide{displacement} we are talking about an angle: its unit is either degrees or radians.}

This leads into the idea of angular velocity which is simply the rate at which the angular displacement changes. Its units are radians per second. Note that \prep{revolutions per minute is a unit of angular \hide{velocity}.} We will also speak of angular acceleration, which is the rate at which the angular velocity changes. The traditional symbols for angular velocity and angular acceleration are $\omega$ and $\alpha$, respectively.

Now take a minute and review the logic we used to derive equation \eqref{const-vel}--\eqref{pos-vel-sqr} in Lecture \ref{ch:kinematics}. They all follow from the definition of velocity and acceleration. The definitions of angular velocity and acceleration are built on a parallel between linear displacement and angular displacement from equation \eqref{arc-length}. So we can import all these linear equations into the context of angular rotation.

\label{ex:spinning-wheel}

Let's consider an example. A wheel is spinning at 30 revolutions per minute. What angular deceleration is required to bring the wheel to rest in five seconds?

We are told the initial speed, though we do want to convert this into radians per second. 
$$\omega_0 = \frac{30 \unit{rev}}{\text{min}} \times \frac{2 \pi \unit{rad}}{1 \unit{rev}} \times \frac{1 \unit{min}}{60 \unit{s}} = 3.1416$$
The final speed is zero since it comes to rest. Since we are also given the time involved we should use the angular equation that corresponds to equation \eqref{const-acc}. That is,
$$\omega = \omega_0 + \alpha t$$
and
$$(0) = (3.1416) + (\alpha)(5) \implies \alpha = -0.63$$
Any other problem like this can be solved using the methods from Lecture \ref{ch:kinematics}.

% Angular and tangential variables, rolling motion

How are these ideas related to those in Lecture \ref{ch:circular-motion} on circular motion? In that lecture, the speed was associated with the motion along the circumference or the arc-length. It's pretty straight-forward to see that this is related to the angular velocity by
\begin{equation} \label{tangential-velocity}
v = r\omega
\end{equation}
which follows from equation \eqref{arc-length}. Similarly we have
\begin{equation} \label{tangential-acceleration}
a = r\alpha
\end{equation}
for the angular acceleration. But be careful: this acceleration is the acceleration along the rotation. The acceleration calculated in equation \eqref{ucm} is directed toward the center. These two vectors are perpendicular to one another.

\prep{In order to avoid confusion we will speak of the components along the circular motion as \hide{tangential} and the components toward the center as centripetal.} For example, we add $t$ as a subscript and now describe equation \eqref{tangential-velocity} by saying that when the angular velocity is constant, the tangential velocity is proportional to the distance from the axis of rotation.

It is worth noting that the polar coordinates we introduced on page \pageref{fig:polar-grid} are consistent with this division of motion into tangential and centripetal.

One way these concepts are used is in rolling motion. \prep{The condition for a \hide{rolling} wheel is that its rotation match its translation. If this is not the case, the wheel is slipping (or sliding if it is not rotating at all).} In symbols, we require
\begin{equation} \label{rolling-condition}
v_\text{cm} = v_t = r\omega
\end{equation}

\label{ex:go-cart-speed}

Consider the following problem. Suppose a go-cart with wheels of radius 0.1 meter has an engine that can produce an angular acceleration of 2.0 radians per second squared. What is its final speed at the end of a 100 meter race? Assume the acceleration is constant.

Since the problem involves acceleration, speeds, and distance, we will use equation \eqref{pos-vel-sqr}. In terms of angular variables we have
$$\omega^2 = \omega_0^2 + 2 \alpha \theta$$
The initial speed is zero and the final speed we will get from the final angular velocity. But what is $\theta$? This is the total angular displacement of the wheel. Knowing that the wheel does not slip allows us to identify the 100 meter distance with the total arc-length travelled by the edge of the wheel. So, we can use equation \eqref{arc-length} to calculate the angular displacement:
$$(100) = (0.1)(\theta) \implies \theta = 1000$$
Now we can solve for the final angular speed:
$$\omega^2 = (0)^2 + (2)(2.0)(1000) \implies \omega = 63.246$$
Since $v_\text{cm} = r \omega$, the final speed is 6.3 meters per second.

There is another way to solve this problem. Since the wheel is rotating, we can also say that $a_\text{cm} = a_t = r \alpha$. In this case $a_t = 0.2$ meters per second squared. Then we can use \eqref{pos-vel-sqr} directly to get the same answer.

% Rotating frames

This covers the basic kinematics of rolling and rotation. We will discuss dynamics (torque as the cause of rotation) in the next lecture. As a segue to discuss generalized coordinates I would like to talk about rotating reference frames.

A question may have already occurred to you from Lecture \ref{ch:newtons-laws}. \prep{How can we get away with considering our laboratories as \hide{inertial} frames? We all know the earth is rotating and taking the lab with it. The short answer is that, technically, we cannot. Our labs are not inertial. But the effects are slight enough that we can neglect them.}

Imagine you are located directly over a spinning merry-go-round looking down from the top. Every object on the merry-go-round has a tangential velocity given by equation \eqref{tangential-velocity}. Suppose a child is playing with a ball and lets it go. From your viewpoint (the inertial one), the ball is free and follows a straight-line inertial trajectory. This is away from the center of rotation. But the child is held in place by the merry-go-round. He sees his ball traveling out and away. He feels the force of the merry-go-round obstructing his inertial motion. He is experiencing \jargon{centrifugal force}.

Do we know the formula for this inertial force? It is caused by the centripetal forces holding the merry-go-round frame together. Therefore it must also have the form given by \eqref{ucm}. In terms of the angular speed of the frame, we have
\begin{equation} \label{centrifugal-force}
F_\text{cfg} = mr\omega^2
\end{equation}

The \jargon{Coriolis force} is another, more subtle, inertial force associated with rotating frames. It is a bit difficult to derive, so I will simply quote the result:
$$F_\text{cor} = 2mv_t\omega$$
Notice that this is a force that requires the object to be moving before it is felt. Because the frame is moving underneath you an extra force is required to keep a moving object in line with the frame. In addition, the direction of the force is perpendicular to the velocity.\footnote{Here is an example where the vector product is handy. We can write this as $$F_\text{cor} = -2m\vect{v} \times \vect{\omega}$$ with the angular velocity vector pointing along the axis of rotation.} So the Coriolis force is a force of deflection---again, this is an artifact of the moving frame. In reality the particle moves in a straight line. In fact, the characteristic spiral motion of hurricanes is a result of the Coriolis force in the atmosphere.

So how big are these forces? Well, the earth rotates once per day, so its angular velocity is
$$\omega = \frac{2\pi \unit{rad}}{86400 \unit{sec}} = \sci{7.27}{-5}$$
The radius of the earth is $\sci{6.38}{6}$ meters, so the centrifugal force on an object will be
\begin{align*}
F_\text{cfg} &= (m)(\sci{6.38}{6})(\sci{7.27}{-5})^2 \\
             &= (m)(0.0337)
\end{align*}
Compare this with the formula for weight, $mg$. The centrifugal force on an object is 0.34\% of its weight. The Coriolis force is much smaller which is why it only manifests itself on the large scale.

%These are the only two inertial forces required in a uniformly rotating frame.

% Generalized coordinates

Every reference frame (even a rotating one) is at rest relative to itself, by definition. No matter how wildly it moves, no matter how curvilinear (like polar coordinates)---the frame is the reference. Occasionally it is more convenient to follow the degrees of freedom in the system than to use an inertial frame. The downside is the introduction of inertial forces.

In the process of uncovering the principle of least action, Lagrange also investigated the use of an arbitrary non-inertial frame and he analyzed it's impact on Newton's laws of motion. His approach is sometimes called \jargon{Lagrangian mechanics}.

\prep{Essentially, the first step is to identify the degrees of freedom of the system. The coordinates are then chosen to align with the natural \hide{constraints} in the system. Relative to these coordinates the configuration is measured. These are called \jargon{generalized coordinates}} and are usually symbolized with the letter $q$. Angular displacement is an example of a generalized coordinate. The definitions of velocity and acceleration are generalized also. They are usually symbolized by $\dot{q}$ and $\ddot{q}$, respectively.\footnote{It's a little calculus convention to symbolize the rate of change of a quantity with a dot. This notation goes back to Newton.}

Building on the principle of least action, Lagrange was able to generalize Newton's second law into a form appropriate in any coordinate system, inertial or not. These equations (called the \jargon{Euler-Lagrange equations}) of motion naturally incorporate the inertial forces in the frame. In addition to all the other uses of generalized coordinates, they are helpful in the study of general relativity where space-time is curved. The identification of gravity as an inertial force (the equivalence principle, see page \pageref{idx:equivalence principle}) follows directly in this approach.

% Preview for next week

Next week we will see the analogy between linear displacement and angular displacement expanded. The notion of torque will be defined and we will talk about equilibrium in rigid systems. Newton's second law has an angular version which will require us to define a type of inertia for rotation. We will use this to define angular momentum and kinetic energy. We will finish off by touching on free rotation and gyroscopic motion.
========
10:torque
--------
Torque and Free Rotation
--------
Read sections 9.1--9.6, look back at section 8.7
--------
% Torque defined

Suppose a rigid object is constrained to rotate about a particular (fixed) axis of rotation. When a force is applied to this object, it will rotate. \prep{The amount of rotation is proportional to both the force applied and the distance from the axis. This is the principle behind the \hide{lever}. This combination of force and distance is called \jargon{torque}.}

If the object is free then the force will also push the object in a straight line based on Newton's second law \eqref{n2l}. So the object will tumble in a combination of linear and angular motion. \prep{We can always break the analysis of this motion into the linear motion of the center of mass and the \hide{angular} motion about the center of mass.}

We can add an additional force to counter-balance the first. This combination will have a net force of zero, but it may still cause rotation. A balanced pair of forces with a non-zero torque is called a \jargon{force couple}.

There are actually two ways to calculate torque. One way is to draw a radial line from the axis of rotation to the point at which the force is applied. Now calculate the components of the force against that radial line. The torque is the radial distance multiplied by the tangential component of the force. See Figure \ref{fig:torque-calc-tang}. Though consistent with the previous idea of tangential and centripetal components, this is not the standard approach.

\tikzfig{torque-calc-tang}{
\begin{tikzpicture}
\node (a) [draw,circle,inner sep=0.5mm,pin=135:{Axis}] at (0,0) {};
\node (f) [fill,circle,inner sep=0.5mm] at (60:5) {};
\draw (a) -- (f) node [pos=0.5,below right] {$r$};
\coordinate (ft) at (150:1.7);
\coordinate (fc) at (240:1.0);
\coordinate (ftc) at ($(ft)+(fc)$);
\draw [->] (90:5) arc (90:30:5) node [right] {$\tau = rF_t$};
\node [forcearrow,left,minimum height=40mm,label=180:{$F$}] at (f) {};
\draw [dotted] (f) -- +(ft) -- +(ftc) -- +(fc);
\node [forcearrow,left,rotate=-30,minimum height=34mm,label=60:{$F_t$},fill=white,fill opacity=1] at (f) {};
\end{tikzpicture}
}{The tangential method of calculating torque}

\prep{The standard way to calculate torque is through the idea of \jargon{lever arm}. The first thing to do is to draw the \jargon{line of action} through the force. The perpendicular \hide{distance} between this line and the axis is the lever arm.} See Figure \ref{fig:torque-calc-lever}. Increasing this distance will increase the leverage of the force.

\tikzfig{torque-calc-lever}{
\begin{tikzpicture}
\node (a) [draw,circle,inner sep=0.5mm,pin=135:{Axis}] at (0,0) {};
\node (f) [fill,circle,inner sep=0.5mm] at (60:5) {};
\coordinate (f2) at (120:5);
\coordinate (f3) at ($(f2)!0.5!(f)$);
\draw [dashed] (f2) -- ($(f2)!3!(f3)$) node [pos=0,above right] {Line of action};
\draw (f3) rectangle +(-0.2,-0.2);
\draw (a) -- (f3) node [pos=0.5,left] {$\ell$};
\draw [->] (90:5) arc (90:30:5) node [right] {$\tau = F \ell$};
\node [forcearrow,left,minimum height=40mm,label=270:{$F$},fill opacity=1,fill=black!20] at (f) {};
\end{tikzpicture}
}{The lever arm method of calculating torque}

% Statics and equilibrium

\prep{For a rigid object to be in equilibrium all the forces and all the torques must balance. This is because there must be equilibrium along all the degrees of freedom of the system. For now we focus on rotation in a fixed plane, so three of the degrees of freedom are eliminated.\footnote{This is because the fixed axis of rotation involves two additional constraints and the third is that the object is not sliding up and down this axis.} This leaves three degrees of freedom for our rigid body: two for \hide{linear} motion and one more for rotation.} Therefore, we can summarize equilibrium for a rigid body with the formulas:
$$\sum F_x = 0 \qquad \sum F_y = 0 \qquad \sum \tau = 0$$

\label{ex:supported-shelf}

As an example, consider a storage shelf which is held up by two posts separated by one meter. A two kilogram mass is sitting 0.4 meters from the left post. What is the support force provided by each post? See Figure \ref{fig:supported-shelf}. I think you can guess that the left post will hold 60\% of the weight and the right will hold the remaining 40\%. Let's confirm.

\tikzfig{supported-shelf}{
\begin{tikzpicture}
\draw (-3,0) -- (4,0);
\node (w) [forcearrow,right,rotate=-90,minimum height=20mm] at (0,0) {};
\node [below=6mm] at (w) {$W = mg$};
\node (l) [forcearrow,left,rotate=90,minimum height=12mm] at (-2,0) {};
\node [below=3mm] at (l) {$L$};
\node (r) [forcearrow,left,rotate=90,minimum height=8mm] at (3,0) {};
\node [below=2mm] at (r) {$R$};
\draw [|-|] (-2,0.3) -- +(2,0) node [pos=0.5,above=1mm] {0.4};
\draw [-|] (0,0.3) -- +(3,0) node [pos=0.5,above=1mm] {0.6};
\end{tikzpicture}
}{A supported shelf}

First of all, there is no horizontal component to this question. All the forces are vertical, so $\sum F_y = 0$ is true but unhelpful. The formula $\sum F_x = 0$ tells us that the forces balance, so we have
$$L + R = mg = 19.6$$
The torques will give us another equation to solve this problem. In order to calculate the torque we need to measure the lever arm relative to the axis of rotation. \prep{But there is no axis of rotation: the shelf is in equilibrium! In this case, its arbitrary. Choose any axis you want. The reason is that the torques around any axis must balance---if they didn't, the object would \hide{spin} there.}

Though the choice is arbitrary, a judicious choice can make the math easier. Basically you can eliminate one torque calculation by putting the axis on top of the force you dislike the most. This example is pretty simple, but for more complicated problems you may want to think about this a bit. For now I will choose to put the axis right where the weight is applied.

In this problem the forces are all perpendicular to the lever arms so there is no trig to mess with. The torque from the left support is simply 
$$\tau_L = (L)(0.4)$$
The right torque is similar:
$$\tau_R = (R)(0.6)$$
Before we add these together recognize that these two torques are in opposition. The left torque wants to rotate the shelf clockwise but the right torque wants to rotate the shelf counter-clockwise. The convention is to call counter-clockwise positive\footnote{This matches how we measure angles on our coordinate grid. The rule is that the angle is positive angle if it is measured from the positive $x$-direction toward the positive $y$-direction.} so we should flip the sign of the left torque. The torque formula gives
$$-(L)(0.4) + (R)(0.6) = 0$$
So $R$ is two-thirds the size of $L$. After substituting that into the first and solving we confirm that $L$ is, in fact, 60\% of the weight.

The previous problem spells out the general approach to solving these torque equilibrium problems:
\begin{items}
\item Set the sum of the horizontal and vertical force components to zero.
\item Pick an axis of rotation with an eye to simplifying the calculation of the torques.
\item Calculate the lever arm for each force (one of them should be zero).
\item Sum the torques and don't forget to determine the correct sign to give them.
\item Work the algebra---this usually involves solving multiple equations.
\end{items}
Let's do another problem that involves some torque calculations.

\label{ex:hanging-support}

Consider a object that is hanging off of a wall. The object is held 2.0 meters off of the wall by a rigid support beam which weighs 50 newtons. The beam is held up by a string attached to the wall and makes a 30$\dg$ angle with the beam. The maximum tension the string can support is 500 newtons. What is the largest weight that can hang off of the beam before the string snaps? Refer to the diagram in Figure \ref{fig:hanging-support}.

\tikzfig[side]{hanging-support}{
\begin{tikzpicture}
\draw (0,-1) -- (0,3);
\draw [fill=black!20] (0,0) rectangle +(4,-0.2);
\draw (4,0) -- (0,2.309);
\fill (0,2.309) circle (0.05);
\fill (4,0) circle (0.05);
\fill (4,-0.2) circle (0.05);
\draw (4.1,-1) -- (4,-0.2) -- (3.9,-1);
\fill (3.8,-1) rectangle +(0.4,-0.4);
\draw (4,0) +(180:0.5) arc (180:150:0.5);
\node at ($(4,0)+(167:1)$) {$30\dg$};
\draw [decorate,decoration=brace] (3.9,-0.4) -- (0.1,-0.4) node [pos=0.5,below=1mm] {2.0};
\end{tikzpicture}
}{A hanging weight}

Okay. There are four forces on the beam:
\begin{items}
\item The support from the wall which is probably angled up and out
\item The tension in the string which is angled up and in at $30\dg$
\item The weight of the beam
\item The weight of the hanging object
\end{items}

In terms of the horizontal, only the first two contribute. Since we want to maximize the tension in the string, we will consider its magnitude to be 500 newtons. Its horizontal component is
$$T_x = (500)(\cos 150\dg) = -433.01$$
So the horizontal component of the support is 433 newtons out.

For the vertical, we have all four forces in play. We are looking for the weight of the object, so we will label it $W$. The vertical component of the tension is
$$T_y = (500)(\sin 150\dg) = 250$$
We know the beam has a weight of 50 newtons down. The only force remaining is the vertical component of the support from the wall, which we don't know. Let's call it $F$ for now. So, the equilibrium equation for the vertical forces is
$$-W + (250) + (-50) + (F) = 0$$
Since the weight points down I gave it a negative sign.

\tikzfig[side]{hanging-support2}{
\begin{tikzpicture}
\draw (0,-1) -- (0,3);
\draw [fill=black!20] (0,0) rectangle +(4,-0.2);
\draw (4,0) -- (0,2.309);
\fill (0,2.309) circle (0.05);
\fill (4,0) circle (0.05);
\draw (4.1,-1) -- (4,-0.2) -- (3.9,-1);
\fill (3.8,-1) rectangle +(0.4,-0.4);
\coordinate (t) at ($(4,0)+(150:1)$);
\node [forcearrow,right,rotate=150] at (t) {};
\node at ($(t)+(70:0.4)$) {$T$};
\fill (4,-0.2) circle (0.05);
\draw [dashed] (0,0) -- (60:2) node [pos=0.5,right=1mm] {$\ell$};
\draw [rotate=60] (2,0) rectangle +(-0.2,-0.2);
\end{tikzpicture}
}{Calculating the lever arm of the tension in Figure \ref{fig:hanging-support}}

Now we move to the torques. The first step is to pick our axis. Since the support from the wall is unknown, let's put the axis there so its lever arm of the support will be zero. The weight of the beam is concentrated at its center\footnote{This point is called the \jargon{center of gravity}. It coincides with the center of mass unless the force involved varies over the configuration of the system. For standard gravity (i.e., weight) the force is constant so there is no difference.}, so it has a lever arm of one meter. The hanging object has a lever arm of two meters. The last one to determine is the lever arm of the tension. The line of action is along the string, so the dotted line in Figure \ref{fig:hanging-support2} represents the lever arm. This line is the opposite side of a right triangle whose hypotenuse is the length of the beam. The cosine connects the two. Therefore
$$\ell = (2)(\cos 30\dg) = 1$$

\tbl[full]{hanging-support}{lcccc}{
Force & Magnitude & Lever Arm & Direction & Torque \\
\hline
Tension       & 500 & 1 & $+$ & 500   \\
Beam weight   &  50 & 1 & $-$ & $-50$ \\
Object weight & $W$ & 2 & $-$ & $-2W$ \\
}{The torque calculations for Figure \ref{fig:hanging-support}}

Table \ref{tbl:hanging-support} summarizes what we have so far. I have left off the support from the wall since we deliberately set its torque to zero. These torques have to add up to zero, so
$$(500) + (-50) + (-2W) = 0$$
Well here is a surprise. We can simply solve for $W$ directly from the torque equation. The maximum weight the beam can hold is 225 newtons.

A couple of notes from this solution. Notice how we were able to avoid a bunch of math by picking our axis to zero out the support force. In fact, we never even needed to look at the horizontal and vertical components of the forces.

\prep{The second thing is that the calculation of the lever arm for the support was the worst part of the problem. This is usually the case. It always comes down to finding a right \hide{triangle} and using our trig.} If you have multiple lever arms to find, this can be quite annoying. Another approach is to calculate the torque tangentially. In this problem that means we need to determine the vertical component of the tension---which we calculated earlier as 250 newtons. Since the distance from the axis for this force was two meters, this also yields a torque of 500 newton-meters. You can see that this approach gets to the torque much faster. 

Depending on the information given in your problem you might consider using one or the other approach. In the end they are equivalent, so it's up to you.

% Newton's second law for rotation; moment of inertia

We are now ready to consider non-equilibrium problems in which the torques do not cancel. You may worry that this will be unbearably difficult given the complications involved in solving the corresponding torque equilibrium problems. However, we've done most of the heavy lifting already, so take heart.

Suppose we have a particle attached by a small rod to a particular point in space without any external forces. If in motion, it will move with uniform circular motion. This is because the centripetal force from the rod is always perpendicular to the motion, so the speed will not change. We can summarize this by saying that the angular acceleration of the particle is zero. This is analogous to Newton's first law of motion.

Now suppose we apply a force to the particle. Any component of the force perpendicular to its motion will be counter-balanced by the rod, so we only need consider a force parallel with the motion. This force will accelerate the particle according to Newton's second law, equation \eqref{n2l}. We also know that torque is related to force via $\tau = Fr$ and acceleration to angular acceleration via $a = r\alpha$. So we can rewrite Newton's second law as
$$(\tau / r) = (m)(r\alpha)$$
or, more suggestively,
\begin{equation} \label{n2l-rot}
\tau = I\alpha
\end{equation}
where $I = mr^2$ is called the \jargon{moment of inertia} for the particle. Equation \eqref{n2l-rot} represents the angular analog of Newton's second law.

For an extended rigid object, this formula is the same. Essentially, the extended object can be considered as a (large) collection of particles, so the moment of inertia in general is
$$I = \sum mr^2$$
\prep{If mass measures the tendency of an object to maintain its linear motion then this \hide{moment} of inertia measures the tendency of an object to maintain its angular motion.} The moment of inertia depends not only on the total mass but also on the distribution of that mass throughout the object. 

For simple shapes, the formula for the moment of inertia can be written in terms of the total mass. For example, a hollow sphere rotating through its center has a moment of inertia of $\frac{2}{3} M\!R^2$. See Table \ref{tbl:moment-of-inertia} for a more complete list.

\tbl[side]{moment-of-inertia}{lc}{
Ring & $M\!R^2$ \\
Disk & $\frac{1}{2} M\!R^2$ \\
Sphere & $\frac{2}{5} M\!R^2$ \\
Shell & $\frac{2}{3} M\!R^2$ \\
Rod (center) & $\frac{1}{12} M\!L^2$ \\
Rod (edge) & $\frac{1}{3} M\!L^2$ \\
}{Moment of inertia for various systems. See \href{http://en.wikipedia.org/wiki/List_of_moments_of_inertia}{here} for more.}

\label{ex:rotating-disk}

Consider the following example. A disk has a radius of 0.10 meters and a mass of 2.0 kilograms. It is attached on-center to a circular post (radius = 0.01 meters) which allows it to rotate horizontally (assume no friction). An ideal string is wound around the post and is attached to a 0.5-kilogram object that is hanging over a pulley. As this object falls, the disk rotates. After three seconds, how fast is the disk rotating? See Figure \ref{fig:rotating-disk}

\pics[side]{rotating-disk}{
\vspace{0.25in}
\begin{tikzpicture}
%\draw (-2.5,-0.3) rectangle (2.5,-3);
\draw [very thick] (0,0.5) -- (0,-0.3);
\draw [shade,left color=black!50,right color=black!00] (-2.0,0.1) rectangle (2.0,0.3);
\draw [shade,left color=black!50,right color=black!00] (-0.2,-0.1) rectangle (0.2,0.1);
\draw (-0.2,0) -- (3,0);
\draw (3,-0.2) circle (0.2);
\draw (3,-0.2) circle (0.05);
\draw (3.2,-0.2) -- (3.2,-1);
\fill (3,-1) rectangle +(0.4,-0.4);
\draw [->] (3.6,-0.8) -- +(0,-0.4) node [pos=0.5,right] {$a$};
\end{tikzpicture}
}{Rotating disk attached to a weight}

The disk begins rotating because of the torque applied from the string. Since this is a non-equilibrium problem, we should not assume the tension in the string equals the weight of the hanging object---it will be less because the mass falls. In fact, Newton's second law tells us that
$$T - mg = -ma$$
where $T$ is the tension in the string and $m$ is the mass of the hanging object. This is just like in the inclined plane example on page \pageref{ex:plane-and-pulley}. So we have a formula between the tension and the acceleration:
$$T = 9.8 - (0.5)(a)$$
Now consider the disk. For this we have Newton's second law in its angular form \eqref{n2l-rot}. The moment of inertia for a disk is $I = \half M\!R^2$, so for this problem we have
$$I = \half(2.0)(0.10)^2 = 0.020$$
The torque is from the tension in the string which it is applied to the post, so the lever arm is its radius:
$$\tau = (T)(0.01)$$
The angular acceleration of the disk can be gotten from equation \eqref{n2l-rot}:
$$(T)(0.01) = (0.020)(\alpha) \implies \alpha = (0.5)(T)$$
Using the previous expression for the tension yields
$$\alpha = 4.8990 - (0.25)(a)$$
Now, which radius do we use in $a = r\alpha$ to solve this equation? The acceleration of the block is equal to the tangential acceleration of the post because these are connected by the string. So, $a = (0.01)(\alpha)$. Since we are asked about the disk rather than the object, we should use this to solve for the the angular acceleration:
$$\alpha = 4.8990 - (0.02)(0.01)(\alpha)$$
So $\alpha = 4.8990$. In order to answer the question we should use the angular analog of equation \ref{pos-vel-sqr}:
$$\omega^2 = (0)^2 + (2)(4.8990)(3) \implies \omega = 5.4216$$
After three seconds the disk is rotating at 5.4 radians per second, or just under 52 rpm.

% Energy of rotation, angular momentum

Shall we do another? Suppose a sphere rolls down an incline of 30$\dg$ which is 4.0 meters long without slipping. How fast is it moving at the bottom of the incline?

For this one we will use energy. Since causing an object to rotate requires work, we expect a formula similar to equation \eqref{kin-ene-lin} for the kinetic energy of rotation:
$$KE_\text{rot} = \half I\omega^2$$
In this case, all the initial energy is potential. The sphere is at a height of 2.0 meters, so its potential energy is
$$PE = (m)(9.8)(2.0) = (19.6)(m)$$
At the bottom of the slope this potential energy is converted into kinetic, but the kinetic energy is split between linear motion and rotation:
$$(19.6)(m) = \half mv^2 + \half I\omega^2$$
We know the sphere does not slip, so we also have $v = r\omega$ and the moment of inertia for a sphere is $\frac{2}{5}M\!R^2$. Since we are asked for the speed we combine these to write
$$(19.6)(m) = \half mv^2 + \half (\tfrac{2}{5}mr^2)(v/r)^2$$
or,
$$19.6 = \tfrac{7}{10}v^2$$
The final speed will be 5.3 meters per second. This speed is independent of the mass and radius of the sphere.

In addition to kinetic energy we also have a rotational analog for momentum. The \jargon{angular momentum} of a system is
\begin{equation} \label{ang-mom}
L = I\omega
\end{equation}
which just like linear momentum is conserved in any collision (assuming no external torque). This conservation is why it is easier to ride a bike that is moving than balancing on one that is stationary. Once the angular momentum of the wheels is built up, they tend to continue rotating along the same axis.

% Free rotation and the moment of inertia tensor

That completes the analogy between linear motion and rotation. Except we have only scratched the surface. So far we have only discussed rotation in a plane with a fixed axis. We have yet to talk about free rotation. In general as an object tumbles it rotates with a wobble. In order to understand this we will need to refine our description of rotation. 

Since each rotation involves a magnitude (the angular speed) and a direction (the axis of rotation), we can talk about it like a vector. For fixed rotation in a plane, this vector points out of the plane.\footnote{Whether it point out or in is arbitrary. It is conventional to consider the vector as pointing at you when you are looking at counter-clockwise rotation. This is consistent with the $xyz$ axes in the sense that rotation from the positive $x$-direction to the positive $y$-direction points in the positive $z$-direction.} In addition, we can associate angular acceleration, torque, and angular momentum with vectors.

How then do we explain the wobble? It happens that, for any shape object, there are certain \jargon{principal axes} about which the object will rotate without this wobble. In this case the angular velocity vectors and the angular momentum vectors are aligned. For rotation off of these axes, the two are not aligned. The distribution of the mass throws off the balance of the rotation. 

\prep{Since the distribution of mass is captured in the moment of inertia, the angular momentum captures both the \hide{rotation} and this distribution.} And since the angular momentum is the conserved quantity (assuming no external forces), the angular velocity will have a tendency to rotate about the angular momentum. This twirling of the axis of rotation is called \jargon{gyroscopic precession}. 

\prep{This is why you will sometimes see the moment of inertia mentioned as a \hide{tensor}: it is the thing that connects the two vectors. It converts the angular velocity into the angular momentum.} For fixed rotation it is enough to consider this as a simple scalar multiplication. But for the complications associated with free rotation we need the full power of tensors to describe the dynamics.

Consider a wheel that is bent on its axle like Figure \ref{fig:bent-axle}. The angular momentum $L$ is aligned with the wheel, but the angular velocity $\omega$ is aligned with the axle. The axle must torque the angular momentum vector around the angular velocity. Newton's third law says that the wheel will also torque the axle. These extra torques cause the jarring vibrations experienced with such a bent axle. 

\tikzfig[side]{bent-axle}{
\begin{tikzpicture}
\draw [shade,bottom color=black!50,top color=black!00] (-1,-0.1) rectangle (1,0.1);
\draw [->] (0,0) -- (2,0) node [pos=1,right] {$\omega$};
\begin{scope}[rotate=-10]
\draw [shade,bottom color=black!50,top color=black!00] (-0.2,-2) rectangle (0.2,2); 
\draw [dashed] (-0.6,1.6) rectangle +(0.4,0.4);
\draw [dashed] (0.6,-1.6) rectangle +(-0.4,-0.4);
\draw [->] (0,0) -- (2,0) node [pos=1,right] {$L$};
\end{scope}
\end{tikzpicture}
}{Example of dynamic balancing}

One solution called \jargon{dynamic balancing} involves adding additional mass (indicated by the dashed squares) in order redistribute the mass and pull the angular momentum vector in line with the rotation. Mathematically, this balancing is done by examining the tensor components of the moment of inertia and figuring out where and how much mass is required to create stability.

This is free rotation without any external forces. If an external force is present it can cause \jargon{nutation} which is a slight vibration in the precession of the rotating object. This nutation is sometimes observable in a gyroscope as a slight up and down ``nodding'' as it precesses. In this case the nutation is caused by the weight of the gyroscope pulling down.

\prep{The rotation of the \hide{earth} exhibits both \href{http://en.wikipedia.org/wiki/Precession_(astronomy)\#Astronomy}{precession} and \href{http://en.wikipedia.org/wiki/Nutation\#Of_the_Earth}{nutation}.} The earth is not quite spherical (bulges out at the equator) which causes a precession of its rotation---this means that the north pole is slowing moving away from the north star. The precession period is 26,000 years and was large enough to be noticed by the ancient astronomers. The nutation in the earth's rotation is much smaller in magnitude. The largest contribution is from the moon's gravitation and has a period of about 18.6 years.

% Preview for next week

Next week we will discuss celestial mechanics. We will need all of the mechanical tools we have developed so far to truly analyze the motion of the planets. We will talk about how to analyze the elliptical pattern of orbits and how this relates to energy and angular momentum. We will also see how these parameters are manipulated by space probes to move about the solar system. To top it off we will touch on how general relativity corrects Newton's law of gravity for extremely dense objects like black holes.
========
11:celestial-mechanics
--------
Celestial Mechanics
--------
Review lectures \ref{ch:circular-motion}, \ref{ch:energy}, \ref{ch:rotation}, and \ref{ch:torque}
--------
% Kepler's three laws

We've already shown how Newton's law of gravity, equation \eqref{n4l} can be used to establish Kepler's third law (see page \pageref{idx:Kepler's three laws}). We can now show that the second law follows from the conservation of angular momentum. 

The moment of inertia for a particle rotating about an axis is simply $mr^2$ where $r$ is the distance from the axis. The angular momentum of this particle is therefore
\begin{equation} \label{particle-ang-mom}
L = (mr^2)(\omega) = mrv_t
\end{equation}
where we have used the fact that $v_t = r\omega$. 

If we look at the position of the particle between two points in time we will get a diagram like Figure \ref{fig:keplers-second}. The triangle defined by these positions has a height equal to $v_t \; \Delta t$ and we can say it has a base equal to $r$. So this area is given by
$$A = \half rv_t \; \Delta t = \half (L/m) \; \Delta t$$

\tikzfig[side]{keplers-second}{
\begin{tikzpicture}
\fill (0,0) circle (0.1);
\fill [black!20] (3,3) -- (3.45,2.55) -- (4,3);
\draw [dotted] (0,0) -- (3,3) node [pos=0.5,above left] {$r_1$};
\draw [dotted] (0,0) -- (4,3) node [pos=0.5,below right] {$r_2$};
\draw [->] (3,3) -- (4,3) node [pos=0.5,above] {$v \; \Delta t$};
\draw [] (3,3) -- (3.45,2.55);
\path (3,3) -- (3.45,2.55) node [pos=0.5,pin={[pin distance=10mm]180:{$v_t \; \Delta t$}}] {};
\end{tikzpicture}
}{Kepler's second law and angular momentum}

\prep{Since the force of gravity is central, its line of action runs through the central point. This means it has no lever arm and produces no torque. As a consequence, the angular \hide{momentum} is conserved. Therefore the area swept out by the radius vector is equal for equal time periods---which is Kepler's second law.}

Kepler's first law is more difficult to derive. We'll skip the proof and move on to learning a few things about calculating with ellipses.

% Conics and polar coordinates

For problems in celestial mechanics, it is easiest to use polar coordinates. In order to consider problems relevant to Kepler's first law, we will consider an ellipse with its focus at the origin of a system of polar coordinates. In addition, assume the $\theta = 0\dg$ line is aligned with major axis of the ellipse like in Figure \ref{fig:ellipse-vocab}.

\tikzfig{ellipse-vocab}{
\begin{tikzpicture}[scale=0.8]

\coordinate (dx) at ( 0:0.2);
\coordinate (dy) at (90:0.2);

\coordinate (a)  at ( 4,0);
\coordinate (b)  at ( 0,3);
\coordinate (c)  at ( 0,0);
\coordinate (r1) at (a);
\coordinate (r0) at ($(a)!2!(c)$);
%%...f^2 = a^2 - b^2...%% f = sqrt(7) < 2.65
\coordinate (f1) at (-2.65,0);
\coordinate (f2) at ( 2.65,0);

\draw (0,0) ellipse (4.0 and 3.0);
%\node [draw=red,fill=yellow,starburst] at (f1) {};
\node [draw,starburst] at (f1) {};

%\fill (f1) circle (0.1) node [pin=135:{Focus}] {};
\fill (f1) circle (0.05) node [below=5mm] {Focus};
\fill (c) circle (0.05) node [pin=0:{Center}] {};
\fill (r0) circle (0.05) node [pin=135:{Perihelion}] {};
\fill (r1) circle (0.05) node [pin=45:{Aphelion}] {};

\draw [|-|] ($+1*(b)+3*(dy)$) +(r0) -- +(f1) node [pos=0.5,above=1mm] {$r_0$};
\draw [ -|] ($+1*(b)+3*(dy)$) +(f1) -- +(r1) node [pos=0.5,above=1mm] {$r_1$};
\draw [dotted] (f1) -- +($+1*(b)+2*(dy)$);

\draw [|-|] ($-1*(b)-3*(dy)$) +(r0) -- +(c)  node [pos=0.5,below=1mm] {$a$};
\draw [ -|] ($-1*(b)-3*(dy)$) +(c)  -- +(r1) node [pos=0.5,below=1mm] {$a$};
\draw [dotted] (c)  -- +($-1*(b)-2*(dy)$);

\node (P) at (b) [circle,draw,fill=white,inner sep=0.1cm] {};
\draw [->] (f1) -- node [above left] {$r$} (P);
\draw [->] ($(f1)+(0:1)$) arc (0:48:1);
\node at ($(f1)+(24:1.3)$) {$\theta$};

\end{tikzpicture}
}{Key parameters and definitions for an ellipse}

\prep{The point of closest approach for the planet is called \jargon{perihelion}. The suffix ``helion'' refers to the \hide{sun}.} If we are talking about orbiting the earth, the correct term would be perigee (the general term is periapsis). We will give this the label $r_0$.

On the opposite side of the ellipse we have the \jargon{aphelion} which is the point of farthest excursion. For the earth we say ``apogee'' and in general we say ``apoasis''. We will label this point $r_1$.

Both of these points lie on the major axis of the ellipse. So these three parameters are related by the following formula:
\begin{equation} \label{semi-major}
r_0 + r_1 = 2a
\end{equation}
where $a$ is the semi-major axis (i.e., half of the major axis).

The equation that describes the shape of the ellipse in polar coordinates is
\begin{equation} \label{polar-ellipse}
r = r_0 \dfrac{1 + e}{1 + e \cos \theta}
\end{equation}
where $e$ is called the \jargon{eccentricity} of the ellipse. An eccentricity of zero corresponds to a perfect circle. \prep{Ellipses are characterized by an eccentricity less than one---the larger the number, the \hide{flatter} the shape.}\footnote{We can incorporate unbound orbits by allowing the eccentricity to be greater than one.} Notice that equation \eqref{polar-ellipse} does not involve time. This is merely an equation to describe the geometry of the path.

The more eccentric the ellipse, the farther the focus is from the center. This distance is half of $r_1 - r_0$. It happens that the formula for the eccentricity is
\begin{equation} \label{eccentricity}
e = \frac{r_1 - r_0}{r_1 + r_0}
\end{equation}
which is just this distance normalized by the semi-major axis of the ellipse.

\prep{The ellipse is characterized geometrically by the parameters $a$ (the \hide{size} of the ellipse) and $e$ (the shape of the ellipse).} Equations \eqref{semi-major} and \eqref{eccentricity} show how to move back and forth between these parameters and the observable parameters $r_0$ and $r_1$. These facts are the bare minimum we need in order to understand the basics of celestial motion.

% The effective potential for a planet

Now we are ready to discuss some dynamics. The potential energy function for gravity is given by equation \eqref{n4l-potential}. \prep{It is possible to reduce the two-dimensional motion of the planet to one dimension by using a \hide{rotating} reference frame tied to the planet.} Use of this frame will introduce a centrifugal force given by equation \eqref{centrifugal-force}. We can use the conservation of angular momentum to eliminate the angular velocity from this expression. Since $L = mr\omega^2$, we have
$$F_\text{cfg} = \frac{L^2}{mr^3}$$
This is similar to the formula for gravity \eqref{n4l} and there is a corresponding ``potential energy'' associated with it. If we combine this with the potential energy for gravity, we have the following:
\begin{equation} \label{eff-pot-newton}
U = -\frac{GMm}{r} + \frac{L^2}{2mr^2}
\end{equation}
This is called the \jargon{effective potential} and acts as the potential energy for the radial motion of the planet. (See Figure \ref{fig:eff-pot-newton}). \prep{Any orbital energy above the effective potential is \hide{kinetic}. Remember this is the kinetic energy associated with the radial motion not the angular motion.} The centrifugal term is the manifestation of the angular motion. In fact, using equation \eqref{particle-ang-mom} one can see that the centrifugal ``potential'' can also be written at $\half mv_t^2$. So this term can be seen as either potential or kinetic.

\tikzfig{eff-pot-newton}{
\begin{tikzpicture}

\coordinate (dx) at ( 0:0.2);
\coordinate (dy) at (90:0.2);

\draw [->] (0,0) -- (8,0) node [right] {$r$};
\draw [->] (0,-3) -- (0,3) node [above] {$E$};

\draw [domain=1:7,samples=100,dashed] plot (\x,-3/\x);
\node at (1.5,-2.00) [pin=-45:{Inverse square law: $-GMm/r$}] {};
\draw [domain=1:7,samples=100,dashed] plot (\x,3/\x^2);
\node at (1.5,1.33) [pin=45:{Centrifugal force: $L^2/2mr^2$}] {};
\draw [domain=0.6:7,samples=100,thick] plot (\x,-3/\x+3/\x^2);
\coordinate (Emin) at (2,-0.75);

\draw [dotted] (-0.1,-0.5) node [left] {$E_0$} -- (8,-0.5);
\draw (0,-0.5) +(-0.1,0) -- +(0.1,0) node [pos=0,left] {$E_0$};
\coordinate (r0) at ({3-sqrt(3)},-0.5);
\coordinate (r1) at ({3+sqrt(3)},-0.5);
\draw (r0) +(0,0.4) -- +(0,0.6) node [above,fill=white] {$r_0$};
\fill (r0) circle (0.1);
\draw (r1) +(0,0.4) -- +(0,0.6) node [above,fill=white] {$r_1$};
\fill (r1) circle (0.1);
\draw [fill=white] (Emin) circle (0.1);
\node at (Emin) [pin=225:{$E_\text{min}$}] {};

\end{tikzpicture}
}{The effective potential for gravity}

Note that the effective potential depends implicitly on the angular motion of the planet through the angular momentum $L$. The faster it rotates, the larger the centrifugal term, and the farther away will be the point of closest approach. The minimum point ($E_\text{min}$) on the effective potential corresponds to a purely circular orbit because the radius does not change---it has no kinetic energy of motion in the radial direction.

% Dynamic and orbital parameters

\prep{The effective potential gives us enough \hide{information} to connect the motion of the planet to its dynamics.} Specifically we can determine the relationship between the orbital energy and angular momentum (the dynamical parameters) to its perihelion and aphelion because they are the turning points on the energy diagram. We have already seen that these points are directly related to the eccentricity and semi-major axis of the ellipse (the orbital parameters).

The turning points are determined by setting the effective potential equal to the total orbital energy of the planet and solving for $r$. But the effective potential \eqref{eff-pot-newton} makes it look like the orbit of the planet depends on its mass, which it does not. The acceleration due to gravity is independent of the mass of the object, so should the orbit of the planets. In order to emphasize this, let's introduce the ``reduced'' quantities $E' = E/m$ and $L' = L/m$. In fact, I'll even drop the primes and simply use the reduced versions because we rarely need to know the original ones. Multiplying both sides by $2mr^2$ and rearranging yields the quadratic equation we now need to solve:
$$2Er^2 + 2GMr - L^2 = 0$$
Determining both the eccentricity and the semi-major axis involve the sum and difference of the solutions to this equation.\footnote{For a general quadratic equation, $ax^2 + bx + c = 0$, the sum of the solutions is $-b/a$ and their difference is $\sqrt{(b/2a)^2 - (c/a)}$.} For the sum we have:
$$r_1 + r_0 = -GM/E$$
and the difference is:
$$r_1 - r_0 = \sqrt{\left( \frac{GM}{2E} \right)^2 + \frac{L^2}{2E}}$$
The semi-major axis of the ellipse is half the sum of the perihelion and aphelion \eqref{semi-major}, so
\begin{equation} \label{semi-major-calc}
a = -GM/2E
\end{equation}
and the eccentricity is the ratio of the difference to the sum \eqref{eccentricity}, so
\begin{equation} \label{eccentricity-calc}
e = \sqrt{\frac{1}{4} + \frac{E L^2}{2(GM)^2}}
\end{equation}
These results are enough for us to start working some problems.

\label{ex:rocket-blast}

Consider a rocket satellite orbiting around the earth in a circular orbit with radius of $\sci{4.5}{7}$ m. A sudden blast of the rocket motor increases the speed by 15\% in the direction of motion. See Figure \ref{fig:rocket-blast}. Find (a) the maximum distance of the rocket, and (b) the eccentricity of the new orbit. % Give credit...

\tikzfig[side]{rocket-blast}{
\begin{tikzpicture}[scale=0.5,rotate=-90]
\fill [black!20] (0,0) circle (0.2);
\draw (0,0) circle (3);
\path [dotted] (0,0) -- (0:3) node [pos=0.3,fill=white] {$r_0 = \sci{4.5}{7}$};
\draw (-2,0) ellipse (5 and 4.5);
\draw [dotted] (0,0) -- (180:7) node [pos=0.6,fill=white] {$r_1$};
\draw [fill=black!20] (3,0) +(-0.1,-0.3) -- +(-0.1,0.2) -- +(0,0.3) -- +(0.1,0.2) -- +(0.1,-0.3) -- cycle;
\draw [->] (3,0) +(0.3,-0.5) -- +(0.3,0.5) node [below,pos=0.5] {$\Delta v = 0.15 \; v_0$};
\end{tikzpicture}
}{Rocket blast problem}

Ever thought you'd be a rocket scientist? The quantity $GM$ occurs frequently, so let's make a note of the product:
\begin{align*}
GM &= (\sci{6.673}{-11})(\sci{5.9742}{24}) \\
   &= \sci{3.9866}{14}
\end{align*}
In this case $M$ is the mass of the earth. Back in Lecture \ref{ch:circular-motion}, we discussed Kepler's third law. In the process we derived the formula $GM = rv^2$ for circular orbits (see page \pageref{123-law}). We can use this to determine the velocity of the satellite before the blast.
\begin{gather*}
(\sci{3.9866}{14}) = (\sci{4.5}{7})(v_0)^2 \\
\implies v_0 = 2976.4
\end{gather*}
The blast occurs in the direction of motion, so all of the $\Delta v$ is tangential and the velocity after the blast must be
$$v = (1.15)(v_0) = 3422.9$$
Since the new orbit is not circular, the speed of the satellite will not always have this value. However, this point does now act as perigee for the new orbit (see Figure \ref{fig:rocket-blast}). Since we know the distance and velocity at this point, we can calculate the reduced energy and angular momentum.

There are a couple of ways to get at the total (reduced) energy, but perhaps the simplest is to simply take the sum of the (reduced) kinetic and potential energies:
\begin{align*}
E &= \half v^2 - GM/r \\
  &= \half(3422.9)^2 - \frac{\sci{3.9866}{14}}{\sci{4.5}{7}} \\
  &= -\sci{3.0010}{6}
\end{align*}
The energy is negative because the satellite is still in a bound orbit. The angular momentum is also straight-forward to calculate because at perigee (and apogee) all the velocity is tangential.
\begin{align*}
L &= rv_t \\
  &= (\sci{4.5}{7})(3422.9) \\
  &= \sci{1.5403}{11}
\end{align*}
Having calculated the dynamical parameters for the orbit, it remains to determine the orbital parameters. Using equation \eqref{semi-major-calc}, we get
\begin{align*}
a &= -\frac{(\sci{3.9866}{14})}{(2)(-\sci{3.0010}{6})} \\
  &= \sci{6.6421}{7}
\end{align*}
Now equation \eqref{semi-major} yields the apogee:
$$r_1 = \sci{8.7842}{7}$$
And equation \eqref{eccentricity} yields the eccentricity:
$$e = 0.32251$$
So, the final answer is $\sci{8.8}{7}$ meters for farthest excursion and the orbit has an eccentricity of 0.32.

% Perturbed orbits and precession

When we talk about the motion of the planets, Kepler's laws are a good first approximation---they describe the motion of each planet around the sun. What they don't take into account is the interaction between the planets. For example, the pull of Jupiter will cause each other planet to deviate slightly from a pure Keplerian ellipse.

\prep{In general, any slight \hide{deviation} from the central inverse square law will manifest itself as a slight \jargon{orbital precession}.} That is, the axis of the ellipse will itself slowly rotate causing the orbit to not quite close, like a spirograph. In Figure \ref{fig:orbital-precession} this angle is denoted by measuring the movement of aphelion, although it is typically easier to measure the precession of perihelion.

\tikzfig[side]{orbital-precession}{
\begin{tikzpicture}[scale=0.7]

\pgfmathsetmacro{\ecc}{0.5};
\pgfmathsetmacro{\per}{2};
\pgfmathsetmacro{\pre}{30};

\draw[domain=60:600,smooth,samples=100,variable=\t] plot
   ({cos(\t)*\per*(1+\ecc)/(1+(\ecc*cos(\t*(1+\pre/360))))},
    {sin(\t)*\per*(1+\ecc)/(1+(\ecc*cos(\t*(1+\pre/360))))});

%\draw [dotted] (0,0) circle (2);
%\draw [dotted] (0,0) circle (6);
\filldraw [dashed] (0,0) -- (165:6) circle (0.1);
\filldraw [dashed] (0,0) -- (135:6) circle (0.1);
\filldraw [dashed] (0,0) -- (165:-2) circle (0.1);
\filldraw [dashed] (0,0) -- (135:-2) circle (0.1);
%\draw (165:1) arc (165:135:1);
\node [fill=white] at (152:3) {$\Delta \phi$};
\node [draw,fill=white,starburst] at (0,0) {};

\end{tikzpicture}
}{Measuring orbital precession}

With the improvement in observations and calculations over time, the orbits of all the planets were explained---including the discovery of Neptune and Pluto. By the middle of the 19th century, the slight irregularities and precession in Kepler's orbits were fully explained by Newton's law of gravity, except one. After taking into account all effects, there still remained a 43 arc-second per century precession in Mercury's orbit unaccounted for (this is a little over 7\% of the total precession observed). This discrepancy was unresolved until 1916 and Einstein's general relativity.

% Relativistic corrections; black holes

\tikzfig{eff-pot-einstein}{
\begin{tikzpicture}

\coordinate (dx) at ( 0:0.2);
\coordinate (dy) at (90:0.2);

\draw [->] (0,0) -- (8,0) node [right] {$r$};
\draw [->] (0,-3) -- (0,3) node [above] {$E$};

\draw [domain=0.6:7,samples=100,dashed] plot (\x,-3/\x+3/\x^2);
\node at (0.7,2) [pin=45:{Newtonian gravity}] {};

\draw [domain=0.28:1,samples=100,thick] plot (\x,-3/\x+3/\x^2-0.67/\x^3);
\draw [domain=1:7,samples=100,thick] plot (\x,-3/\x+3/\x^2-0.67/\x^3);

\draw [dotted] (-0.1,-0.5) node [left] {$E_0$} -- (8,-0.5);
\draw (0,-0.5) +(-0.1,0) -- +(0.1,0) node [pos=0,left] {$E_0$};
\coordinate (r0) at ({3-sqrt(3)-0.42},-0.5);
\coordinate (r1) at ({3+sqrt(3)},-0.5);
\coordinate (Emin) at (1.47,-0.87);

\fill (r0) circle (0.1);
\fill (r1) circle (0.1);
\draw [fill=white] (Emin) circle (0.1);

\end{tikzpicture}
}{The effective potential in general relativity}

Although general relativity requires a significant amount of math to fully appreciate, we can learn a bit about its consequences. For us, the easiest impact to see is on the effective potential. General relativity adds a new term to the calculation. The complete (reduced) effective potential is\footnote{This equation is exact---no slow speed or small mass approximation is necessary.}
\begin{equation} \label{eff-pot-einstein}
U = -\frac{GM}{r} + \frac{L^2}{2r^2} - \frac{GM}{c^2} \frac{L^2}{r^3}
\end{equation}
This revised effective potential is plotted in Figure \ref{fig:eff-pot-einstein}. The third term causes a precession which Einstein calculated as
\begin{equation} \label{relativistic-precession}
\Delta \phi = \frac{6\pi}{a(1 - e^2)} \frac{GM}{c^2}
\end{equation}
where $a$ and $e$ are the semi-major axis and eccentricity of the orbit, respectively. This formula explains the anomalous precession of Mercury and was one of the three initial successes of Einstein's new theory of gravity.\footnote{The other two were gravitational redshift and the deflection of starlight.} \prep{The quantity $GM/c^2$ is characteristic of the effects of \hide{general} relativity.}

\prep{You can see that the new term predicts a slightly \hide{stronger} law of gravity than Newton's. Ultimately this comes from the fact that $E = mc^2$, so the gravitational field itself acts as a source of gravity.} Both the equilibrium point and perihelion are pulled a little closer. But more dramatically, if the incoming object has sufficient energy the gravitation well will capture it regardless of the centrifugal force.

This point of no return is called the Schwarzschild radius, $r_s = 2GM/c^2$. If an object is crushed below its own Schwarzschild radius, it will not be able to prevent its own collapse---a \jargon{black hole} will result. That is why this distance is traditionally called the radius of a black hole even though it really does not have any extension. Notice that black holes do not require a lot of mass---what they require is an extremely dense mass.

% General relativity

Of course, black holes are only one of the dramatic predictions of general relativity. We don't have time to cover them all: curvature of space-time, gravitational waves, expansion of the universe, the existence of ``dark energy''.\footnote{See Lecture \ref{ch:elasticity} and \ref{ch:em-and-relativity} for more info.} General relativity has withstood the test of time and stands today as one of the two pillars of fundamental physics.\footnote{The standard model is the other pillar which we will cover in Lecture \ref{ch:high-energy}.} It also represents the end the road for this term regarding the motion of simple objects.
========
12:harmonic-motion
--------
Harmonic Motion
--------
Read sections 10.1--10.6
--------
% The ubiquity of stable equilibrium and vibration

In Lecture \ref{ch:energy} we discussed the fact that nearly all physical systems sit in a state of stable equilibrium (see page \pageref{ubiquity-of-stable-equilibrium}). \prep{A state is in stable equilibrium if the \hide{internal} forces of the system tend to push it back into that state. This must be true along all the degrees of freedom for the system.} For example, a rigid object is in equilibrium only if both the forces and the torques in the system are balanced (see Lecture \ref{ch:torque}).

If the system is somehow displaced from this point of equilibrium, it will be pushed back. As the system returns to this equilibrium state, its inertia will tend to carry it through and past equilibrium. So the system touches its equilibrium only to move away in the opposite direction. Eventually the forces in the system become large enough to overcome the inertia of the motion, bring it to a stop, and push it back toward equilibrium. Eventually the system will be back to the displaced state in which it started. And the cycle repeats over and over. This back-and-forth motion is called \jargon{vibration} and a system can vibrate along any of its degrees of freedom, whether that is a spring, a string, the surface of a drum, a metal beam, a column of air, or the electromagnetic field. 

\prep{The maximum extent of the \hide{displacement} is called the \jargon{amplitude} of the motion and the time it takes for one complete cycle is called the \jargon{period} of the motion.} It is no coincidence that this is the same term we used in Lecture \ref{ch:circular-motion}. \prep{The reciprocal of the \hide{period} is called \jargon{frequency} and its unit is the \jargon{hertz}---so when the vibration of a system is said to have a frequency of 10 hertz, we mean that its motion repeats 10 times each second.}

% An ideal spring, Hooke's law \ldots ``everything is linear to first order''

The simplest example of a vibrating system is a spring with one end attached to a fixed point and the other end attached to a certain mass. We will assume the spring is oriented horizontally to ignore gravity and we will assume the mass slides without friction (see Figure \ref{fig:simple-spring}).

\tikzfig[side]{simple-spring}
{
\begin{tikzpicture}
\draw (0,1) -- (0,-0.6);
\draw (0,0) -- (0.5,0);
%\draw [decorate,decoration={zigzag,amplitude=2mm,segment length=4mm}] (0.5,0) -- (2.5,0);
\draw [decorate,decoration={coil,aspect=0.5,amplitude=2mm,segment length=2mm}] (0.5,0) -- (2.5,0);
\draw (2.5,0) -- (3,0);
\draw (3,-0.5) rectangle +(1,1);
\draw [fill=white] (3.2,-0.5) circle (0.1);
\draw [fill=white] (3.8,-0.5) circle (0.1);
\draw (0,-0.6) -- +(4.5,0);
\end{tikzpicture}
}{The simplest vibrating system: an ideal spring}

This system is in equilibrium when the spring is not stretched. We define the position of the mass to be zero at this point. Any displacement to the right will be positive, and any displacement to the left will be negative. In either case, the spring will exert a force that will tend to restore the mass to equilibrium. In other words, the mass will experience a force that is in opposition to its displacement. The spring is considered an \jargon{ideal spring} if the magnitude of this force is exactly proportional to the displacement. In symbols, the restorative force of an ideal spring is
\begin{equation} \label{hooke}
F = -kx
\end{equation}
where $k$ is called the \jargon{spring constant} and is measured in newtons-per-meter and this equation is frequently called \jargon{Hooke's Law}. The motion of a mass subject to this force law is called \jargon{simple harmonic motion}.

%It happens to be the case that any real spring can be considered ideal if the displacement involved is not too large. In fact, this is also true of any system. The restorative forces involved in stable equilibrium can always be considered linear---i.e., obeying equation \eqref{hooke}---if the displacement from equilibrium is sufficiently small.\footnote{This is related to the definition of the derivative: see Lecture \ref{ch:overview}, equation \eqref{dfn-derivative}.}

% A fortunate fluke: uniform circular motion versus simple harmonic motion

When our simple mass-and-spring system is vibrating, the restorative force will change in time as it responds to the motion of the mass. This means that the constant acceleration equations from Lecture \ref{ch:kinematics} will not be applicable to this system. We need a different way to analyze this kind of vibrating motion. This is similar to the situation we faced in Lecture \ref{ch:circular-motion} with uniform circular motion, except we now know the force but not the mathematics of the motion.

All is not lost. By a fortunate fluke, we can leverage our learnings from Lecture \ref{ch:circular-motion} to help us now. Consider the projection of uniform circular motion onto the $x$-axis. Figure \ref{fig:ucm-projected} shows the essential correspondences.

\tikzfig[full]{ucm-projected}
{
\begin{tikzpicture}[scale=2]
\def\ang{30}
\def\rad{1}
\def\vel{0.7}
\def\acc{0.7*0.7}
\def\bot{-1.5\rad}

%%%%%%%% ucm-to-shm-position %%%%%%%%
\begin{scope}[xshift=0mm]
% This shades the projection
\fill [black!10] (\ang:1) -- (0,0) |- ({cos(\ang)},\bot) -- cycle;
% This is the circular motion
\draw [help lines] (0,0) circle (\rad);
\draw [dotted] (0,0) -- (0:\rad);
\draw [->,very thick] (0,0) -- (\ang:\rad);
\draw [fill=white] (\ang:\rad) circle (0.05);
\node at (0,1.5\rad) {$r = A \quad ; \quad \theta = \omega t$};
% This is the projected motion
\draw [|-|,help lines] (-\rad,\bot) -- (\rad,\bot);
\draw [->,very thick] (0,\bot) -- +({cos(\ang)},0);
\draw [fill=white] ({cos(\ang)},\bot) circle (0.05);
\node at (0,\bot) [below=4mm] {$x(t) = A \cos (\omega t)$};
\node at (0,\bot) [below=10mm] {$x_\text{max} = A$};
\end{scope}

%%%%%%%% ucm-to-shm-velocity %%%%%%%%
\begin{scope}[xshift=30mm]
% This shades the projection
\fill [black!10] (\ang:1) -- +(90+\ang:\vel) |- ({cos(\ang)},\bot) -- cycle;
% This is the circular motion
\draw [help lines] (0,0) circle (\rad);
\draw [dotted] (0,0) -- (\ang:\rad);
\draw [->,very thick] (\ang:\rad) -- +(90+\ang:\vel);
\draw [fill=white] (\ang:\rad) circle (0.05);
\node at (0,1.5\rad) {$v = \dfrac{2 \pi r}{T} = A \omega$};
% This is the projected motion
\draw [|-|,help lines] (-\rad,\bot) -- (\rad,\bot);
\draw [->,very thick] ({cos(\ang)},\bot) -- +({\vel*cos(90+\ang)},0);
\draw [fill=white] ({cos(\ang)},\bot) circle (0.05);
\node at (0,\bot) [below=4mm] {$v(t) = A \omega \sin (\omega t)$};
\node at (0,\bot) [below=10mm] {$v_\text{max} = A \omega$};
\end{scope}

%%%%%%%% ucm-to-shm-acceleration %%%%%%%%
\begin{scope}[xshift=60mm]
% This shades the projection
\fill [black!10] (\ang:1) -- +(180+\ang:\acc) |- ({cos(\ang)},\bot) -- cycle;
% This is the circular motion
\draw [help lines] (0,0) circle (\rad);
\draw [dotted] (0,0) -- (\ang:\rad);
\draw [->,very thick] (\ang:\rad) -- +(180+\ang:\acc);
\draw [fill=white] (\ang:\rad) circle (0.05);
\node at (0,1.5\rad) {$a = \dfrac{v^2}{r} = A \omega^2$};
% This is the projected motion
\draw [|-|,help lines] (-\rad,\bot) -- (\rad,\bot);
\draw [->,very thick] ({cos(\ang)},\bot) -- +({\acc*cos(180+\ang)},0);
\draw [fill=white] ({cos(\ang)},\bot) circle (0.05);
\node at (0,\bot) [below=4mm] {$a(t) = -A \omega^2 \cos (\omega t)$};
\node at (0,\bot) [below=10mm] {$a_\text{max} = A \omega^2$};
\end{scope}
\end{tikzpicture}
}{Uniform circular motion versus simple harmonic motion}

\prep{The position of the particle in uniform circular motion is specified by its radius and its angle. Since the motion is \hide{uniform}, the angle increases at a constant rate, so we have $\theta = \omega t$, where $\omega$ is the angular speed of the particle.} The projection of this position onto the $x$-axis involves a right triangle. The diagrams on the bottom of Figure \ref{fig:ucm-projected} show this projection: the position of this particle is given by 
\begin{equation} \label{shm-pos}
x(t) = A \cos \omega t
\end{equation}
where we have also relabeled the radius as $A$ since this is also the amplitude of the projected motion.

In Lecture \ref{ch:circular-motion} we found that \prep{the acceleration in uniform circular motion is directed in toward the center. Since this is directly opposed to the position vector, the same is true in the projection. That is, the acceleration is opposed and \hide{proportional} to the position. This is precisely the kind of connection we expect with an ideal spring.}

In fact, we can say more. We know that the speed of the uniform circular motion is related to the radius and period of the motion via $v = 2 \pi r / T$. By definition, the angular speed is the $2\pi$ radians divided by the time period $T$, so we can rewrite this as $v = A \omega$. (This should also remind you of the formula for tangential velocity \eqref{tangential-velocity} in Lecture \ref{ch:rotation}.) Since this velocity vector is pointing perpendicular to the position vector, the projection of the velocity is given by
\begin{equation} \label{shm-vel}
v(t) = A \omega \sin \omega t
\end{equation}
The formula for the acceleration in uniform circular motion is from equation \eqref{ucm}. Using our work so far, we can rewrite this as 
$a = A \omega^2$. Since the projection is opposed to the displacement, the formula for the acceleration of simple harmonic motion is given by
\begin{equation} \label{shm-acc}
a(t) = -A \omega^2 \cos \omega t
\end{equation}
We can get to this same spot without the analogy to circular motion using a bit of calculus. Those of you familiar with those techniques will recognize the connections between the sinusoidal functions here. In either case, equations \eqref{shm-pos}--\eqref{shm-acc} describe the kinematics of simple harmonic motion.

In the preceding, we have assumed the particle begins at its point of maximum extension. We can remove this restriction by adding an extra term to equation \eqref{shm-pos}:
\begin{equation} \label{shm}
x(t) = A \cos (\omega t + \phi)
\end{equation}
\prep{The quantity $\phi$ is called the \jargon{phase shift} and will become important when we discuss \hide{wave} interference} in Lecture \ref{ch:waves-interference}. Any system which obeys equation \eqref{shm} is called a \jargon{simple harmonic oscillator}.

% The mathematics of simple harmonic motion

It remains to connect these considerations with the parameters of our ideal spring system. We can put together Hooke's law \eqref{hooke} with Newton's second law \eqref{n2l} to get 
$$-kx = ma$$
After plugging in the results from equations \eqref{shm-pos} and \eqref{shm-acc} and simplifying we get
\begin{equation} \label{kmw2}
k = m \omega^2
\end{equation}
This little equation is an important summary of the dynamics of the ideal spring. In general, any vibrating system will have a similar equation connecting the parameters of the system to the frequency of its motion. The value of $\omega$ is called  \jargon{angular frequency} to distinguish it from the vibration frequency defined earlier. Because there are $2\pi$ radians in each cycle, the two quantities are simply connected by the equation $\omega = 2 \pi f$. So, we can write the vibration frequency of the simple harmonic motion in terms of the spring constant and the mass:
\begin{equation} \label{shm-freq}
f = \frac{1}{2\pi} \sqrt{\frac{k}{m}}
\end{equation}
This is called the \jargon{natural frequency} of the ideal spring. For any system in stable equilibrium, each degree of freedom will have its own natural frequency.

% Energy in SHM, --energy diagram--

The amplitude in equation \eqref{shm} is related to the energy in the system. Hooke's law \eqref{hooke} is conservative and the potential energy associated with it is\footnote{This can be seen from the definition of work \eqref{dfn-work}
$$\Delta W = F \Delta x$$
In this case we have to be careful because the force is not constant. But the work does increase at a constant rate, so we use the trick from Lecture \ref{ch:kinematics} where the average value is equal to the average of the ends. In this case, the work done at the beginning is zero because there is no net force at equilibrium. As we pull on the spring, the work required increases. At full extension, the work required is $W = (-kx)(x)$. Taking the average introduces a factor of one-half.}
\begin{equation} \label{pot-ene-spr}
PE_\text{spr} = \half kx^2
\end{equation}
In general, the total energy of the ideal spring system is sum of the kinetic energy of the mass and the potential energy in the spring. But when the system is at maximum extension the velocity of the mass is zero (for a moment). Since $x = A$ at this point, we can write
\begin{equation} \label{energy-and-amplitude}
E_\text{tot} = \half kA^2
\end{equation}
The fact that the energy of vibration is proportional to the \emph{square} of the amplitude of the vibration explains why laser light is so much more powerful than regular light (see Lecture \ref{ch:quantum-mechanics}).

% Non-linear forces, the pendulum, --phase space--

Hooke's law \eqref{hooke} is an idealization for a real spring, and even more so for complex physical systems. \prep{However, the forces maintaining any state of stable equilibrium are approximately linear for \hide{small} displacements.} One easy way to see this is by investigating the energy diagram. For a system to be in stable equilibrium, the potential energy curve must create a trough or potential well. The point of equilibrium is at the bottom of this well. If one were to fix the vertex of a parabola to this point and fit its curvature to the curvature of the potential energy function, one might get a diagram like Figure \ref{fig:parabola-in-potential-well}.

\tikzfig{parabola-in-potential-well}
{
\begin{tikzpicture}
\clip (-0.5,-0.5) rectangle (6.5,4.5);
\draw [->] (0,0) -- (6,0) node [right] {$q$};
\draw [->] (0,0) -- (0,4) node [above] {$U$};
\draw [domain=0:6,samples=100] plot (\x,{sin(\x*90)+2});
\draw [domain=0:6,samples=100,dashed] plot (\x,{1.26*(\x-3)^2+1});
\draw [fill=white] (3,1) circle (0.1) node [below=2mm] {Stable equilibrium};
\node at (1.5,1.26*1.5*1.5+1) [pin=-45:{Hooke's Law}] {};
\end{tikzpicture}
}{A parabola can be made to fit into any potential energy well}

\prep{This shows that any potential well can be approximated by a \hide{parabola} associated with some version of Hooke's law} \eqref{hooke}.\footnote{The curvature of the parabola is related to the second derivative of the potential energy function.} The project for this term uses this trick to calculate an estimate for the anomalous precession of Mercury due to general relativity.

An important example of a non-linear system is the pendulum. In this case we consider our displacement to be the angle of the pendulum from vertical. The weight of the pendulum bob creates a torque that has a tendency to push the pendulum back to center (see Figure \ref{fig:pendulum}).

\tikzfig[side]{pendulum}
{
\begin{tikzpicture}[scale=4]
\def\ang{30}
\draw [dashed] (0,0) -- node [left] {$L$} (270:1) node [draw,circle,fill=white,inner sep=1mm] {} arc (270:270+\ang:1);
\draw (0,0) -- (270+\ang:1) node [draw,circle,fill,inner sep=1mm] {};
%\draw [dotted] (270:0.4) arc (270:270+\ang:0.4);
\node at (270+\ang/2:0.3) {$\theta$};
%\node at (270+\ang/2:0.9) {$s$};
\path (270+\ang:1) ++(90+\ang:0.2) node [forcearrow,rotate=90+\ang] {} +(\ang:0.15) node {$T$};
\path (270+\ang:1) ++(270:0.2) node [forcearrow,rotate=270] {} +(270:0.2) node{$mg$};
%\draw [->,red,rotate=\ang] (0,-1.2) -- (0,-0.4) node [above right] {$y$};
%\draw [->,red,rotate=\ang] (-0.4,-1) -- (0.4,-1) node [right] {$x$};
\end{tikzpicture}
}{Forces on a pendulum}

The tension from the string has no lever arm, so it introduces no torque into the system. The tangential component of the weight is simply $-mg \sin \theta$, so the total torque on the pendulum is
$$\tau = -mgL \sin \theta$$
Newton's second law for rotation states that this will cause an angular acceleration:
$$-mgL \sin \theta = mL^2 \alpha$$
where I have used the fact that the moment of inertia for this simple pendulum is $mL^2$. Now if the angle involved is small, we can use the approximation that $\sin \theta \approx \theta$ (when $\theta$ is measured in radians).\footnote{Small means less than 10$\dg$, or less than 0.1 radian. This is the point in the derivation where we replace the natural potential energy function with the ideal parabola for simple harmonic motion.} We can also absorb an $L$ on both sides to convert the angles into tangential variables. We get
$$-gs = La$$
where $s$ represents the arc-length of the pendulum's swing. This equation is similar to $-kx = ma$ for an ideal spring. So, we can immediately write the frequency for the pendulum swing as
\begin{equation} \label{pendulum-freq}
f = \frac{1}{2\pi} \sqrt{\frac{g}{L}}
\end{equation}
Remember, this equation is only valid when the angular displacement is small.

% Damped harmonic motion

The ideal spring is a good model for any vibration. We can improve the model by adding an element of friction to the system. There are different ways to do this, but one very common way is by introducing a drag term which is proportional to the velocity of the system:
\begin{equation} \label{drag-term}
F_\text{drag} = -cv
\end{equation}
where $c$ is the ``stiffness'', or viscosity of the drag. This is the type of friction an object experiences as it pushes slowly through a fluid. The shock absorbers in your car use this kind of a set up to minimize vibration.

This damping effect introduces a non-conservative force into the system which will reduce the amplitude of the motion over time. Since the amplitude is related to the energy of this system, this reflects the fact that energy is being lost through friction. The equation for the amplitude is
$$A(t) = A_0 \exp(-\gamma t)$$
where $\gamma = c/2m$. The displacement of the damped oscillator over time is graphed in Figure \ref{fig:damped-oscillator}.

\tikzfig[side]{damped-oscillator}
{
\begin{tikzpicture}
\draw [->] (0,-2) -- (0,2) node [above] {$x$};
\draw [->] (0,0) -- (5,0) node [right] {$t$};
\draw [domain=0:4.5,samples=200] plot (\x,{2*exp(-\x)*cos(500*\x)});
\end{tikzpicture}
}{The motion of a damped harmonic oscillator}

\prep{When $\gamma = \omega$, the system is said to be \jargon{critically damped}. This is the circumstance which brings the system back to equilibrium the \hide{fastest}.} If the system is under-damped ($\gamma < \omega$), then it will oscillate a bit before being brought to rest, as described above. If the system is over-damped ($\gamma > \omega$), then the viscosity will be so thick it will actually drag against the system being brought to rest.

% Driven harmonic motion and resonance

Finally, we have one last topic to consider: forced vibrations. If a damped system is driven by an external vibration, the motion of the system will eventually match the frequency of the driver. Initially it will move through a temporary ($\Delta t > 1/\gamma$) \jargon{transient state} until it reaches a \jargon{steady state} of sinusoidal motion. This steady state will have an amplitude which will depend upon both the frequency of the external driver and the natural frequency of the system.

What happens is that the external vibration does work on the system when the force is aligned with the displacement of the system. \prep{When the frequency of the external vibration is matched with the natural frequency of the system, the work done in each cycle \hide{accumulates}. It does not take long for system to absorb a lot of energy from the external source even if the magnitude of the source is small.} Eventually the system is moving fast enough that the damping force (proportional to this speed) increases to drain the energy that is being absorbed. This steady state is called \jargon{resonance}.

The typical power absorption for a driven harmonic oscillator is plotted in Figure \ref{fig:resonance}. The peak power absorption occurs at the natural frequency of the system. The width of the peak is related to the ``stiffness'' of the damping: at one-half of the maximum power absorption it is equal to $2\gamma$.

\tikzfig{resonance}
{
\begin{tikzpicture}
\def\z{0.1}
\draw [->] (0,0) -- (0,4) node [above] {$P$};
\draw [->] (0,0) -- (6,0) node [right] {$f_\text{ext}$};
\draw [domain=0:1.9,samples=200] plot (3*\x,{2*\z*\x^2/((1-\x^2)^2+(2*\z*\x)^2)});
\draw (3,0.1) -- (3,-0.1) node [below=1mm] {$f = \omega / 2\pi$};
\draw [dotted] (0,2.5) -- (3,2.5) node [pos=0,left] {$\half P_\text{max}$};
\draw [<->] (2.71,2.5) -- +(0.6,0) node [fill=white,pos=0.5,below=1mm] {$2\gamma$};
\end{tikzpicture}
}{Power absorption in a driven harmonic oscillator}

Resonance can be used to explain the scattering of light (why the sky is blue), how microwaves work, and is important in certain electrical circuits. The quality factor of an electrical circuit is defined as the ratio of the resonant frequency and the half-maximum width of the power absorption curve. A sharp peak will make a good radio receiver as it will only react to a particular range of radio frequencies. A quality factor between 10 and 100 is common. For our ideal spring, this quality factor would be
$$Q = \frac{\omega}{2\gamma} = \sqrt{\frac{km}{c^2}}$$
which shows how this one metric incorporates all the essential parameters of the system.\footnote[-0.25in]{The quality factor for a resonating circuit is $\sqrt{L/CR^2}$---see Lecture \ref{ch:induction-and-ac}.}

% Next week

Next lecture we will extend this notion of things that stretch to cover the topic of the elasticity of solids. We will find that forces create stress in an elastic solid and that this stress can be decomposed into three essential components. Stress causes strain, and Hooke's law will reappear in the relationship between them. We will take a quick overview of the various ways real objects deform and react to various stresses.% and include a discussion on materials science.

The idea of stress also offers us a segue to discuss general relativity. We will see that the essential effect of gravity is to create stress in the space-time continuum: which is witnessed by the presence of the ocean tides. We will finish by discussing whether it is possible to avoid being crushed while falling into a black hole.
========
13:elasticity
--------
Elasticity
--------
Read sections 10.7--10.8
--------
% Phases of matter and atomic springs

As discussed in Lecture \ref{ch:overview}, physics is often described as the study of matter and energy. So far, we have focused on the dynamics of motion. Now we turn to a study of the properties of matter---this will occupy us for the next few lectures. \prep{The most basic classification of material things is by their \hide{phase}: whether they are solid, liquid, or gaseous.} At the microscopic level, these phases are distinguished by the strength of the inter-molecular interaction. The solid phase is such that the configuration of the molecules are essentially locked together. They may vibrate in place, but there is no bulk motion relative to one another. 

In the fluid phases, the molecules can flow around one another and move freely. Both liquids and gases are considered fluids because of their ability to flow. The two are distinguished by the fact that the molecules in liquids stay relatively close together (they constantly ``touch''), but in gases they fly about nearly free of interaction.

In this lecture we will discuss solids and their elastic properties. Frequently a solid is depicted as a bunch of molecules connected to one another by springs (see Figure \ref{fig:atomic-solid}). The springs are meant to represent the inter-atomic forces between the molecules. As we discovered in the previous lecture, the forces in any system near stable equilibrium can be approximated by ideal springs, so this picture is not as unrealistic as it may first appear.

\tikzfig[side]{atomic-solid}
{
\begin{tikzpicture}
\tikzstyle {spr} = [decorate,decoration={coil,aspect=0.5,segment length=1mm,amplitude=1mm}];

\foreach \x in {1,...,3}
\foreach \y in {1,...,3}
{
\draw [spr] (\x,\y) -- +(0,-1);
\draw [spr] (\x,\y) -- +(-1,0);
}

\foreach \x in {1,...,3} \draw [spr] (\x,0) -- +(-1,0);
\foreach \y in {1,...,3} \draw [spr] (0,\y) -- +(0,-1);

\foreach \x in {0,...,3}
\foreach \y in {0,...,3}
\node (\x\y) at (\x,\y) [draw,fill=white,circle,inner sep=2mm] {};
%\node (\x\y) at (\x,\y) [ball color=gray,circle,inner sep=2mm] {};

\end{tikzpicture}
}{A solid as a collection of molecules connected by springs}

This conceptual model also shows the main property of a solid: its elasticity. When any force is applied to a solid, it will respond through deformation and will resist the force applied. The details of this deformation can be extremely complicated---as can be seen just be considering the number of degrees of freedom available to all the molecules.

% Stress, strain, deformation, deflection

The simplest approach is to consider a solid rod. This is somewhat like a one-dimensional system. Assume the rod is fixed at one end and a force is applied to the other. In general, the force will have two components: along the length of the bar and across the length of the bar. The first is called \jargon{normal stress}\footnote{``Normal'' because the force is perpendicular to the cross-section of the bar.} and the second \jargon{shear stress}. \prep{The reason we use the word \jargon{stress} rather than force here is that we expect all the forces to be in balance---we are interested not in the net force which produces motion, but the stable combination of forces which produces deformation. Stress is what's left after the \hide{net force} has been calculated.}

Normal stress will either stretch (also known as tension) or compress the solid (see Figure \ref{fig:normal-stress}).\footnote{In three dimensions we can distinguish between tension and compression by the fact that tension will cause expansion in one dimension and contraction in the other two. Compressive forces will cause expansion in two dimensions and contraction in one.} The resulting deformation is called the \jargon{strain} in the object and is defined as the amount of deformation divided by the original length of the bar. The strain is a unit-less number: the percent change in the original length. If the force is distributed over a large area, the resulting strain will be less. So we are really talking about the pressure from the normal force causing the deformation. When the displacement involved is small, the controlling equation is
\begin{equation} \label{normal-stress}
\frac{F}{A} = Y \left( \dfrac{\Delta L}{L_0} \right)
\end{equation}
Notice how this is similar in form to Hooke's law. The quantity $Y$ is called \jargon{Young's modulus} and is on the order of $10^{11}$ for metals in SI units (indicating enormous forces are required to create a significant deformation).

\tikzfig[side]{normal-stress}
{
\begin{tikzpicture}
\begin{scope}[help lines]
\draw [fill=black!10] (0,-0.5) rectangle (4,0.5);
\draw [<->] (0,-0.3) -- node [above] {$L_0$} (4,-0.3);
\draw [<->] (0.2,-0.5) -- node [right] {$A$} (0.2,0.5);
\end{scope}
\draw (0,-0.6) rectangle (3.6,0.6);
\draw [<-] (3.6,0.1) node [left] {$\Delta L$} -- (4,0.1);
\node (f) at (4.5,0) [forcearrow,rotate=180] {};
\node at (f.west) [right=1mm] {$F$};
\end{tikzpicture}
}{A solid rod under normal stress}

\prep{Shear stress is similar, except now we are interested in quantifying the \hide{deflection} of the bar} (see Figure \ref{fig:shear-stress}). The formula for shear stress is nearly the same:
\begin{equation} \label{shear-stress}
\frac{F}{A} = S \left( \dfrac{\Delta x}{L_0} \right)
\end{equation}
except now the strain is quantified as the ratio of the deflection to the bar's length. The proportionality constant $S$ is called the \jargon{shear modulus}.

\tikzfig[side]{shear-stress}
{
\begin{tikzpicture}
\begin{scope}[help lines]
\draw [fill=black!10] (0,-0.5) rectangle (4,0.5);
\draw [<->] (0,-0.3) -- node [above] {$L_0$} (4,-0.3);
\draw [<->] (0.2,-0.5) -- node [right] {$A$} (0.2,0.5);
\end{scope}
\draw (0,-0.5) -- (0,0.5) -- (3.9,0.3) -- (3.9,-0.7) -- cycle;
\draw [->] (3.9,0.5) node [above] {$\Delta x$} -- (3.9,0.3);
\node (f) at (4.5,0) [forcearrow,rotate=270] {};
\node at (f.north) [right=2mm] {$F$};
\end{tikzpicture}
}{A solid rod under shear stress}

We have not exhausted all the ways a solid can be put under stress. You may notice that in Figure \ref{fig:normal-stress} there is a slight expansion along the cross-sectional area. The effect is exaggerated in the diagram, but the point is that normal stress will not change the volume of the object. When one part is squeezed, another will bulge. However, it is possible for forces to completely surround the object like in Figure \ref{fig:pressure-stress}. We will call this \jargon{pressure stress}. 

\tikzfig[side]{pressure-stress}
{
\begin{tikzpicture}
%\node at (2,0) [circle,shading=ball,ball color=gray!20,inner sep=4mm] {};
%\node at (2,0) [circle,shading=ball,ball color=gray,inner sep=3mm] {};
\node at (2,0) [circle,fill=black!20,inner sep=4mm] {};
\node at (2,0) [circle,draw,inner sep=3mm] {};
\foreach \q in {0,60,...,300} \path (2,0) +(\q:1) node [forcearrow,rotate=180+\q] {}; 
\end{tikzpicture}
}{An object under compressive pressure}

In a way you can consider this a special case of normal stress, but we only take the average pressure in all directions. In other words, we break the normal stress into two components: (1) the average value from all directions (the pressure stress) which changes the volume of the object and (2) the remainder (the normal stress proper) which merely distorts the shape of the object.

The formula for pressure stress is
\begin{equation} \label{pressure-stress}
\Delta P = -B \left( \dfrac{\Delta V}{V_0} \right)
\end{equation}
where $B$ is called the \jargon{bulk modulus} of the material. The negative sign is here because an increase in pressure will cause a decrease in volume.

% Hooke's law, elasticity, plasticity, and failure

In the formulas \eqref{normal-stress}, \eqref{shear-stress}, and \eqref{pressure-stress}, the forces involved must be small. In fact, they are all similar in form to Hooke's law \eqref{hooke} and are sometimes referred to as such. \prep{When the forces become larger, these equations cease to work and tend to \hide{over-predict} the stress required for a particular level of strain. In other words, the object tends to break apart.} There are three typical limits of strain for a given object:
\begin{items}
\item Proportionality limit
\item Elastic limit
\item Deformation limit
\end{items}
These are highlighted in Figure \ref{fig:stress-strain}. Up to the proportionality limit, Hooke's law is valid and each increment of stress causes a consistent increment of strain. Past the proportionality limit and up to the elastic limit, the object is plastic, meaning that when the stress is removed the object still will conform to its original shape. If the stress exceeds the elastic limit, the deformation is permanent and if the stress goes beyond the deformation limit, the object will break. Clearly understanding these limits is important in the design and construction of all kinds of objects.

\tikzfig[full]{stress-strain}
{
\begin{tikzpicture}[scale=1.5]
\draw [->] (0,-0.2) -- (0,4.2) node [above] {Stress ($F/A$)};
\draw [->] (-0.2,0) -- node [below=1mm] {Strain ($\Delta L/L_0$)} (4.2,0);
\draw (0,0) .. controls (2,2.5) and (3,3) .. (3.5,3);
\draw [help lines] (0,0) -- node [above,sloped] {Hooke's Law} (3.2,4.0);
\fill [opacity=0.10] (0,0) rectangle (4.0,0.74); \fill (0.6,0.74) circle (0.05) node [right=1mm] {Proportionality limit};
\fill [opacity=0.10] (0,0) rectangle (4.0,2.18); \fill (2.0,2.18) circle (0.05) node [right=1mm] {Elastic limit};
\fill [opacity=0.10] (0,0) rectangle (4.0,3.00); \fill (3.5,3.00) circle (0.05) node [above left] {Deformation limit};
\fill [opacity=0.10] (0,0) rectangle (4.0,4.00);
\draw [<-] (4.1,0.37) -- +(1,0) node [right] {Hooke's law is valid};
\draw [<-] (4.1,1.46) -- +(1,0) node [right] {Hooke's law is not valid};
\draw [<-] (4.1,3.50) -- +(1,0) node [right] {Object is broken};
\draw [<-] (4.1,2.59) -- +(1,0) node [right] {Deformation is permanent};
\end{tikzpicture}
}{Typical stress-strain relationship for a solid object}

% Continuum mechanics and the stress tensor

Now, \prep{in general, an object will be under the influence of a variety of forces in multiple directions at a variety of points. One way to deal with this complexity is to break the object into a (large) number of pieces. The simplest way to do this is by splitting it into little \hide{cubes}.} Each cube interacts with the others through the forces along their sides. We deliberately make the cubes so small that we are able to assume the forces are constant along each face. Also, since the cubes are small we can apply Hooke's law to each: in other words, the strain in each cube will be directly proportional to the forces on the sides. Over the volume of the object, the strain within the cubes accumulate and gives us the total deformation and deflection in the shape of the object. This approach is called \jargon{continuum mechanics}.

Consider the forces on one of these elemental cubes. Since we are only interested in the stress and not the bulk motion of the cube, we assume the forces are in equilibrium. This means that the forces on opposite sides of the cube are equal and opposite, so we only need consider one side of each pairs. For extreme simplicity, we will consider the two-dimensional ``cube'' shown in Figure \ref{fig:elemental-cube}. The Greek letter $\sigma$ is traditionally used to denote stress. In our case $\vect{\sigma}(\vhat{x})$ represents the force of stress along the face with the $x$-direction as its normal. I've written it this way to emphasize the fact that stress $\sigma$ is a tensor: it maps each direction vector into the force of stress along that direction.\footnote{Just because it is a function between vectors is not enough for it to be a tensor. It must also be linear. One could show this by rotating the cube an comparing the results with the original orientation.}

\tikzfig{elemental-cube}
{
\begin{tikzpicture}
%\draw [dotted] (-2,-2) rectangle (2,2);
\clip (-5,-3) rectangle (5,3.5);
\draw [dotted] (-3,-2) -- (3,-2) (-3,2) -- (3,2) (-2,-3) -- (-2,3) (2,-3) -- (2,3);

\draw (2,-1) -- (2,1);
\draw [->] (1,0) -- (3,0) node [right] {$\vhat{x}$};
\node at (2,0) [forcearrow,right,rotate=37,minimum height=50mm] {};
\node at (-2,0) [forcearrow,right,rotate=217,minimum height=50mm,draw=gray,fill=none] {};
\node at (2,0) [below right] {$\vect{\sigma}(\vhat{x})$};

\draw (-1,2) -- (1,2);
\draw [->] (0,1) -- (0,3) node [above] {$\vhat{y}$};
\node at (0,2) [forcearrow,right,rotate=-18,minimum height=32mm] {};
\node at (0,-2) [forcearrow,right,rotate=162,minimum height=32mm,draw=gray,fill=none] {};
\node at (0,2) [above right] {$\vect{\sigma}(\vhat{y})$};
\end{tikzpicture}
}{Forces of stress on a cubical element}

We can go a bit further by breaking these stress vectors into their components. This is shown in Figure \ref{fig:elemental-cube-components}. Each component has a double subscript. The first letter denotes which cube face we are referring to and the second letter denotes the direction of the component. For example, $\sigma_{xy}$ represents the $y$-component of the stress force $\vect{\sigma}(\vhat{x})$. There are several advantages with this \jargon{index notation}. One of them is that we can easily write that \prep{the stress tensor is \hide{symmetric}, i.e., $\sigma_{xy} = \sigma_{yx}$. This is because these are both the tangential components of their forces and produce torque. But the cube is in equilibrium, so these torques must cancel. This will only happen if these components are equal.}

\tikzfig{elemental-cube-components}
{
\begin{tikzpicture}
%\draw [dotted] (-2,-2) rectangle (2,2);
\clip (-5,-3) rectangle (5,3);
\draw [dotted] (-3,-2) -- (3,-2) (-3,2) -- (3,2) (-2,-3) -- (-2,3) (2,-3) -- (2,3);

\draw [->] (2,0) -- (2,1.5) node [pos=0.5,left,fill=white] {$\sigma_{xy}$};
\draw [->] (2,0) -- (4,0) node [pos=0.5,below=1mm,fill=white] {$\sigma_{xx}$};
%\fill [opacity=0.1] (1,-0.8) rectangle (3,0.8);
\node at (2,0) [forcearrow,right,rotate=37,minimum height=50mm,fill=none,draw=gray] {};
%\node at (2,0) [below right] {$\vect{\sigma}(\vhat{x})$};

\draw [->] (0,2) -- (1.5,2) node [pos=0.5,above,fill=white] {$\sigma_{yx}$};
\draw [->] (0,2) -- (0,1.5) node [pos=0.5,left,fill=white] {$\sigma_{yy}$};
%\fill [opacity=0.1] (-0.75,1.75) rectangle (0.75,2.25);
\node at (0,2) [forcearrow,right,rotate=-18,minimum height=32mm,fill=none,draw=gray] {};
%\node at (0,2) [above left] {$\vect{\sigma}(\vhat{y})$};
\end{tikzpicture}
}{The components of the stress on a cubical element}

We can take this even further by busting these components into pieces that emphasize their normal, shear, and pressure stress dynamics. We have already seen that the shear components are equal by definition, so that is done. The pressure piece is simply the average of the two normal components. These pressure pieces are also equal by definition. The remaining normal components are also equal (though opposite) because they are their difference from the average. This means that \prep{we are able to characterize the stress created by arbitrary forces using just \hide{three} numbers related to the three components of stress} we introduced at the beginning of this lecture. Figure \ref{fig:stress-components} shows these ``canonical'' components for the example in Figure \ref{fig:elemental-cube}.

\tikzfig[side]{stress-components}
{
\vspace{-2in}
\begin{tikzpicture}

\begin{scope}[yshift=0mm]
\node at (-3,0) {\bf{Shear}};
\draw [dotted] (-0.5,-0.5) rectangle (0.5,0.5);
\draw [->] (-0.25,1) -- (0.25,1);
\draw [->] (1,-0.25) -- (1,0.25);
\draw [->] (0.25,-1) -- (-0.25,-1);
\draw [->] (-1,0.25) -- (-1,-0.25);
\end{scope}

\begin{scope}[yshift=-35mm]
\node at (-3,0) {\bf{Pressure}};
\draw [dotted] (-0.5,-0.5) rectangle (0.5,0.5);
\draw [->] (0,1) -- (0,1.42);
\draw [->] (1,0) -- (1.42,0);
\draw [->] (0,-1) -- (0,-1.42);
\draw [->] (-1,0) -- (-1.42,0);
\end{scope}

\begin{scope}[yshift=35mm]
\node at (-3,0) {\bf{Normal}};
\draw [dotted] (-0.5,-0.5) rectangle (0.5,0.5);
\draw [->] (0,1) -- (0,0.75);
\draw [->] (1,0) -- (1.25,0);
\draw [->] (0,-1) -- (0,-0.75);
\draw [->] (-1,0) -- (-1.25,0);
\end{scope}

\end{tikzpicture}
}{The three canonical components of stress for Figure \ref{fig:elemental-cube-components}}

% Overview of materials science

% Tides are a result of stress from the gravitational field

We can even talk about stress on an astronomic scale. \prep{The ocean tides result from the \hide{stress} induced by the gravitational pull of the moon (and the sun).} The gravitational force creates a normal stress on the oceans which tend to expand the water along the line between the centers of the earth and moon and compress the water perpendicular to this line.

The expansion can be understood because the inverse square law means that the force of gravity on the near side to the moon will be slightly larger than at the center, which will be slightly larger than on the opposite side. If we label the distance between the earth and moon $d$ and the radius of the earth as $r$, we have
$$F_\text{near} = \frac{GMm}{(r - d)^2}$$
for the force of gravity on the near side. The force on the far side is similar with $r + d$ in the denominator instead.

We can rewrite this equation as
$$F_\text{near} = \left( \frac{GMm}{d^2} \right) (1 - r/d)^{-2}$$
The reason to do this is that we can use the binomial theorem \eqref{binomial-theorem} on the second factor because $r/d$ is so very small. We have
$$(1 - r/d)^{-2} \approx 1 + 2r/d$$
The stress on the earth's oceans is given by the difference between this force and that at the center of the earth. For both the near and far sides this is the same in magnitude. We have:
$$\sigma_{xx} = \left( \frac{GMm}{d^2} \right) \frac{2r}{d}$$
where the $x$-direction is aligned along the earth-moon line.

We expect compression on in the $y$-direction, but the reasoning is different. In this case, we are looking for the component of the forces on the sides of the earth directed toward the center of the earth. The triangle involved in these components is similar to the triangle formed by the geometry of the earth-moon system (refer to Figure \ref{fig:tides}). This means we can write
$$\frac{F}{F_\text{grav}} = \frac{r}{d_\text{side}}$$
because in similar triangles the ratio of similar sides are equal.

\tikzfig{tides}
{
\begin{tikzpicture}
\fill [black!20] (0,0) ellipse (1.4 and 1.1);
\draw [fill=white] (0,0) circle (1);
\draw (6,0) circle (0.3);
\draw [dotted] (0,0) -- (6,0) node [pos=0.5,below] {$d$};
\draw [dotted] (0,0) -- (0,1) node [pos=0.5,left] {$r$};
\draw [dotted] (0,1) -- (6,0) node [pos=0.5,above right] {$d_\text{side}$};
\end{tikzpicture}
}{Tides on the earth caused by the gravitational force of the moon}

The force of gravity $F_\text{grav}$ on the side of the earth is proportional to the inverse square of the distance $d_\text{side}$, or
$$F_\text{grav} = \frac{GMm}{d^2 + r^2}$$
However, by using the binomial theorem earlier, we have implicitly agreed to completely ignore $r^2$ relative to $d^2$ since $r \ll d$.\footnote{For example, if $x = 10^{-6}$ is barely in our measurement range then $x^2 = 10^{-12}$ is certainly not.} By similar logic we can now write $d_\text{side} = d$.

This means that the normal stress across the earth-moon line is
$$\sigma_{yy} = - \left( \frac{GMm}{d^2} \right) \frac{r}{d}$$
where I have introduced the negative sign since the stress is compressive along this component.

The gravitational field introduces no shear stress, so this completely determines the tidal stress from the moon.

% The equivalence principle and geodesic deviation

In classical mechanics we characterize the influence of gravity by Newton's inverse square law \eqref{n4l}. But in Einstein's general theory of relativity we use these tidal stresses to define the influence of gravity. There are two reasons for this. The first is that we need a field theory---one that does not involve action-at-a-distance like Newton's law. The gravitational effect must propagate through the field at the speed of light rather than being instantaneous. The second reason is that \prep{there is always an inertial frame in which the force of gravity can be eliminated---this is the equivalence principle (see page \ref{idx:equivalence principle}). But even in a \hide{free-fall} frame the tidal effects of gravity are present. In a way the tidal effects are more ``real'' than the force of gravity itself.}

% Gravity waves are pressure-less waves of stress

\prep{So in general relativity, \hide{gravity} propagates through space as waves of stress in the fabric of space-time.} In fact, gravity waves (if detected) will be measured through their extremely faint normal stresses in objects. Only waves from dramatic astronomic events like a supernova will be detectable directly, but there is already \href{http://en.wikipedia.org/wiki/Hulse-Taylor_binary}{indirect evidence} of the existence of gravity waves.

% How to fall into a black hole without being crushed

As one falls into the gravitational well of an object, the free-fall frame experiences tidal forces similar to those from the moon. If the object is a black hole (crushed beyond is Schwarzschild radius---see Lecture \ref{ch:celestial-mechanics}), these tidal effects increase without limit. As one is pulled inexorably toward the central pit of destruction, the tidal forces will pull one into a long string of spaghetti.

This situation is unavoidable if the black hole is not rotating. If it does rotate (which almost all will since angular momentum is conserved), the \jargon{event horizon} that surrounds the black hole at its Schwarzschild radius splits in two. And it becomes possible to pass into the event horizon without being doomed to being crushed in the central singularity (the so-called \jargon{ergosphere}). In fact, there is even reason to believe we can extract energy for the rotation of the black hole by exploiting this ergosphere---this is called a \href{http://en.wikipedia.org/wiki/Penrose_process}{Penrose process}. There is even speculation that this ergosphere may offer an ability to travel through a black hole to another region of space-time---the \jargon{worm hole} made famous in many science fiction stories nowadays. But that discussion lies far afield from this lecture.

% Next week

Next week we will move on from solids to discuss the dynamics of fluids. As mentioned earlier, these thoughts will apply to both liquids and gases. Initially we will discuss hydrostatics: the properties of fluids at rest. The main result will be a determination of the buoyant force in any fluid. After that we move to hydrodynamics, or fluids in motion. We will introduce some new concepts to speak quantitatively about fluid flow and characterize the different ways fluids move. Bernoulli's equation will be introduced as the main equation for hydrodynamics. We will touch on viscosity which will introduce some realism into our discussion. Finally we will touch on the topic of deterministic chaos which was first discovered in the study the weather by fluid modeling of the atmosphere.
========
14:fluids
--------
Fluids
--------
Read sections 11.1--11.11
--------
% Solids strain, fluids flow. Of gases and liquids

Of the three phases of matter, liquids and solids are distinguished by their ability to flow. Liquids flow downward under their own weight to take the shape of their container while gases flow by expanding to completely fill their container. The ability to transport mass from one point to another is the main thing that separates fluids from solids.

%%% An ideal fluid at rest cannot support shear stress or horizontal pressure differentials.

This distinction also shows up in how fluids react to the three types of stress introduced in the last lecture. Fluids don't break. In fact, fluids can't really support any normal or shear stress. \prep{Although a solid will deform and resist the stress, a \hide{fluid} will simply react by moving out of the way.} An ideal fluid will flow instantly, but any real fluid will have a bit of reaction time related to its viscosity. This means that pressure is the only kind of stress that a fluid at rest will support.

In fact, a fluid at rest won't even support a pressure differential. \prep{The fluid will move from high to low pressure. If the pressure increases anywhere in the fluid, this increase will distribute \hide{evenly} throughout the fluid.} This is called \jargon{Pascal's principle} and is what makes most hydraulics work. The hydraulic press is a simple example of this where a force on one end can be used to support a much larger force on the other (see Figure \ref{fig:hydraulic-press}). Since the pressure must be equal and pressure is force divided by area, a larger area will deliver a larger force. The hydraulic press is a machine with an ideal mechanical advantage equal to the ratio of the area on either side of the press.

\tikzfig{hydraulic-press}
{
\begin{tikzpicture}
\fill [black!20] (-4,-0.3) -- (-4,-2) arc (180:360:1 and 0.2) -- (-2,-0.3);
\fill [black!20] (2.5,-0.3) -- (2.5,-2) arc (180:360:0.5 and 0.1) -- (3.5,-0.3);
\draw [fill=black!20] (-3,-0.3) ellipse (1 and 0.2);
\draw [fill=black!20] (3,-0.3) ellipse (0.5 and 0.1);
\draw (-3,0) ellipse (1 and 0.2);
\draw (-4,0) -- (-4,-2) arc (180:360:1 and 0.2) -- (-2,0);
\draw (3,0) ellipse (0.5 and 0.1);
\draw (2.5,0) -- (2.5,-2) arc (180:360:0.5 and 0.1) -- (3.5,0);
\draw [fill=black!20] (-2,-1.7) -- (2.5,-1.7) arc (-90:90:0.04 and 0.2) -- (-2,-1.3) arc (90:270:0.04 and 0.2);
\node [forcearrow,rotate=270,left,minimum height=40mm] at (-3,-0.3) {};
\node [forcearrow,rotate=270,left,minimum height=10mm] at (3,-0.3) {};
\node at (3,0.5) {$F_1$};
\node at (-3,2) {$F_2 = 4F_1$};
\node at (2.5,-0.3) [left] {$A_1$};
\node at (-2,-0.3) [right] {$A_2 = 4A_1$};
\node at (0,1) {$MA = \dfrac{A_2}{A_1}$};
\end{tikzpicture}
}{The mechanical advantage of the hydraulic press}

% Density, pressure, and buoyancy
%%% The vertical pressure differential in a static ideal fluid provides the force of buoyancy.

The statement I made earlier when I said that a fluid will not support a pressure differential was not quite true. In the presence of gravity (or any long-range force for that matter), the fluid below must support the fluid above.\footnote{Obviously this requires a container of some sort. Fluid doesn't just pile up like sand.} In fact, the pressure differential required is pretty easy to calculate. Imagine a rectangular box of height $h$ with a horizontal cross-section of area $A$ (see Figure \ref{fig:hydrostatic-eqn}). 

We will assume the mass density\footnote{Remember that mass density is defined as the mass divided by the volume of the substance. Later we will see the density defined for other quantities like the number of particles or charge.} $\rho$ of the fluid is constant, so the total mass of this imaginary box of fluid is 
$$m = \rho V = \rho Ah$$
The pressure on the bottom of the box must exceed the pressure at the top because it is holding up the weight of the fluid in the box. The total force from the fluid on the bottom will be $F_2 = P_2 A$. This force must balance both the pressure at the top of the box and also the weight of the box. Thus,
$$P_2 A = P_1 A + \rho Ahg$$
When we cancel the area and write in terms of a pressure differential we get:
\begin{equation} \label{hydrostatic-eqn}
\Delta P = \rho gh
\end{equation}
which I like to call the \jargon{hydrostatic equation}.

\pics[side]{hydrostatic-eqn}
{
\vspace{-1.5in}
\begin{tikzpicture}
\def\l{1} \def\w{1} \def\h{3};
\begin{scope}[draw=white,fill opacity=0.1]
\filldraw (0,0,0) -- +(\l,0,0) -- (\l,\h,0) -- (0,\h,0) -- cycle;
\filldraw (0,0,0) -- (\l,0,0) -- (\l,0,\w) -- (0,0,\w) -- cycle;
\filldraw (0,0,0) -- (0,\h,0) -- (0,\h,\w) -- (0,0,\w) -- cycle;
\filldraw (\l,\h,\w) -- (\l,0,\w) -- (0,0,\w) -- (0,\h,\w) -- cycle;
\filldraw (\l,\h,\w) -- (\l,0,\w) -- (\l,0,0) -- (\l,\h,0) -- cycle;
\filldraw (\l,\h,\w) -- (0,\h,\w) -- (0,\h,0) -- (\l,\h,0) -- cycle;
\end{scope}
\draw [|<->|] (\l+0.2,0,0) -- node [right] {$h$} +(0,\h,0);
\node [forcearrow,rotate=-90] at (\l/2,\h+0.75,\w/2) {};
\node at (\l/2,\h+1.25,\w/2) {$F_1 = P_1 A$};
\node [forcearrow,rotate=90,minimum height=20mm] at (\l/2,-1.00,\w/2) {};
\node at (\l/2,-1.75,\w/2) {$F_2 = P_2 A$};
\node [forcearrow,rotate=-90] at (\l/2,\h/2,\w/2) {};
\node at (\l/2,\h/2-0.5,\w/2) {$W$};
\end{tikzpicture}
}{Deriving the hydrostatic equation}

This reasoning provides us with a method for calculating the force of buoyancy in a fluid. This \jargon{buoyant force} is precisely this pressure differential multiplied by the cross sectional area. In other words
\begin{equation} \label{buoyant-force}
B = \rho gV
\end{equation}
where $B$ is the force of buoyancy, $\rho$ is the density of the fluid, and $V$ is the total volume displaced. This equation is sometimes called \jargon{Archimedes' principle}. If the density of the submerged object is greater than that of the fluid, its weight will be larger than the buoyant force. The net force will be down and the object will sink. \prep{If the density of the submerged object is less than the fluid, the object will rise until it breaks the surface of the fluid (presuming there is one). After that point, the displaced volume will get smaller until \hide{equilibrium} is achieved between $\rho gV$ and the weight---the object floats.}

% Atmospheric pressure and the siphon, gauge vs. absolute pressure

\label{ex:swimming-pool}

Consider a swimming pool. What is the water pressure one meter below the surface? Well, according to equation \eqref{hydrostatic-eqn}, the answer is 9800 pascals (one \jargon{pascal} is equal to one newton per meter squared), or 9.8 kPa. But this is the pressure differential---what is the pressure at the top of the pool? Hint: It's not zero.

Yes, the pool is also supporting the weight of all the air above it. The atmosphere also acts like a fluid and this is the source of atmospheric pressure. We are all like fish swimming is a sea of nitrogen and oxygen gas. The typical value for atmospheric pressure near sea level is 101.3 kPa. So this is the pressure at the top of the swimming pool. The bottom of the swimming pool will have a absolute pressure of 111.1 kPa.

The pervasiveness of the air makes it easy to ignore. In fact, many tools designed to measure pressure (like a tire gauge) are calibrated to register zero at atmospheric pressure. These tools are said to measure \jargon{gauge pressure} which is simply the true absolute pressure minus one atmosphere's worth of pressure. Usually we work with pressure differentials so this issue washes out. On the other hand, occasionally we do need to know the absolute pressure so it's important to be aware of this distinction.

\prep{By the way, atmospheric pressure is how a straw works. It's often said that sucking on the straw creates a vacuum and that the vacuum sucks the liquid up the straw. This is not the right: the surrounding \hide{air} pressure pushes the fluid up the straw. A straw won't work in the vacuum of space.}

One last point about atmospheric pressure. Even if we ignore the fact that it is constantly in motion, this pressure does not obey equation \eqref{hydrostatic-eqn}. This is because in it we have assumed the density to be constant.\footnote{We have also assumed the gravitational force $mg$ to be constant.} Which may be true for a liquid, but for a gas the density generally depends on its pressure (see the ideal gas law \eqref{igl} in Lecture \ref{ch:kinetic-theory}). Taking this into account (with a bit of calculus), the correct equation\footnote{One might call this the ``pneumostatic equation''.} is
\begin{equation} \label{pneumostatic-eqn}
P = P_0 \exp(-kz)
\end{equation}
where $k$ is related to the molar mass and temperature of the gas.

For small heights, it is still appropriate to use equation \eqref{hydrostatic-eqn} for a gas since the pressure differentials are not large enough to invalidate the constant density assumption.

% Flow rates, continuity, types of flow

That is about it for fluids at rest. We are now ready to discuss fluids in motion. The first thing to remember is humility. Of all the problems in physics, accurately describing the motion of fluid is one of the most difficult. As always, our initial step is to classify things in order to focus our study on the simplest things first.

\prep{The main distinction to make is between \hide{turbulent} and laminar flow. \jargon[laminar flow]{Laminar flow} occurs when the streamlines, or flow of current, does not change over time.} In a way, the fluid is both flowing and at rest since the overall pattern does not change though mass transport is occurring.

\jargon[turbulent flow]{Turbulent flow} is the opposite extreme and its precise description represents the last unsolved problem in classical Newtonian physics.\footnote{See the \href{http://en.wikipedia.org/wiki/Turbulence}{here} for more info.} Frequently laminar and turbulent flow occur together (e.g., take a close look at the water that flows out of your tap at home). The initial flow is laminar but then breaks into turbulence after a certain point. Turbulence will often generate a \href{http://upload.wikimedia.org/wikipedia/commons/f/fe/Airplane_vortex_edit.jpg}{vortex} in its wake. The \href{http://en.wikipedia.org/wiki/Reynolds_number}{Reynolds number} (which is related to viscosity to be discussed later) can be used to predict when turbulent flow will occur. 

%%% The steady flow of an ideal fluid is both incompressible and non-viscous.

Even with laminar flow we can simplify things. We define an \jargon{ideal fluid} as both incompressible and non-viscous. By ``non-viscous'' (also known as \jargon{inviscid flow}) we mean we will ignore friction effects. When we say the fluid is \jargon{incompressible} we mean that the volume of any section of the fluid does not change as it flows. The shape of this section may stretch, twist, and turn but the total volume must remain the same.\footnote{We will also assume that the flow of the fluid is far below the speed of sound in the fluid. When the speed of sound is approached new behaviors are exhibited like shock waves and sonic booms.}

We can also describe incompressibility by saying that the volume flow rate is the same along the streamlines of the fluid. The \jargon{volume flow rate} is simply the amount of volume that flows through a given cross-section per second. It is pretty straightforward to see that the volume flow rate is equal to the product of the area of the cross-section and the speed of the fluid:
$$Q = \frac{\Delta V}{\Delta t} = \frac{A \Delta x}{\Delta t} = Av$$
So another (more useful) way to characterize incompressibility is by saying that 
\begin{equation} \label{incompressibility}
Q = A_1 v_1 = A_2 v_2
\end{equation}
for any two points along the fluid flow.

Now even if the fluid is compressible, the \jargon{mass flow rate} remains constant. In other words, if the volume increases the density will decrease because the mass of the fluid doesn't change. By using the logic in the previous paragraph we can show that 
\begin{equation} \label{continuity}
\rho_1 A_1 v_1 = \rho_2 A_2 v_2
\end{equation}
for any two points along the fluid flow. \prep{This equation is called the \jargon{continuity equation} since it represents the fact that the fluid is \hide{continuous}: what goes in one end must come out the other.} This also shows that a third way to characterize incompressibility is by saying the fluid density does not change along the streamlines.

% Bernoulli's equation http://en.wikipedia.org/wiki/Bernoulli%27s_equation
%%% Bernoulli's equation describes the pressure differentials in a ideal fluid that is flowing.

When an incompressible fluid flows, it can be shown that 
\begin{equation} \label{bernoulli}
P + \half \rho v^2 + \rho gz = \text{constant}
\end{equation}
where $z$ is the elevation of the fluid. This follows from definitions of work and energy applied to the fluid. The conservation of this quantity is called \jargon{Bernoulli's equation} and can be re-written is several different ways. Notice that the hydrostatic equation \eqref{hydrostatic-eqn} follows as a special case where $v = 0$.\footnote{Be aware that the $h$ is the hydrostatic equation is actually the depth in the fluid, so $h = -\Delta z$.}

%%% Bernoulli's principle has quite a number of interesting applications.

The term $\half \rho v^2$ is sometimes called the \jargon{dynamic pressure} and can be adjusted for compressible flow (this adjustment is important when the speed approaches the speed of sound in the fluid). \prep{When the elevation differences are negligible, this \hide{dynamic} pressure will drive the pressure differences in the fluid and is responsible for the \jargon{Venturi effect}.} The drop in pressure that occurs when a fluid flows has several applications including the \href{http://en.wikipedia.org/wiki/Carburetor\#Basics}{carburetor} in your car and the force of \href{http://en.wikipedia.org/wiki/Lift_force\#Lift_in_an_established_flow}{lift} on an airplane wing.\footnote{It is sometimes said that the air flows faster over the top of an airplane wing because the air that is split has a larger distance to cover in order to avoid being ``cut in two''. But the reality is that two streamlines of air do not rejoin in the same ``place'' (see the black line of dots in  \href{http://upload.wikimedia.org/wikipedia/commons/9/99/Karman_trefftz.gif}{this animation}.) The reality is that the air is compressed under the wing and this increases the speed of the air according to equation \eqref{incompressibility}.} It's also why tarps get pulled of off moving pick-ups and why windows are blown out and roofs are torn off of buildings in high winds.

In applications where the elevation is important Bernoulli's equation \eqref{bernoulli} is often rewritten as
$$\frac{P}{\rho g} + \frac{v^2}{2g} + z = \text{constant}$$
The term $v^2/2g$ is called the \jargon{velocity head} of the fluid and the remainder is called the \jargon{hydraulic head} which is composed of the \jargon{pressure head} $P/\rho g$ and \jargon{elevation head} $z$. These terms and ideas are used in many applications such as geology and hydraulics engineering.

% Viscosity: Stokes' law, Poiseuille's law

Incorporating corrections for the compressibility of fluids is quite challenging (and really requires a bit more understanding of thermodynamics), but we can talk a bit about viscosity. Ultimately viscosity is the friction between the streamlines of the fluid flow and give the fluid the ability to support shear stress. If we constrain a fluid between to large parallel plates and keep the bottom one at rest, the force required to maintain a fluid velocity $v$ from the top place is given by
\begin{equation} \label{dfn-viscosity}
F = {\eta A v}{d}
\end{equation}
where $A$ is the area of the plates and $d$ is the distance between them. The proportionality constant $\eta$ represents the viscosity of the fluid.

If this viscosity is constant then we have a \jargon{Newtonian fluid}. Water and most gases are Newtonian fluids. One easy (and fun) example of a non-Newtonian fluid is cornstarch mixed in water (2:1 ratio works well). When placed under a large stress, the fluid becomes very viscous (will support a normal force like a solid), but when placed under a small stress acts like a normal liquid.

%%% Stokes' law describes the force required to push an object against the viscosity of a fluid.

\jargon{Stokes' law} is a formula closely related to \eqref{dfn-viscosity} and describes the force required to push a sphere with radius $R$ through a fluid at velocity $v$:
\begin{equation} \label{stokes-law}
F = 6 \pi \eta R v
\end{equation}
This formula can be used to estimate the air drag and an object when the velocity is small.

%%% Poiseuille's law describes the flow rate of a viscous fluid driven by a pressure differential.

\jargon{Poiseuille's law} is another viscosity related formula. We have
\begin{equation} \label{Poiseuille's law}
Q = \frac{\pi R^4 (\Delta P)}{8 \eta L}
\end{equation}
This formula describes the pressure differential required to produce a particular volume flow rate $Q$ through a tube of radius $R$ and length $L$. The higher the viscosity, the lower the volume flow rate.

% Navier-Stokes and CG fluids

\prep{Both \href{http://en.wikipedia.org/wiki/Stokes_flow}{Stokes' law} and \href{http://en.wikipedia.org/wiki/Hagen-Poiseuille_equation}{Poiseuille's law} are all special cases of the use of viscosity in specific situations. They cannot be derived from \hide{Bernoulli's} equation.} They involve deriving the streamline pattern for the situation from more fundamental equations. As Bernoulli's equation is related to energy, we seek equations more like Newton's laws for the fluid. These are the \jargon{Navier-Stokes equations}. In general these equations are a set of nonlinear partial differential equations for the velocity of the fluid. These kind of problems are among the most difficult in mathematics.\footnote{The equations in general relativity have this same character.}

However, it is possible to model these equations in the computer.\footnote{For more info, see \href{http://en.wikipedia.org/wiki/Computational_fluid_dynamics}{here}.} The computer will never give us the exact solution or a simple equation like those above. But the method is fairly straight-forward and works when other methods don't.

In fact, this is exactly how some CGI effects work. Many models are built to investigate the optimal design for cars, aircraft, even the Space Shuttle. This is also one of the only methods available to study turbulence.

% Deterministic chaos
%%% Deterministic chaos was first discovered by modeling the weather as a fluid.

In fact, it was through the computer simulation of a highly simplified model of the atmosphere that \jargon{deterministic chaos} was first (accidentally) discovered. \href{http://en.wikipedia.org/wiki/Edward_Lorenz}{Lorenz} was running a computer simulation with his model and output the data. The next day he used the print out to restart the calculation and ended up with a completely different result. Ultimately the reason was that the accuracy of the print-out was to three digits, but the computer was calculating with six digits. The mathematical model was highly sensitive to the initial condition---a change in the fourth digit completely altered the simulation.

\prep{This extreme \hide{sensitivity} to initial conditions is the hallmark of deterministic chaos.} It is important to recognize that the apparent chaos in the system is exactly determined by the initial conditions---there is no random element. But the system is very sensitive to the starting conditions. This is also sometimes called the \jargon{butterfly effect} and explains why it is impossible to predict the weather with accuracy more than about a week into the future.\footnote{Not just difficult: mathematically impossible in principle. It is easier to control the weather (which is ultimately an engineering problem) than to predict it!}

An explosion is also extremely sensitive to initial conditions. The final location of the shrapnel depends on the precise way the explosive is constructed. But \prep{in order for a system to be chaotic the dynamics of the system must also be \hide{attracted} back to its original state.} The description of these \jargon{strange attractors} is one of the objectives in chaos theory. So any chaotic system must be both explosively sensitive and must ``fold'' back on itself in some sense.

% Next week

Next week we will have a complete change of topic to discuss heat and temperature. This will occupy us for the next three lectures. We start by simply asking the question: how exactly does one measure temperature? Heat (typically) causes expansion and we will discuss the equations for that. In addition, there are three ways in which heat moves based on the phase of the object transferring the heat. We will also see that heat can change the phase of matter: from solid to liquid to gas, which will give us a physical distinction between heat and temperature. Finally we will round off the topic by discussing temperature extremes: the very hot and the very very cold.
========
15:heat-temperature
--------
Heat and Temperature
--------
Read sections 12.1--12.9 and 13.1--13.4
--------
What is heat? This is a question that goes way back. In antiquity, the ancient Greeks felt that the elements of the world could be categorized by two principles: wetness and heat. These principles combine in each of the four elements (earth, water, air, fire) in a rubric something like Figure \ref{fig:greek-elements}.\footnote{Interestingly, most ancient civilizations had a rubric similar to this. See \href{http://en.wikipedia.org/wiki/Classical_element}{here}.}

\tikzfig[side]{greek-elements}
{
\begin{tikzpicture}[scale=0.8]
%\fill [shade,left color=yellow,right color=green!50!black] (-3,-0.1) rectangle (3,0.1);
%\fill [shade,top color=blue,bottom color=red] (-0.1,-3) rectangle (0.1,3);
%\fill (-0.1,-0.1) rectangle (0.1,0.1);
\path [draw] (0,-3) -- (0,3) node [pos=0,fill=white] {Hot} node [pos=1,fill=white] {Cold};
\path [draw] (-3,0) -- (3,0) node [pos=0,fill=white] {Dry} node [pos=1,fill=white] {Wet};
\node at (-1,1) {Earth};
\node at (1,1) {Water};
\node at (1,-1) {Air};
\node at (-1,-1) {Fire};
\end{tikzpicture}
}{Periodic table of the ancient Greeks}

Although we don't view the elements this way (we see in these ideas a foreshadowing of the phases of matter), the nature of heat was a subject of debate even into the 18th century. At that time there were three competing theories:
\begin{items}
\item \href{http://en.wikipedia.org/wiki/Phlogiston}{Phlogiston}: the fire-like element of the Greeks
\item \href{http://en.wikipedia.org/wiki/Caloric_theory}{Caloric}: a weightless, invisible fluid
\item \href{http://en.wikipedia.org/wiki/Kinetic_theory}{Kinetic}: random motion of molecules 
\end{items}
Ultimately the theory of phlogiston was rejected because it would have been required negative mass in order to remain consistent with the more accurate chemical experiments of the 19th century. However, both the caloric and kinetic theories of heat were viable at that time. Ultimately, the theory of a caloric fluid was subsumed as the conservation of energy and the kinetic theory is what we are all taught in grade school today. We will discuss the kinetic theory in more detail in Lecture \ref{ch:kinetic-theory}.

% A thermometric property is a physical variable that is measurably affected by heat.

\prep{Regardless of the conceptual model we keep with regard to heat, job one of any scientific approach is to \hide{measure} it. For that purpose, we need to identify a \jargon{thermometric property}, that is, some physical effect that is controllably changed by temperature levels.}\footnote{We will soon see a reason to create a distinction between the terms heat and temperature. For now I am switching to use the more proper term temperature for the current discussion.} There many examples of thermometric properties:
\begin{items}
\item The volume of a liquid
\item The length of a metal rod
\item The pressure of a constant volume of gas
\item The electrical resistance of a piece of wire
\item The speed of sound
\item The color of a hot stove
\end{items}
All of these properties and more are potential ways to quantify temperature. The first is the principle behind the standard glass thermometer (using either mercury or alcohol). 

% Of the many possible temperature scales, the Celsius and Kelvin scales are preferred.

The SI unit for temperature is the Kelvin. We need some sort of agreed upon scale to measure temperature. It's okay to be looser when asking the question, ``which is hotter,'' but to ask whether this is twice as hot is another problem altogether. The first temperature scale worthy of the name was developed by Fahrenheit and is roughly calibrated to the weather: zero is a cold day and one hundred degrees is a hot one. This \jargon{Fahrenheit scale} has largely been supplanted by the Celsius scale, but is still used by a small number of countries still behind the times.

Shortly after Fahrenheit, Celsius developed a more ``metric'' scale. This scale uses water as its basis. The freezing point of water is defined as zero degrees, and the boiling point of water is one hundred.\footnote{These hundred degrees lead to this scale sometime being called the centigrade scale. This terminology is antiquated and a bit confusing as it seems to imply a more fundamental unit called a ``grade'' similar to the centimeter.} This \jargon{Celsius scale} is very easy to reproduce (by design) and is commonly used in labs today.

\prep{Fast forward a century and we have the \jargon{Kelvin scale}. Which is simply the \hide{Celsius} scale calibrated to \jargon{absolute zero}.} Using extrapolations based on the temperature dependence of the expansion of gases, this lower bound of temperature was discovered. There are several ways to interpret absolute zero, but perhaps the simplest is that this is the temperature at which all the random thermal motion in an object stops. This lower bound on the Celsius scale is $-273.15 \dg$C. The Kelvin simply adds this number to the Celsius scale yielding ``absolute zero'' Kelvin.

The conversion between these scales is as follows:
\begin{gather*}
F = \tfrac{9}{5} C + 32 \\ C = \tfrac{5}{9}(F - 32)
\end{gather*}
and
\begin{gather*}
C = K - 273.15 \\ K = C + 273.15
\end{gather*}
One important thing to note is that the ``size'' of a degree in temperature is the same in Celsius and Kelvin. In other words, any temperature difference measured on the Kelvin scale is the same number as the difference on the Celsius scale. Frequently the important quantity in a problem is a difference in temperature. In that case we are indifferent to whether the temperature is measured in Celsius or Kelvin. However, there are some cases (e.g., the ideal gas law \eqref{igl}) where the absolute temperature is required. In that case we must remember to convert Celsius into Kelvin before using our equations.

% Thermometric properties are linear in small increments; the simplest is thermal expansion.

Any thermometric property can be represented mathematically as a function of temperature. As we discussed in Lecture \ref{ch:overview} in equation \eqref{taylor-expansion}, any function can be considered linear for small increments. Perhaps the simplest example of this is \jargon{thermal expansion}. Nearly all substances expand when their temperature increases (all else equal). We can write this as
\begin{equation} \label{thermal-expansion}
\frac{\Delta L}{L_0} = \alpha \Delta T
\end{equation}
where $\alpha$ is called the \jargon{coefficient of thermal expansion} which is a characteristic of the material.\footnote{There is also a version of this for volume expansion sometimes denoted $\beta$. This is usually used for liquids since one does not usually have a rod of fluid (though that is what a standard thermometer is). It's not too difficult to show that $\beta = 3 \alpha$. This follows from calculating the new volume if each side expands according to equation \eqref{thermal-expansion} then applying the binomial theorem \eqref{binomial-theorem}.} Notice that the left-hand side of the equation is the same percent strain we introduced in Lecture \ref{ch:elasticity}. This thermal expansion accumulates over the length of the object. So even though the expansion may be a very small percentage, the total expansion may not be trivial. A few centimeters of expansion can slowly rip apart a highway or a battleship.

Usually $\alpha$ is positive indicating that things tend to expand with increasing temperature and shrink with decreasing temperature. One important exception is cold water. \prep{When water gets within four degrees Celsius of its freezing point, it will expand as the temperature drops. This has the effect of decreasing the \hide{density} of the water.} Generally, hot air rises because its expansion results in a lower density---it literally floats over cold air according to Archimedes' principle \eqref{buoyant-force}. By the same reasoning very cold water will float too. The result is that water freezes top down and ice cubes float. This also has the fringe benefit that life can survive in a frozen-over lake because the ice acts as thermal insulation for the liquid water below. One common downside is that frozen pipes burst for the same reason. In fact, the freezing of water in rocks is a major contributor to geological erosion.

% Heat energy is transported via conduction (solids) and convection (fluids).
%%% R-value'' = $L/k$

Having now established a way to quantify and measure temperature, we are prepared to discuss the flow of heat. \prep{Here is where we begin to create a distinction between the ideas of temperature and heat. We see temperature \hide{differences} as the driver of heat flow.}\footnote{Although it is tempting to think of temperature as a kind of potential energy creating a force which drives the flow of heat, this approach doesn't work. Essentially this is the caloric fluid model of heat. There are two fundamental problems: (1) temperature has a natural lower bound, and (2) it is better to associate heat with energy rather than the temperature.} For any solid heat will flow via \jargon{heat conduction}. The rate at which heat energy is transported (i.e., power) is given by
\begin{equation} \label{heat-conduction}
P = \frac{Q}{t} = k \frac{A}{L} \Delta T
\end{equation}
where $k$ is the \jargon{thermal conductivity} of the material. The larger the surface area $A$, the smaller the length $L$, the larger the temperature difference $\Delta T$, the easier heat will flow.\footnote[0.1in]{It should be noted that this is for the simplistic case of heat flowing straight through a rod. The conduction of heat through more complex geometries will obey different equations.}

This formula is similar in form to other equations describing flow like Fick's law \eqref{ficks-law} and Ohm's law \eqref{ohms-law}. The opposite of conduction is resistance. One quantity you may have seen before is the ``R-value'' which is defined as $L/k$. This metric is used rate the quality of insulation. Since it involves the reciprocal of thermal conductivity, this is a kind of thermal resistance. The better the insulation, the higher the R-value. An R-value of 5.6 per inch (typical US home insulation) corresponds roughly to one in SI units.

\prep{Heat conduction also occurs in fluids, but \jargon{heat convection} completely washes out any effect. Convection is caused by the heat being carried \hide{with} the fluid rather than through it.} Since no mass transport occurs in solids, there is no convection possible, but with fluids it is the main method of heat transfer. Unfortunately, fluid flow is so complicated that there is no single formula to describe convection.

% The electromagnetic field is also able to transport heat energy via radiation.

\prep{The third and final way in which heat moves is through \jargon{heat radiation}. This is heat transported through the electromagnetic field. This is the \hide{weakest} form of heat flow, but will work in the vacuum of space} and is how the sun warms the earth. The formula for heat radiation is
\begin{equation} \label{heat-radiation}
P = \frac{Q}{t} = e \sigma A T^4
\end{equation}
where $e$ is called the \jargon{emissivity} and is a property of the material ranging from zero to one. The value of $\sigma$ is $\sci{5.67}{-8}$ and is called the \jargon{Stefan-Boltzmann constant}. It is a property of the electromagnetic field.\footnote{I don't see any reason to not also have heat radiation via the gravitational field. The corresponding constant would be minuscule compared to the electromagnetic field however.} The surface area of the radiating object is $A$ and $T$ is its absolute temperature in Kelvin.\footnote{This is an example of one of the formula where it is important to use Kelvin rather than Celsius. The easy way to remember which is that $\Delta T$ can be either Kelvin or Celsius, but just $T$ must be Kelvin.}

% The difference between heat energy and temperature: specific heat capacity.

Heat will flow whenever there is a temperature differential. But this still does not completely explain what makes some things hot and others cold. \prep{As we pour heat into a substance different materials require more heat than others in order to generate the same increase in \hide{temperature}. This is called the \jargon{heat capacity} of the material.} In general, we have:
\begin{equation} \label{heat-capacity}
Q = cm \Delta T
\end{equation}
where $c$ is the heat capacity, $m$ is the mass involved and $Q$ is the total heat flow required for the $\Delta T$ change in temperature.

% Phase changes also show the distinction between heat energy and temperature.

As we continue to pour heat into a solid object, it will eventually melt. \prep{While it is undergoing this \hide{phase change}, the temperature remains constant. The heat is going somewhere, but not into an increase in temperature.} If one were to plot the temperature as a function of the heat input, the graph would flat-line here. This a characteristic of every \jargon{phase transition}. During the transition the substance is a mixture of the two phases---each at the same temperature.\footnote{In fact, it is possible for all three phases to coexist. This will only occur at a particular combination of temperature and pressure and is called the \jargon{triple point} of the substance. In fact, the modern definition of the Kelvin scale uses the triple point of water rather than the melting and boiling points originally used.} A typical graph might look like Figure \ref{fig:phase-changes}.

\tikzfig{phase-changes}
{
\begin{tikzpicture}[scale=2.5]
%\clip (5.0,-2.0) rectangle (8.7,2.0);
\fill [black!20] (6.0,-1) rectangle (6.5,1.5);
\fill [black!20] (7.0,-1) rectangle (7.5,1.5);
\draw [->] (5.5,-1.0) -- (5.5,1.5) node [above] {$T$};
\draw [->] (5.5,-1.0) -- (8.0,-1.0) node [right] {$Q$};
\draw [thick,->] (5.5,-0.5) -- (6.0,0.2) -- (6.5,0.2) -- (7.0,0.8) -- (7.5,0.8) -- (8.0,1.5);
%\draw [dotted] (6.0,-1) -- (6.0,1.5);
%\draw [dotted] (6.5,-1) -- (6.5,1.5);
%\draw [dotted] (7.0,-1) -- (7.0,1.5);
%\draw [dotted] (7.5,-1) -- (7.5,1.5);
\node [rotate=90,right] at (5.75,-1) {Solid};
\node [rotate=90,right] at (6.25,-1) {Melting};
\node [rotate=90,right] at (6.75,-1) {Liquid};
\node [rotate=90,right] at (7.25,-1) {Evaporation};
\node [rotate=90,right] at (7.75,-1) {Gas};
\end{tikzpicture}
}{Typical phase change diagram}

The slope on this graph represents the heat capacity of the substance. The horizontal distance during the phase changes represent the \jargon{latent heat} required to complete the phase transition. As such, each phase transition requires a certain amount of heat given by
\begin{equation} \label{latent-heat}
Q = mL
\end{equation}
Each transition has its own $L$ value. This makes it possible for us to solve a basic calorimetry problem like the following.

\label{ex:calorimetry}

Sometimes I make my coffee too hot, so I mix in a bit of ice to cool it down. Suppose I have 300 grams of coffee (which is basically water) at 80$\dg$C and mix it with 30 grams of ice at $-10\dg$C. What is the final temperature of the mixture?

Let's call the final temperature for which we are solving $T$. The amount of heat that flows out of the coffee is given by
$$Q_1 = (4186)(0.300)(T - 80)$$
because water has a specific heat of 4186. This heat flow will be negative because the coffee is losing heat.

The process for the ice is three-fold. First, its temperature needs to be brought up the boiling point:
$$(2000)(0.030)(10) = 600$$
then it must melt:
$$(335000)(0.030) = 10050$$
and then this melted ice must be brought to the final temperature $T$:
$$(4186)(0.030)(T - 0)$$
So the total heat that the ice absorbs is
$$Q_2 = 10650 + (125.58)(T)$$
Since the all the heat lost from the coffee is gained by the ice (no ``leakage'' of heat), the total change in heat is zero. Thus
$$Q_1 + Q_2 = 0$$
or
$$(4186)(0.300)(T - 80) + 10650 + (125.58)(T) = 0$$
Solving for $T$ yields a final temperature of 65 degrees Celsius.

For specific combinations of pressure and volume, transitions between any two phases is possible. Consider the diagram in Figure \ref{fig:phase-transitions}.

\tikzfig{phase-transitions}
{
\begin{tikzpicture}[scale=1.5]
\node (g) [draw,fill=black!20,circle,minimum size=1.5cm] at (90:2) {Gas};
\node (l) [draw,fill=black!20,circle,minimum size=1.5cm] at (210:2) {Liquid};
\node (s) [draw,fill=black!20,circle,minimum size=1.5cm] at (330:2) {Solid};
\draw [->] (g) .. controls (150:1.4) .. node[above,sloped] {Condensation} (l);
\draw [<-] (g) .. controls (150:0.7) .. node[below,sloped] {Evaporation} (l);
\draw [->] (l) .. controls (270:1.4) .. node[below,sloped] {Freezing} (s);
\draw [<-] (l) .. controls (270:0.7) .. node[above,sloped] {Melting} (s);
\draw [->] (s) .. controls (30:1.4) .. node[above,sloped] {Sublimation} (g);
\draw [<-] (s) .. controls (30:0.7) .. node[below,sloped] {Deposition} (g);
\end{tikzpicture}
}{The six possible phase transitions between three phases}

In fact, it is possible to have even more phase transitions. \prep{As an extreme example, \hide{plutonium} has six different solid phases making it very difficult to work with.}\footnote{See \url{http://physics.info/expansion}.} Liquid helium has two different phases with a transition at 2.17 kelvin. Below that value it acts as a super-fluid with zero viscosity (something like how a superconductor drops to zero resistance below a certain temperature---see below).

% Temperature extremes: of things very, very hot or very, very cold.

Finally, we will wrap up the lecture with a few notes on temperature extremes. \prep{At the hot end of the scale there is actually a \hide{fourth} state of matter called \jargon{plasma}.} This occurs when the random collisions between the atoms in a gas become so violent that they literally tear the atoms apart into ions and electrons. Plasmas are used frequently in high-tech manufacturing processes and other industrial applications.

But because plasma is electrically active, the fluid dynamics are extremely difficult to model. The currents of plasma have a tendency to curl and twist around one another and ``pinch'' in ways that make it difficult to control. This difficulty is one of the main obstacles in the creation of nuclear fusion energy.

On the other extreme is the very cold. One of the ways to cool down a gas is by letting it quickly expand---essentially reversing equation \eqref{thermal-expansion}. In this way one can create temperatures cold enough to liquefy air. This makes liquid nitrogen pretty easy to acquire for practical uses. Obviously its extremely cold temperature can make it dangerous if used improperly.

\prep{Getting closer and closer to \hide{absolute zero} is quite a story in the history of physics. Each increment is more and more difficult to accomplish (like approaching the speed of light).} Along the way we find \jargon{superconductivity}. First discovered in the early 1900s, this phenomena is when the resistance of certain metals drops to zero---not close to, but literally zero. This is one of the few quantum mechanical effects on a macroscopic scale (the laser is another). As temperatures drop, these quantum mechanical effects become more evident in various ways. Superconductivity is one of the most dramatic examples of this.

% Next week

Next week we will continue the story of heat and temperature. The focus will be on kinetic theory. By assuming that molecules in a gas interact via simple elastic collisions, we will be able to derive the relationship between pressure, volume, and temperature for an ideal gas. This approach is called statistical mechanics and involves quite a bit of math, so we will only be able to touch the surface of this subject. We will also see that diffusion can be explained using the same kinetic theory. In the end we will see that classical statistical mechanics is not as successful as it ought to be given the success of Newtonian mechanics. These failures pave the way to the discovery of quantum mechanics which we will review in Lecture \ref{ch:classical-limits}.
========
16:kinetic-theory
--------
Kinetic Theory
--------
Read sections 14.1--14.4, review Lecture \ref{ch:momentum}
--------
% The kinetic hypothesis identifies heat energy with the random mechanical energy of molecules.

In the previous lecture we investigated some of the basic properties of heat and temperature by focusing on what heat ``does'': how to measure it, how it flows, etc. In this lecture we focus on what heat ``is'': the random motion of molecules.

Richard Feynman has \href{http://www-scf.usc.edu/~kallos/feynman.htm}{said},
\begin{quote}
If, in some cataclysm, all of scientific knowledge were to be destroyed, and only one sentence passed on to the next generation of creatures, what statement would contain the most information in the fewest words? I believe it is the \jargon{atomic hypothesis} that

All things are made of atoms---little particles that that move around in perpetual motion, attracting each other when they are a little distance apart, but repelling upon being squeezed into one another.

In that one sentence, you will see, there is an enormous amount of information about the world, if just a little imagination and thinking are applied.
\end{quote}

Well, today we will apply this idea in the context of the kinetic theory of gases. \prep{The basic idea is that the higher the \hide{temperature} of a gas, the more kinetic energy the molecules possess.} We can even incorporate phase changes into this framework by associating latent heat with the potential energy created through inter-molecular interactions.\footnote{A truly phenomenal website with a simple molecular dynamics applet is located at \url{http://physics.weber.edu/schroeder/software/MDApplet.html}.} 

% The molecular mass of a substance is also equal to the number of grams in one mole.

Before we can speak in detail about molecular motion we need to deal with their size. The radius of a typical atom is on the order of the nanometer. This means that the number of atoms in any laboratory sample is huge. It also means that they are essentially unobservable without highly specialized equipment. This was a major obstacle for the adoption of the atomic hypothesis in the early 1900s. It was none other than Albert Einstein who analyzed \jargon{Brownian motion} (the random, jerky motion of particulates suspended in a fluid) that provided the first indisputable physical evidence for the atom.

The point here is that the fundamental unit of the \jargon{mole}\footnote{Abbreviation: mol. I believe that this is simply a shortening of the word molecule.} has been developed to deal with this atomic size. By definition, the mole is the number of atoms in 12 grams of carbon-12 (a specific isotope of carbon---see Lecture \ref{ch:nuclear-energy}) and has a value of $\sci{6.022}{23}$. This number is called \jargon{Avagadro's number} labeled $N_A$.

You may wonder why we need a special unit for something that is just a number. Isn't it just a naming convention, like a dozen eggs? In a fundamental sense that is true, but one must remember that we are human. No matter how sophisticated our machinery becomes, ultimately measurements must be translated to and from this human scale. There is no way to literally count the number of atoms in a particular sample.\footnote{Maybe with the advances in nanotechnology this will be possible. If that day ever comes, we will still need to define the counting process in a way that is reproducible and independent of external variables.} In other words, the mole is not just a number that we simply arbitrarily choose---it represents the relationship between the lab and the atomic world. This relationship is best summarized in the following formula:
$$\frac{\text{grams}}{\text{mole}} = \frac{\text{molecular mass}}{\text{molecule}}$$
where the \jargon{molecular mass} is the mass of each molecule in so called \jargon{atomic mass units}. By definition a carbon-12 atom has a mass of 12 amu. \prep{The atomic mass units are listed in any periodic chart, so given the chemical make-up of a substance we can determine its total \hide{molecular mass} and therefore the number of moles in a particular sample.}

% The simplest thermal system is one with no molecular interaction at all---an ideal gas.

With this link back to the lab we are now prepared to dive into the world of the microscopic. The simplest microscopic system to analyze is an \jargon{ideal gas}. In an ideal gas, we assume that the molecules have two properties.
\begin{items}
\item Negligible interaction (which will eliminate any possible phase transitions)
\item Negligible size (which will allow the volume to decrease without limit)
\end{items}
We relax both of these conditions enough to allow the molecules to interact through elastic collisions. These collisions will be the only mechanism to distribute kinetic energy throughout the gas (other than collision with the walls of the container). \prep{Most gases at standard temperature and pressure\footnote{Most commonly 0$\dg$C and 101.3 kPa (atmospheric pressure), though some organizations use different definitions.} can be considered \hide{ideal}.}

As mentioned in the previous lecture, \prep{gases will expand with increasing temperature. This \hide{volume} is obviously also related to the pressure surrounding the gas. These three variables combine in the \jargon{ideal gas law}}
\begin{equation} \label{igl}
PV = nRT
\end{equation}
where $n$ is the number of moles of gas and $R$ is a proportionality constant equal to 8.31 in SI units. An alternate form is
\begin{equation} \label{igl2}
PV = NkT
\end{equation}
where $N$ represents the number of molecules in the gas and $k = R/N_A$ is called the \jargon{Boltzmann constant}.

% The ideal gas law follows from the basic principles of Newton's laws of motion.

Now we are ready to introduce some mechanics. Consider a single particle trapped in a cubical box of length $L$. Suppose the particle moves parallel with one of the edges of the box---we will call this direction $\vhat{x}$. Assuming the atom strikes and rebounds off the way elastically (this is an ideal gas), the change in momentum is given by
$$\Delta p = 2mv$$
This collision will occur every time the atom travels the length of the box twice. Given the velocity $v$, we have
$$\Delta t = 2L / v$$
Combining these two results according to the impulse form of Newton's law \eqref{impulse} gives us an average force per collision\footnote{This calculation is similar to the ``machine gun pressure'' problem in Lecture \ref{ch:momentum} on page \pageref{ex:machine-gun-pressure}.} of 
$$\avg{F} = mv^2 / L$$
Since pressure is average force over area, we may write
$$PV = mv^2$$
The right-hand side is simply twice the kinetic energy of the atom.

Now if we consider a random collection of molecules, the momentum will be split into three due to the three dimension of space, so in general we have
$$PV = \tfrac{2}{3} N \avg{KE}$$
where $\avg{KE}$ represents the average kinetic energy per molecule. Comparing this with \ref{igl2} yields
\begin{equation} \label{internal-energy}
\avg{KE} = \tfrac{3}{2}kT
\end{equation}
which explicitly shows the relationship between the temperature of the gas and the random motion of its molecules. This average motion is called the \jargon{internal energy} of the gas. Its the kinetic energy of the system after the bulk motion has been isolated. We have shown the internal energy of an ideal gas to be $\tfrac{3}{2}NkT$ or $\tfrac{3}{2}nRT$.

% Statistical mechanics derives thermal properties from more fundamental laws.

The above derivation of the internal energy of an ideal gas is an example of the use of \jargon{statistical mechanics}. \prep{Essentially we assume that our system is composed of a large number of \hide{identical} pieces (atoms). By applying the laws of mechanics to each part, we can take the overall average to derive the properties of the overall system.} For example, if we relax our restrictions on an ideal gas a bit we can derive the \jargon{Van der Walls equation}:
\begin{equation} \label{van-der-walls}
\left( P + a \frac{n^2}{V^2} \right) \left( V - nb \right) = nRT 
\end{equation}
where $a$ is related to the attraction between the molecules and $b$ the ``size'' of the molecules. This represents an improvement over the ideal gas law \eqref{igl} and is applicable to liquids as well.

% The Maxwell-Boltzmann distribution depicts the molecular speeds in an ideal gas.

Derivations can go the other way too. The \jargon{Maxwell-Boltzmann distribution} represents the number of molecules at various speeds in the gas. There are several simulators on the web to show how this distribution works (here's \href{http://academic.pgcc.edu/psc/chm101/ideal_gas/GasLab\%20Gas\%20in\%20a\%20Box.html}{one}: hit setup then go, use the slider to slow down the animation). The point is that even if the molecules all start with the same speed, through random collisions some will increase in speed and some will decrease. The distribution of speeds over the long haul is what the \href{http://en.wikipedia.org/wiki/Maxwell-Boltzmann_distribution}{Maxwell-Boltzmann distribution} describes.

An example of the distribution is given in Figure \ref{fig:maxwell-boltzmann}. One thing to note is that although the average speed does increases with temperature, there is always a range to the speeds: there are always some that are slow and some that are fast. This is one of the ways to explain evaporation. No matter what the overall temperature of the liquid, there will always be some molecules with high kinetic energies. These molecules have enough energy to escape the potential well that binds the liquid together and escape.

\tikzfig{maxwell-boltzmann}
{
\begin{tikzpicture}
\draw [->] (0,0) -- (7,0) node [pos=0.5,below=1mm] {Molecular speed};
\draw [->] (0,0) -- (0,4) node [pos=0.5,above,rotate=90,yshift=1mm] {Number of molecules};
\node at (1.7,3.0) [right] {Low $T$};
\draw plot [smooth] coordinates {
(0.00,0.0000)
(0.25,0.2417)
(0.50,0.8802)
(0.75,1.6939)
(1.00,2.4197)
(1.25,2.8539)
(1.50,2.9141)
(1.75,2.6422)
(2.00,2.1596)
(2.25,1.6068)
(2.50,1.0955)
(2.75,0.6877)
(3.00,0.3989)
(3.25,0.2143)
(3.50,0.1069)
(3.75,0.0496)
(4.00,0.0214)
(4.25,0.0086)
(4.50,0.0032)
(4.75,0.0011)
(5.00,0.0004)
(5.25,0.0001)
};
\node at (4.5,1.0) [right] {High $T$};
\draw plot [smooth] coordinates {
(0.00,0.0000)
(0.25,0.0309)
(0.50,0.1208)
(0.75,0.2615)
(1.00,0.4401)
(1.25,0.6409)
(1.50,0.8469)
(1.75,1.0415)
(2.00,1.2099)
(2.25,1.3408)
(2.50,1.4269)
(2.75,1.4654)
(3.00,1.4571)
(3.25,1.4066)
(3.50,1.3211)
(3.75,1.2091)
(4.00,1.0798)
(4.25,0.9420)
(4.50,0.8034)
(4.75,0.6704)
(5.00,0.5478)
(5.25,0.4384)
(5.50,0.3439)
(5.75,0.2644)
(6.00,0.1994)
(6.25,0.1476)
(6.50,0.1072)
(6.75,0.0764)
%(7.00,0.0535)
};

\end{tikzpicture}
}{Example of the Maxwell-Boltzmann distribution of speeds in an ideal gas.}

% v_avg = 2/sqrt(pi) * v_peak
% v_rms = sqrt(3/2) * v_peak

On the technical side, notice that the distribution is not symmetric (no negative values). This implies that the most probable speed (the peak of the graph) is not the same as the average speed. It can be shown that the average is about 13\% larger than the peak value.

In fact, the distribution of the kinetic energies depends on $v^2$, so the shape is different though qualitatively the same. But the average kinetic energy does not correspond to either the most probable speed or the average speed. The speed to which it does correspond is called the \jargon{root-mean-square} (abbreviated as RMS) because it is the square root of the average of the square of the speeds. This complicated sounding calculation is actually quite common and shows up in a variety of contexts related to statistics. \prep{Usually called the \jargon{standard deviation}\footnote{Actually, for technical reasons the definition of standard deviation is not quite the same as root-mean-square.}, it is a good measure of the \hide{distribution} in the variable of interest.} One way to see this is that the straight average will cancel negative and positive contributions (which gets you to the middle), but the root-mean-square will accumulate them (which gets at the spread of values). For the Maxwell-Boltzmann distribution, the RMS speed is about 22\% larger than the peak value.

% Fick's law of diffusion also follows from the kinetic hypothesis.

\jargon[diffusion]{Diffusion} is the process in which solutes flow from regions of high concentration to low concentration. The substrate through which the flow occurs could be solid, liquid or gaseous. \prep{Diffusion is comparable to heat \hide{conduction} in many ways and is easy to understand using kinetic theory.} Some of the molecules on the boundary of the high concentration region will have a random motion away from that region. As these molecules flow away they reach the area of low concentration. Though molecules are leaving the low concentration area also, they do so at a smaller rate. More flow in than out. Eventually a concentration equilibrium is established and there is not net flow of material (though the individual molecules are constantly moving back and forth).

The equation governing diffusion is \jargon{Fick's law}:
\begin{equation} \label{ficks-law}
\frac{M}{t} = D \frac{A}{L} \Delta C
\end{equation}
Notice the similarity to the equation for thermal conduction \eqref{heat-conduction}. The amount of mass $M$ transported per second is proportional to the concentration differential $\Delta C$, the geometry of the situation $A/L$, and a proportionality constant $D$ called the \jargon{diffusion constant}.

This is the basic process behind \jargon{osmosis} which has so many applications in biology. \prep{The \hide{osmotic} pressure due to the concentration differentials in water is responsible for the rigidity of plants, the stability of the cell, and is how plants draw water and nutrients from the soil.}

Diffusion is also used in many high-tech processes to control the electrical properties of various substances. We will talk about some of these applications in Lecture \ref{ch:solid-state}.

% Statistical mechanics based on Newton's laws of motion is not as successful as it should be.

It is easy to take the success of kinetic theory for granted. For over two centuries the applications of Newtonian mechanics continued to spread until some began to think there was no other way the universe could work. They were wrong and the first signs were discovered in the decades prior to and after 1900. \prep{Of the two scientific ``revolutions'' around this time, the changes wrought by \hide{quantum mechanics} exceed that of relativity.} When viewed the right way, relativity can be seen as a tweak to the framework of Newtonian mechanics---quantum mechanics reworks the very conceptual foundation. We will return to this topic in Lecture \ref{ch:classical-limits} and discuss relativity and quantum mechanics in more detail in Lectures \ref{ch:em-and-relativity} and \ref{ch:quantum-mechanics}. But for now it is worth mentioning some of the cracks that were discovered in this foundation related to kinetic theory.

The first crack we have already mentioned: superconductivity. As temperatures get down near absolute zero, the electrical resistance of certain materials drop to zero. We shouldn't be surprised to find that electrical resistance drops with decreasing temperature, but exactly zero implies new physics.

The second crack is the heat capacity of solids. According to kinetic theory the heat capacity of any solid should be $3R$. This is based on a result from statistical mechanics called the \jargon{equipartition principle}. It states that the internal energy of a system in thermal equilibrium is $\half kT$ for each degree of freedom. We have seen an example of this in equation \eqref{internal-energy}---the particle has three degrees of freedom corresponding to the three dimensions of motion. In fact, the internal energy of a diatomic molecule is $\tfrac{7}{2}kT$ per molecule because it has seven degrees of freedom.\footnote{Three for translation, two for rotation, and two for vibration. There are only two for translation because rotation about the axis that connects the two atoms is no motion at all (symmetry). Two for vibration because the energy has both kinetic and potential modes.} 

For atoms locked in a solid, there is no translation or rotation, but they can vibrate in three dimensions which means that there are six degrees of freedom per molecule, so the internal energy of the solid ought to be $3NkT$ which corresponds to a specific heat capacity of $3R$. \prep{However, as temperatures get cold the heat capacity of a real solid drops. It is as if some of the \hide{degrees of freedom} are getting ``frozen'' out.}\footnote{In fact, a typical diatomic gas (like nitrogen or oxygen) actually has a specific heat capacity closer to 2.5 because the vibrational modes are inactive. More complex molecules are locked down to about 3. See \href{http://en.wikipedia.org/wiki/Ideal_gas\#Classical_thermodynamic_ideal_gas}{here}.
} This is purely quantum mechanical effect. Einstein created the first  \href{http://en.wikipedia.org/wiki/Einstein_solid}{quantum model} that correctly predicted this effect.

The third crack involves something called the \jargon{ultraviolet catastrophe}. Historically, this is the start of all things quantum. This problem is related to the heat radiation from a so-called \jargon{blackbody}, or an object with emissivity equal to one. The energy spectrum from a black body is qualitatively like that of the distribution in Figure \ref{fig:maxwell-boltzmann},\footnote{I'm just too lazy to draw another diagram---the equations are different. See Figure \ref{fig:uv-cat} for an accurate picture.} but classical statistical mechanics predicts the spectrum to extend into the low wavelength (ultraviolet) without limit. This would imply that all radiation should occur beyond the visible spectrum which anyone who has sat in front of a campfire would say is clearly nonsense. Interestingly, Einstein also had a \href{http://en.wikipedia.org/wiki/Ultraviolet_catastrophe\#Solution}{role to play} in recognizing the way that the quantum hypothesis (introduced by Planck) could resolve this embarrassment.

% Next week

Next week we will finish off our discussion of heat and temperature by talking about thermodynamics proper. This can be seen as a continuation of Lecture \ref{ch:heat-temperature}, but we will need our calculations of internal energy \eqref{internal-energy} to complete the picture. We will state and discuss the laws of thermodynamics, the first of which is simply the conservation of energy. Using simplified thermodynamic processes we will talk about efficiency in heat engines which will lead us to discuss reversibility. This in turn will motivate the definition of a new quantity called entropy which is the subject of the (infamous) second law of thermodynamics.
========
17:thermodynamics
--------
Thermodynamics
--------
Read sections 15.3--15.12
--------
% Thermodynamics was born in the pursuit of building a more efficient steam engine.

\prep{The science of thermodynamics is a product of the industrial revolution and the pursuit of a more efficient \hide{steam engine}.} As such the approach has a strong engineering emphasis---practical rather than theoretical. Another way in which it is distinguished from mechanics is that the approach has more ``systems'' reasoning: we focus on how the properties of the systems interact and change. Though statistical mechanics sheds much light on thermodynamics, technically they are independent. As such, the laws of thermodynamics are is still valid when quantum mechanics replaces classical mechanics.

Our starting point is the conservation of energy. This is called the \jargon{first law of thermodynamics} and is usually written as
\begin{equation} \label{1st-law}
\Delta U = Q - W
\end{equation}
Basically this is saying two things:
\begin{items}
\item Heating a system increases its internal energy ($\Delta U = Q$).
\item Work done by a system decreases its internal energy ($\Delta U = -W$).
\end{items}
Equation \eqref{1st-law} is written in the context of heat engines, so the concern is how much work we can get out of the system---which is why there is a negative sign in front of $W$.

Remember that \prep{the \hide{internal} energy of a system is directly related to its temperature.} For an ideal gas we have
$$\Delta U = dkT/2$$
where $d$ is the number of degrees of freedom for the molecule---we will assume $d = 3$ for a monatomic gas (like argon) and $d = 5$ for a diatomic gas (like oxygen) (see page \pageref{idx:equipartition-principle}).

% The simplest thermal processes involve ideal gases where one variable is held constant.

The first law doesn't seem to say much until we start to add some information about the system under consideration. The simplest system to consider is an ideal gas, for which we have the ideal gas law \eqref{igl}. There are four basic parameters involved: pressure, volume, amount of material (moles), and temperature. The first two are related to work through $W = P \Delta V$.\footnote{This follows from the definition of work $W = F \Delta x$. Divide the first factor by $A$ to get pressure and multiply it into the second factor to get $V$.}

We will normally assume the amount of material is constant in a particular process. However, the other three variables may change in various ways. We will focus on four simpler processes each of which hold a particular variable constant.

The first process is \jargon{isothermal}, meaning that the temperature is held constant. A common way to do this is to connect the system to a \jargon{heat reservoir}.\footnote{Sometimes called a ``heat bath''.} This is simply an outside system which is considered so large that the change in its temperature is negligible due to the flow of heat to and from our system of interest.

Since the temperature is held constant, we know two things. First, the change in internal energy is zero. Second, from the ideal gas law we know that the product of pressure and volume is constant. Usually in an engine we manipulate the volume (driving a piston, for example), so we are interested in the work done when the volume changes in the gas. The challenge here is that the pressure changes too. This calculation involves a bit of calculus, so I will simply quote the result:
\begin{equation} \label{isothermal-work}
W_\text{isoth} = nRT \ln (V/V_0)
\end{equation}
A volume increase corresponds to positive work. Since the temperature is held constant, heat must be flowing into the system from the reservoir to support the process. The amount of heat is equal to the work done according to the first law. \prep{This \hide{isothermal} process shows that it is possible to manipulate the flow of heat without a temperature differential.}

The second process to consider is \jargon{isobaric}, meaning that the pressure is held constant. In this case, the ideal gas law tells us that ratio of volume and temperature is constant. The work done is simply $W_\text{isoba} = P \Delta V$ because the pressure is constant. An easy way to support this kind of process is through an open container exposed to the atmosphere.

The third process is one with constant volume, like with a closed container. This is called a \jargon{isochoric} process. There is no work involved since $\Delta V = 0$.

The fourth and final process we will consider is called \jargon{adiabatic} which means no heat flow. A thermally insulated container will obviously be adiabatic, but also any process that happens quickly. If the process is fast enough, there simply is not enough time for the heat to flow. So, whether a given process is adiabatic or not depends on the thermal conductivity of the materials. But if there is no heat flow, the first law reduces to $\Delta U = -W$, so the work done in an adiabatic process comes from the internal energy of the gas (and a corresponding decrease in temperature). We have:
\begin{equation} \label{adiabatic-work}
W_\text{adiab} = -\tfrac{3}{2} nR \Delta T
\end{equation}
for a monatomic ideal gas.

\prep{In a way, the \hide{adiabatic} process stands in contrast to the isothermal process. Both involve divorcing the connection between heat and temperature.} In the adiabatic flow temperature changes without heat flow but in this isothermal process heat flows without a temperature change. The connection between pressure and volume is similar too. For an adiabatic process we have
\begin{equation} \label{boyles-adiabatic}
PV^\gamma = \text{constant}
\end{equation}
where $\gamma$ is a number larger than one.\footnote{It can be shown that this $\gamma$ is equal to the ratio of the specific heat capacity of the gas at constant pressure relative to that at constant volume.} For an ideal gas, we have
$$\gamma = \frac{d+2}{d}$$
where $d$ is the number of degrees of freedom. For the monatomic ideal gas, $\gamma = 5/3$. This shows that under compression the pressure in an adiabatic process will rise faster than in an isothermal one. Under expansion the adiabatic pressure will fall faster.

% A heat engine is any contraption that harnesses the flow of heat to create work.

These four processes show us how it is possible to use the first law \eqref{1st-law} to convert heat flow into usable mechanical work. Any contraption that harnesses heat flow to create work is called a \jargon{heat engine}. Thermodynamics is primarily the mathematics behind heat engines. Every heat engine is rated by its \jargon{efficiency} which is the power it generates in useful work divided by the power it consumes.\footnote{I like to draw a distinction between a machine which multiplies force, and an engine which does work. In my mind the key metric for a machine is its mechanical advantage, but for an engine it is power: how fast it creates energy. I try and keep a distinction in the nomenclature although I don't think most authors do.} This is equivalent to the definition we used in Lecture \ref{ch:energy} of total work done over the energy consumed because power is work per second.

Since a heat engine converts heat flow into work its primary waste product will be heat energy. Since energy is conserved, we have a simple relationship
$$Q_\text{in} = W + Q_\text{out}$$
which simply says that the energy going in either comes out as usable work or wasted heat. This allows us to write a formula for efficiency in terms of heat:
\begin{equation} \label{heat-engine-efficiency}
e = 1 - \frac{Q_\text{out}}{Q_\text{in}}
\end{equation}
So efficiency is the opposite of how much energy is wasted per unit of input energy.

% Heat flow is always irreversible, but the most efficient engines are nearly reversible.

With much fanfare, we are now ready to introduce the \jargon{second law of thermodynamics}:
\begin{quote}
\emph{Between high and low temperature, heat will flow spontaneously}
\end{quote}
Truly an inspiring statement, huh? I think the reason why there is so much talk about the second law is that this sentence is a Trojan horse of sorts. This simple, obvious statement is the reason why no heat engine will ever be close to 100\% efficient, why no perpetual motion machine can exist, and can even explain the ultimate ``heat death'' of the universe. Understanding how this can be has lead to many alternate formulations of this law. We will discover a few along our way.

The key word in the previous statement is ``spontaneously'' which is closely related to \jargon{irreversibility}. Heat will not flow spontaneously from cold to hot. Of course, heat can flow against a temperature differential (this is what a refrigerator does after all). \prep{But when the heat flow is \hide{spontaneous}, the system does not control the flow of energy. This is unlike a mechanical system in which the energy is flowing due to the internal forces between the parts.} The mechanical energy distribution is directly related to the configuration of the system, so it is possible (in principle) to reverse the flow of energy by simply reverting this configuration back to its initial state. There is nothing a mechanical system can do to reverse the spontaneous flow of heat.

% Even reversible engines cannot be perfectly efficient---it depends on the temperatures.

\prep{So spontaneous heat flow is bad for \hide{efficiency}.} We will now see that even a perfectly reversible heat engine cannot be 100\% efficient. A heat engine requires the flow of heat. But the second law implies that only isothermal heat flow is reversible. In addition, any engine must cycle: the process must repeat. The simplest engine we can consider is one that uses an ideal gas (we've already calculated the work involved for all four basic processes). A complete cycle will involve returning to the same pressure, volume, and temperature. In fact, it's sufficient to track just pressure and volume since if they match, so will the temperature. We can plot the process on a $PV$-chart like Figure \ref{fig:pv-chart}.

\tikzfig[side]{pv-chart}
{
\vspace{-3.5in}
\begin{tikzpicture}
\draw [->] (0,0) -- (0,4) node [above] {$P$};
\draw [->] (0,0) -- (4,0) node [right] {$V$};
%\draw [domain=0.25:4] plot (\x,1/\x);
%\draw [domain=0.50:4] plot (\x,2/\x);
%\draw [domain=0.75:4] plot (\x,3/\x);
%\draw [domain=1.00:4] plot (\x,4/\x);
\draw [domain=0.67:3] plot (\x,2/\x);
\fill (0.67,3) circle (0.05) node [above=1mm] {$A$};
\fill (3,0.67) circle (0.05) node [right=1mm] {$B$};
\end{tikzpicture}
}{An isothermal process for an ideal gas plotted on $PV$ chart}

Simply using isothermal processes is not enough for our engine, however. We could create a cycle from $A$ to $B$ and back, for example, but the work done in the expansion process---given by equation \eqref{isothermal-work}---is equal to the work required to compress the gas back to its initial state. We have an engine but it does no net work.

We can do better. An adiabatic process is also reversible because there is no heat flow at all. This will give us a way to change the temperature of the gas. The simplest non-trivial process which combines isothermal and adiabatic processes is called a \jargon{Carnot cycle} (see Figure \ref{fig:carnot-cycle}). 

\tikzfig[side]{carnot-cycle}
{
\vspace{-2.5in}
\begin{tikzpicture}
\draw [->] (0,0) -- (4,0) node [right] {$V$};
\draw [->] (0,0) -- (0,4) node [above] {$P$};

\draw [domain=1.00:2.50] plot (\x,3/\x);
\draw [domain=2.50:3.50] plot (\x,7.5/\x^2);
\draw [domain=1.43:3.50] plot (\x,2.1/\x);
\draw [domain=1.00:1.43] plot (\x,3/\x^2);

\draw [fill] (1.00,3.00/1.00) circle (0.05) node (a) [above] {$$};
\draw [fill] (2.50,3.00/2.50) circle (0.05) node (b) [above right] {$$};
\draw [fill] (3.50,2.10/3.50) circle (0.05) node (c) [right] {$$};
\draw [fill] (1.43,2.10/1.43) circle (0.05) node (d) [below left] {$$};

\node (1) at (1.75,3/1.75) [above right] {1};
\node (2) at (3,7.5/3^2) [above right] {2};
\node (3) at (2.47,2.1/2.47) [below left] {3};
\node (4) at (1.22,3/1.22^2) [below left] {4};

\end{tikzpicture}
}{Example of the Carnot reversible cycle for a monatomic ideal gas}

Suppose we start the ideal gas in a state of high pressure and low volume. The first step is isothermal expansion. For example, we allow the gas to expand while thermally connected to a heat reservoir at temperature $T_1$. The work done by the gas is given by equation \eqref{isothermal-work}. The second step is adiabatic expansion. We now disconnect the gas from the heat reservoir, thermally isolate the gas, and allow it to continue to expand. The work the gas does is given by \eqref{adiabatic-work}. The gas is now in a low pressure, high volume state with a temperature lower than the initial state.

This is all the work we are going to get out of the engine. We now need to work on returning the gas back to it original state (high pressure, low volume) in order to complete the cycle so we need to compress it. Adiabatic compression will simply reverse what we have already done, so the third step should be isothermal compression. Thermally connect the gas to another heat reservoir at temperature $T_2$ and compress it.\footnote{How far should we compress it? It takes a bit of calculation, but we need $V_D / V_C = V_A / V_B$. This will cause the fourth step to actually complete the cycle.} The fourth step is adiabatic compression which will bring the gas back to its original state.

Work is required in the last two steps, but it will be less than the work done by the gas.\footnote{The net work is actually the area enclosed within the curve from Figure \ref{fig:carnot-cycle}.} We know that the efficiency of the engine is the net work done divided by the input heat energy. This input heat energy occurs during the isothermal expansion. The amount of heat is given by equation \eqref{isothermal-work} because of the first law and the fact that the internal energy does not change.

The heat wasted occurs during the isothermal compression and is also given by \eqref{isothermal-work}. Putting all of these facts together gives us the efficiency for our engine:
\begin{equation} \label{carnot-efficiency}
e = 1 - \frac{T_\text{cold}}{T_\text{hot}}
\end{equation}

Here's the kicker (and also the insight that put Carnot in the history books). This is the best any heat engine can do between reservoirs of these two temperatures. The argument has two parts. The first is simply that any irreversible engine will have a lower efficiency than a reversible one. This is pretty obvious as any spontaneous heat flow will simply add to the wasted heat without any productive work. The second is that \prep{every \hide{reversible} engine will have the same efficiency.} One way to see this is by supposing we have two reversible engines with different efficiencies. Since they are truly reversible, run the more efficient one backward by using the work generated from the first one. In this way we generate excess work without any net heat flow at all!

So, although equation \eqref{carnot-efficiency} was derived for an ideal gas, it represent the maximum possible efficiency of any heat engine. Obviously a real heat engine will be worse. 

% Entropy is heat normalized by temperature; irreversible cycles create entropy.

Take a moment to compare \eqref{carnot-efficiency} with \eqref{heat-engine-efficiency}. They allow us to write
$$\frac{Q_\text{hot}}{T_\text{hot}} = \frac{Q_\text{cold}}{T_\text{cold}}$$
for the Carnot cycle we have been discussing. This suggests there is a kind of quality of heat flow at various temperatures. In a way, the quality of heat flow at a lower temperature is greater than at a higher temperature. This ``quality'' is related to reversibility and is \emph{not} called \jargon{entropy}.

\prep{Entropy is a way of grading the internal energy of a system and is closely related to how closely the system is to thermal \hide{equilibrium}. When the internal energy of a system is far from equilibrium, it is said to be in a low entropy state.} For example, when one hot and one cold object are thermally connected (forming one system) heat will flow. In other words, the internal energy of the combined system redistributes itself until it reaches thermal equilibrium (uniform temperature). Another way to say this is that the system moves from a low to a high entropy state. 

Whenever heat flows out of a system, the entropy changes by
\begin{equation} \label{entropy-dfn}
\Delta S = \frac{Q}{T}
\end{equation}
where $S$ represents the entropy of the system.\footnote{This formula only works for an reversible isothermal process. In order to calculate the entropy change for an arbitrary process, it is sufficient to do so for another process that connects the beginning and end states. The entropy change is independent of the process used to get there.} By this definition, the entropy change in the Carnot cycle is zero. In this way the change in entropy represents the ``quality'' of the heat flow. In an irreversible cycle, the entropy created when the heat flows out of the system at the low temperature exceeds the reduction that occurs when heat is absorbed at the high temperature. The net entropy change is positive. This is a characteristic of any irreversible cycle.

\prep{Entropy is a recognition of the fact that internal energy tends to \hide{uniformity}.} In this way, the \jargon{second law of thermodynamics} is often written as
\begin{equation} \label{2nd-law}
\Delta S \ge 0
\end{equation}
Be aware what this statement does not say: it does not say entropy never decreases---it often does. But whenever the internal energy of a system is pushed away from thermal equilibrium, the entropy increases in the external environment that is doing the pushing. At best the total entropy (system plus surroundings) is zero for a reversible process. The total entropy increases for an irreversible process. Every decrease in entropy is accompanied by a larger increase in entropy somewhere else.\footnote{There is a small loophole here. Another way to affect the entropy of a system is by combining it with another: the total entropy is the sum of the two parts. If the absolute entropy of a system could ever be negative, we could reduce the total in this way. The so-called \jargon{third law of thermodynamics} closes this loophole by stating that the entropy of a system is only zero at absolute zero. In this way, the entropy of a system can never be made negative.}

% Another perspective on entropy: energy lost to mechanical work.

The heat flow that occurs into the cold reservoir is wasted energy and is lost for mechanical work. The entropy change of the process offers us a way to quantify this through the formula
\begin{equation} \label{work-lost}
W_\text{lost} = T_0 \Delta S
\end{equation}
where $T_0$ is the temperature of the coldest reservoir in the system.

% Yet another perspective on entropy: microscopic distribution of heat energy.

We are now prepared to come full circle and discuss entropy in the context of kinetic theory. I have already mentioned how entropy represents the distribution of the energy in a system. For example, if we take a system and divide into two parts, the energy distribution will follow the degrees of freedom in the system. 

We define the microscopic state our system as the way in which the energy is distributed. It can be shown that the number of states available to a system is exponentially dependent upon its degrees of freedom:
\begin{equation} \label{system-states}
\Omega \propto E^{d/2}
\end{equation}
Since the degrees of freedom of a typical gas is related to the number of its atoms, this can become a very large number. \prep{The number of ways in which the energy can be distributed uniformly far \hide{outnumber} the other ways it can be distributed.}

%\tikzfig[side]{energy-distribution}
%{
%\begin{tikzpicture}
%\draw [->] (0,0) -- (4,0) node [pos=0.5,below] {Energy distribution};
%\draw [->] (0,0) -- (0,4) node [pos=0.5,left] {$\Omega$};
%\draw [domain=0:4,smooth] plot (\x,{0.0002*(\x*(4-\x))^7});
%\end{tikzpicture}
%}{Simple calculation for number of states for different energy distributions}

A simple example calculation is shown in Table \ref{tbl:energy-distribution} for a system with five units of energy. The system has two parts with six and four degrees of freedom in the first and second parts, respectively. Notice how the largest number of total states occurs when the energy per degree of freedom is equal in the two parts. Increasing the degrees of freedom makes the distribution much more extreme.

\tbl[side]{energy-distribution}{cc|cc||cc}
{
$E_1$ & $E_2$ & $\Omega_1$ & $\Omega_2$ & $\Omega$ \\ 
\hline
0 & 5 &   0 & 25 &   0 \\ 
1 & 4 &   1 & 16 &  16 \\
2 & 3 &   8 &  9 &  72 \\
3 & 2 &  27 &  4 & 108 \\
4 & 1 &  64 &  1 &  64 \\
5 & 0 & 125 &  0 &   0 \\
}{Calculation of the number of states in a simple two-part system}

The basic postulate of kinetic theory in this context is that the probability of the system being in any microscopic state is equal. In effect this means that the system is usually in a state of uniform distribution. The system is constantly bouncing between different states, but there are so many that the effect is to pull the system to uniformity---which we have previously called equilibrium and ``explains'' the second law.

Boltzman was able to show that the absolute entropy of a system is related to the number of states by
\begin{equation} \label{entropy-states}
S = k \ln \Omega
\end{equation}
a result of which he was so proud that he has it engraved on his tombstone.

% Next week

This completes our survey of thermodynamics. We will switch gears again to discuss wave motion. This will occupy us for the next couple of lectures and then we will apply some of these results to the study of sound and light. In the first lecture we will discuss how waves are generated from a single source. The primary effect is the radiation of energy through some medium whether it is a string, the air, or the electromagnetic field. The speed, wavelength, and intensity of the wave will be discussed. We will extend the topic a bit to include multiple sources at the same location. In the lecture after we will discuss multiple sources separated in space (which leads to interference---the chief characteristic of waves.).
========
18:waves-radiation
--------
Wave Motion and Radiation
--------
Read sections 16.1--16.9
--------
\jargon[radiation]{Radiation} can be divided into two classes: that which transports mass and that which transports energy. An example of the first class is nuclear radiation. When nuclear energy is released, each atomic nucleus acts like a little bomb. The atomic particles go flying in all directions carrying residual kinetic energy. This atomic shrapnel we call radiation. We will see in Lecture \ref{ch:nuclear-energy} that there are three types of natural nuclear radiation each with varying properties.

The second class of radiation is that which transports only energy. This is the kind we refer to when a pebble is dropped in a still pond and we say that the ripples radiate from the impact. This radiation does real work---each wave erodes the shoreline a tiny bit---so energy is truly being transported.

In the first case, the radiation is simply mass in motion. This mass carries momentum and energy which interacts with other matter through the principles we have already studied. But the second case is different. \prep{No mass moves from point A to point B, only energy. This energy transport requires a \jargon{wave medium}. The medium does not itself move from point A to point B, but it does support this transmission of \hide{energy}.}

% A wave requires a source and a medium made up of coupled oscillators near equilibrium.

In order to support this transmission of energy, the medium must be composed of interconnected parts.\footnote{This interconnection is the crucial ingredient and makes the wave motion possible---when one particle moves, those connected will be dragged along with it. These in turn will drag additional parts which propagates the disturbance through the entire medium.} There are many different types of media: strings are the simplest model, but we will also talk about the way waves move through solids and fluids. The electromagnetic field also acts as a medium for waves, although it is a bit of a special case (we will revisit this issue in Lecture \ref{ch:physical-optics} and \ref{ch:classical-limits}).

Since the applications of wave motion are so wide spread, it is useful to keep the discussion fairly abstract. However, most wave phenomena can be seen in a simple string. \prep{The essential characteristic of the wave medium is that it be composed of \hide{coupled} oscillators all near equilibrium.}

Although the medium itself does not move in bulk, there is a direction involved in the radiation of energy. \prep{We say that we have a \jargon{transverse wave} if the oscillation in the medium is \hide{perpendicular} to the movement of the disturbance (like a string).} We have a \jargon{longitudinal wave} if the oscillation is parallel to the radiation (like a compressed spring, or sound waves). Wave motion is not confined to either/or: typical water waves have both transverse and longitudinal components.

By definition, the disturbance of a transverse wave has only one degree of freedom, but a longitudinal wave has two (the $y$ and the $z$ if it is moving along the $x$-direction). To completely describe the wave we need to specify its direction. This is called the \jargon{polarization} of the wave.\footnote[-0.5in]{It is a bit more complicated than this since we could drive the string with a circular type of motion. In that case, the direction of the oscillation rotates in time: this is called circular polarization. More complex combinations are possible as well.} In addition, the disturbance need not be a physical displacement. We could speak of a heat wave, for example. As long as the medium is coupled across this property, radiation will occur. The possible polarization states depend on the nature of the medium.

% Any disturbance in the medium acts as a damped oscillator as its energy radiates away.

Because we are essentially discussing the motion of oscillators, the mathematics begins where Lecture \ref{ch:harmonic-motion} left off. The basic result was that when a system is oscillating sufficiently near equilibrium, the oscillation is governed by equation \eqref{shm}. However, our \prep{oscillators are connected to one another, and the radiation has a \hide{dampening} effect as the energy is propagated away.}\footnote{The rate at which this energy is carried away is called the \jargon{impedance} of the medium.} The oscillation of each element in the medium looks more like Figure \ref{fig:damped-oscillator}.

Now instead of focusing on each element in the medium, we want to discuss the profile of the disturbance across the medium. For simplicity we will talk about an string with a linear mass density of $\mu$ under tension $T$. An element of the string will experience a net force when it and its two neighbors are not in a straight line (see Figure \ref{fig:wave-equation}). \prep{The net force due to the curvature in the string acts to eliminate that curvature. In fact, the stronger the curvature in that ``line'', the greater \hide{force} of restoration.} Mathematically, when the forces of restoration are proportional to the curvature of the disturbance, the medium obeys the \jargon{wave equation} and will support the kinds of waves we are discussing in this lecture.

\pics[side]{wave-equation}
{
\begin{tikzpicture}
\node (a) at (-2,0) [fill,circle,inner sep=0.5mm] {};
\node (b) at (0,1) [fill,circle,inner sep=0.5mm] {};
\node (c) at (2,0) [fill,circle,inner sep=0.5mm] {};

\draw [dotted] (a) -- (b) -- (c);

\node [forcearrow,rotate=-27] at ($(b)!0.24!(c)$) {};
\node [forcearrow,rotate=207] at ($(b)!0.24!(a)$) {};
\node at ($(b)!0.5!(c)$) [fill=white] {$T$};
\node at ($(b)!0.5!(a)$) [fill=white] {$T$};

\draw [->] (b) -- ($(b)+(0,-0.6)$) node [below] {$a$};
\end{tikzpicture}
}{Forces on the element of a string eliminate curvature}

The speed with which any disturbance propagates through this string is also related to the tension and linear mass density. For an ideal string, the speed is given by
\begin{equation} \label{wave-speed-string}
v = \sqrt{T/\mu}
\end{equation}
For a solid this speed represents the speed of sound in the substance. We have
\begin{equation} \label{wave-speed-solid}
v = \sqrt{Y/\rho}
\end{equation}
Actually, this is only the formula for a compression wave in a solid. When a solid is disturbed, the strain can propagate through shear stress as well.\footnote{In fact, this is an example of a non-standard polarization and is important in the investigation of earthquakes. The two types of waves have different wave speeds and can be used to investigate the nature of the Earth's core (see \href{http://en.wikipedia.org/wiki/Seismic_wave}{here} for details).} For a liquid we have
\begin{equation} \label{wave-speed-liquid}
v = \sqrt{B/\rho}
\end{equation}
where $B$ is the bulk modulus. Since the pressure in a gas is temperature dependent, so is the speed of sound. We have
\begin{equation} \label{wave-speed-gas}
v = \sqrt{\gamma kT/m}
\end{equation}
where $m$ represents the molecular mass of the gas.\footnote{A quick cheat for the speed of sound in air is $v = 331 + 0.6 T_\text{cel}$ where $T_\text{cel}$ is the temperature measured in Celsius. This can be derived from equation \eqref{wave-speed-gas} and the binomial theorem \eqref{binomial-theorem}.}

% In order to support a sustained disturbance, a source must drive the oscillation.

If we pluck a string, the oscillation will eventually die away as the energy is radiated through the string (assuming the string is infinite in length). In order to maintain a sustained wave pattern, we must have a source that supplies the energy that is being drained away. The simplest driver is simply one that moves with simple harmonic motion. As we discussed in Lecture \ref{ch:harmonic-motion}, when an oscillator is driven by an outside source, its frequency will match the frequency of the driver regardless of its natural frequency. In this way we can control the motion of the medium from this single driver: all the other elements of the medium (that participate in the radiation) will vibrate with this same frequency.

% [MOVED] The wavelength of the disturbance is related to the driving frequency and radiation speed.

If we consider a string that is being driven at one end by a simple harmonic oscillator, then the resulting disturbance will look like Figure \ref{fig:sine-wave}. In this figure the wave is traveling to the right. Notice how each element of the string oscillates with the same frequency (the white dots, for example) as the driver on the far left. \prep{If the motion of the element \hide{matches} the driver, it is said to be \jargon{in phase} (the gray dots are in phase).} If the motion is the exact opposite (when one is up the other is down---like the white dot), it is said to be \jargon{out of phase}.

\pics[side]{sine-wave}
{
\vspace{-2in}
\begin{tikzpicture}
\foreach \t in {0,...,8}
{
\draw [domain=0:4] plot (\x,{0.75*\t-0.2*sin(180*\x-45*\t)}); 
\draw [dotted] (0,0.75*\t) -- (4,0.75*\t) node [pos=0,left=2mm] {$t$=\t};
\fill (0,{0.75*\t-0.2*sin(180*0-45*\t)}) circle (0.05);
\draw [fill=white] (1,{0.75*\t-0.2*sin(180*1-45*\t)}) circle (0.05);
\draw [fill=white] (3,{0.75*\t-0.2*sin(180*3-45*\t)}) circle (0.05);
\draw [fill=gray] (2,{0.75*\t-0.2*sin(180*2-45*\t)}) circle (0.05);
\draw [fill=gray] (4,{0.75*\t-0.2*sin(180*4-45*\t)}) circle (0.05);
}
\end{tikzpicture}
}{Sine wave profile over time}

It is no coincidence that we use same word ``phase'' in this context and in equation \eqref{shm}. Consider the driver located at point $x = 0$. The closest element that is in phase with it (the first gray dot) has a phase shift of $\phi = -2\pi$ radians, since it is a full cycle behind the driver. The distance between these two elements is called the \jargon{wavelength} of the wave and represents where the wave profile repeats. The phase shift of all the other elements are given by the formula
\begin{equation} \label{wave-phase-shift}
\phi = -\frac{2\pi}{\lambda} x
\end{equation}
where $\lambda$ is the wavelength and $x$ represents the distance from the driver. Using equation \eqref{shm}, we can represent the entire wave profile (in both space and time) with the following formula:\footnote{This formula can also be written as 
$$\psi = A \cos(\omega t - kx)$$
The quantity $k = 2\pi / \lambda$ is called the \jargon{wave number} and is the number of cycles per meter, similar to how frequency is related to period.} 
\begin{equation} \label{wave-formula}
\psi = A \cos \left( 2\pi f t - \frac{2\pi}{\lambda} x \right)
\end{equation}
\prep{The \hide{speed} of the wave is directly related to the frequency and wavelength of the wave.} We have
\begin{equation} \label{vfl}
v = f \lambda
\end{equation}
which follows directly from the constant velocity equation $x = vt$ and the definition of frequency $f = 1/T$.

% More complex sources produce more complex radiation patterns: e.g., multipoles.

Recognize that equation \eqref{wave-formula} only works for one-dimensional waves. For waves that propagate in multiple dimensions, the amplitude must decrease in order for energy to be conserved (energy is proportional to the square of the oscillation's amplitude). Some special mathematics is involved here \ldots for a two-dimensional wave (like the ripples in a pond), equation \eqref{wave-formula} will involve the so-called \href{http://en.wikipedia.org/wiki/Bessel_function}{Bessel functions}. From the top the wave profile will be circular, but from the side it will have a shape (that oscillates up and down) like that in Figure \ref{fig:bessel-function}.

\pics[side]{bessel-function}
{
\vspace{-1in}
\begin{tikzpicture}[xscale=0.125]
\draw [dotted] (0,-1) -- (0,2);
\draw [dotted] (-16,0) -- (16,0);
\draw plot [smooth] coordinates {
(-16.0,-0.1749)
(-15.5,-0.1092)
(-15.0,-0.0142)
(-14.5, 0.0875)
(-14.0, 0.1711)
(-13.5, 0.2150)
(-13.0, 0.2069)
(-12.5, 0.1469)
(-12.0, 0.0477)
(-11.5,-0.0677)
(-11.0,-0.1712)
(-10.5,-0.2366)
(-10.0,-0.2459)
( -9.5,-0.1939)
( -9.0,-0.0903)
( -8.5, 0.0419)
( -8.0, 0.1717)
( -7.5, 0.2663)
( -7.0, 0.3001)
( -6.5, 0.2601)
( -6.0, 0.1506)
( -5.5,-0.0068)
( -5.0,-0.1776)
( -4.5,-0.3205)
( -4.0,-0.3971)
( -3.5,-0.3801)
( -3.0,-0.2601)
( -2.5,-0.0484)
( -2.0, 0.2239)
( -1.5, 0.5118)
( -1.0, 0.7652)
( -0.5, 0.9385)
(  0.0, 1.0000)
(  0.5, 0.9385)
(  1.0, 0.7652)
(  1.5, 0.5118)
(  2.0, 0.2239)
(  2.5,-0.0484)
(  3.0,-0.2601)
(  3.5,-0.3801)
(  4.0,-0.3971)
(  4.5,-0.3205)
(  5.0,-0.1776)
(  5.5,-0.0068)
(  6.0, 0.1506)
(  6.5, 0.2601)
(  7.0, 0.3001)
(  7.5, 0.2663)
(  8.0, 0.1717)
(  8.5, 0.0419)
(  9.0,-0.0903)
(  9.5,-0.1939)
( 10.0,-0.2459)
( 10.5,-0.2366)
( 11.0,-0.1712)
( 11.5,-0.0677)
( 12.0, 0.0477)
( 12.5, 0.1469)
( 13.0, 0.2069)
( 13.5, 0.2150)
( 14.0, 0.1711)
( 14.5, 0.0875)
( 15.0,-0.0142)
( 15.5,-0.1092)
( 16.0,-0.1749)
};
\end{tikzpicture}
}{Bessel function of the first kind of order zero}

In addition, we can talk about sources that are not simple oscillators: so-called \jargon{multipole} oscillators. The radiation patterns can be quite complex (see Figure \ref{fig:radiation-patterns} for some examples). 

\pics[full]{radiation-patterns}
{
\begin{tikzpicture}
\node at (0,0) {\includegraphics[scale=0.5]{images/radiation-monopole.png}};
\draw [fill=white] (0,0) circle (0.1);
\node at (5.2,0) {\includegraphics[scale=0.5]{images/radiation-dipole.png}};
\draw [fill=black] (5.1,0) circle (0.1);
\draw [fill=white] (5.3,0) circle (0.1);
\node at (10.4,0) {\includegraphics[scale=0.5]{images/radiation-quadrupole-lateral.png}};
\draw [fill=white] (10.25,0) circle (0.1);
\draw [fill=white] (10.55,0) circle (0.1);
\draw [fill=black] (10.4,0.15) circle (0.1);
\draw [fill=black] (10.4,-0.15) circle (0.1);
\end{tikzpicture}
}{Radiation patterns from a monopole, dipole, and quadrupole sources \newline Image credit: \url{http://paws.kettering.edu/~drussell/Demos/rad2/mdq.html}}

One interesting thing to note is that the radiation is directional: there are certain directions in which the radiation is minimal. This is one of the ways to construct directional antenna, for example. We won't need to know about this for our class however.

% The medium is called dispersive if different frequencies radiate energy at different speeds.

For the ideal string we have been considering, the formula for the wave speed is a constant. \prep{Frequently in other media this radiation speed will depend on the \hide{frequency} of the disturbance. This is called \jargon{dispersion}.}

One consequence of dispersion is that an arbitrary wave profile will not be preserved as it moves though the medium. In general, preservation will occur only if either (1) the medium is non-dispersive (not common), or (2) the wave profile is a pure sine wave---which has only a single frequency. What typically happens is that the sharp corners on the profile get rounded down over time and the profile spreads out due to its dispersion.

% Intensity is related to both the amplitude of the wave and the power of the driving source.

One final topic is required in this discussion of the radiation of wave energy: that of intensity. When we talk about sound and light as wave phenomena, the intensity corresponds to the our sensory perceptions of loudness and brightness (pitch and color correspond to the frequency of the wave). \prep{Physically, we define the \jargon{intensity} of a wave as the power that passes through a certain area divided by that area---a kind of \hide{density} of how the power radiated.}\footnote{Actually, the intensity is closely related to the energy density of the field. The relationship is $I = ev$, where $e$ is the density of energy (both potential and kinetic) and $v$ is the speed of the radiation. We will see this again in Lecture \ref{ch:em-and-relativity}.} For a single point source, the intensity is related to the distance from the source by
\begin{equation} \label{point-intensity}
I = \frac{P}{4\pi r^2}
\end{equation}
The intensity drops with an inverse square law because the surface area of the surrounding sphere increases with the square of the distance.

An important thing to note (for the next lecture) is that intensity is proportional to the square of the amplitude of the wave since the energy depends on the amplitude squared as in equation \eqref{energy-and-amplitude}.

% ``Intensity level'' calibrates this definition of intensity to our actual sensation of sound.

However, this definition of intensity does not quite complete the story. \prep{Both the sensation of sound and light are not \hide{linear}---the ear and eye are more sensitive to lower intensities than higher intensities.} This suggests creating an alternate scale to measure intensity called the \jargon{intensity level} and is measured in \jargon{decibels}. The formula for decibel level is
\begin{equation} \label{intensity-decibel}
\beta = 10 \log (I / 10^{-12} )
\end{equation}
Although this scale could be used for light, it is designed to work for sound. This is because the sound intensity of $10^{-12}$ watts is the typical the \jargon{threshold of hearing}. This formula calibrates the decibel level at the threshold of hearing to zero. Every decibel increase corresponds to a ten-fold increase in power.

Frequently we need to convert from decibels to intensity. This is done with logarithms, but a short-cut involves using the inverse of the previous formula:
\begin{equation} \label{decibel-intensity}
I = 10^{0.1 \beta - 12}
\end{equation}

% Next week

Next week we continue our discussion of wave motion. We investigate the mathematics of the interference of two waves and what it depends upon. We will also see that waves can rebound off of a boundary (reflection) and can interfere with the original wave source. For just the right combination, the incoming and reflected waves can combine to create a so-called standing wave. We will finish the topic by touching on the question of how waves of differing frequency interact.
========
19:waves-interference
--------
Wave Motion and Interference
--------
Read sections 17.1--17.7
--------
% When the disturbances from two sources combine the instantaneous amplitudes add.

Having discussed the way in which waves propagate through a medium in the last lecture, we are now prepared to discuss how waves interact. Each wave emanates from a source and when the disturbances from two (or more) sources combine, the instantaneous amplitudes add.\footnote{This is sometimes called the ``principle of superposition''. But, to me, this adds a lot of drama over something very simple. Besides, there are many superpositions principles (e.g., the electric field). All it means is that when two things combine they add. If the waves are polarized, this may involve a vector addition.} In a formula one can say:
\begin{equation} \label{wave-superposition}
\psi = \psi_1 + \psi_2
\end{equation}
One important consequence of this is that if the two waves are sinusoidal (i.e., can be written in a form like equation \eqref{wave-formula}), the resulting disturbance will be another sine wave if and only if the original two have the same frequency. So for now we restrict our analysis to interfering waves with the same frequency. For simplicity we will also only consider waves with the same amplitude.

% When two waves combine the interference type depends on the phase difference.

\prep{In general when two waves combine, the \hide{amplitude} of the combination varies. This variation is called \jargon{wave interference} and is the quintessential characteristic of waves.} When Thomas Young showed that light could be made to interfere with itself,\footnote{You'll see how this is done in Lecture \ref{ch:physical-optics}.} this eliminated the simple particle model of light which went back to Newton.

\prep{The interesting thing is that two waves can \hide{annihilate} one another. This occurs when the two waves are out of phase with one another at the point of observation and is called \jargon{destructive interference}.} When the two waves are in phase we get \jargon{constructive interference}. So, the amplitude of the resulting oscillation at the point of interference may be anywhere between zero and twice the original amplitude. 

Remember that the energy of a vibration is proportional to the square of the amplitude according to equation \eqref{energy-and-amplitude}. This implies that the energy transported to this spot may be anywhere between zero to four times the energy of the sources! In some cases (destructive interference) we have no energy transport, in other cases (constructive interference) we have twice the total source energy. Overall, the two extremes average out over the whole space yielding an energy balance.

So, \prep{the wave interference depends on the \hide{phase} difference between the two vibrations.} If $\Delta \phi = 0\dg$ we have constructive interference because the two vibrations are acting together. If $\Delta \phi = 180\dg$, we have destructive interference because the two vibrations are opposing one another. Any phase angle in between will cause something between these two extremes.\footnote{For example, a phase shift of 120\dg will create an amplitude equal to the incoming amplitudes.} Technically it is possible for the phase angle to exceed 360\dg. In this case, the pattern simply repeats. Table \ref{tbl:interference} summarizes these conclusions.

\tbl[]{interference}{cc}{
$\Delta \phi / 360\dg$ & Interference Type \\
\hline
$n$ & Constructive \\
$n+\half$ & Destructive \\
}{Interference criteria, where $n$ is any integer}

% The distance between source and observer adds a phase shift based on wavelength.

So far we have been discussing the interaction of waves at a certain point in space. Now consider two sources separated in space each sending a wave to a third point in space as in Figure \ref{fig:two-sources}. The interference the observer experiences is from the phase difference at the point of observation. 

\tikzfig[side]{two-sources}{
\begin{tikzpicture}[scale=0.5]
\fill [opacity=0.2] (-4,3) -- (1,-1) .. controls (2,-1) and (1,0) .. (2,0) -- cycle;
\fill [opacity=0.2] (3,2) -- (-2,-1) .. controls (-2,0) and (-3,-1) .. (-3,0) -- cycle;
\node (s1) at (-4,3) [fill,circle,inner sep=0.5mm,label=90:{Source 1}] {};
\node (s2) at ( 3,2) [fill,circle,inner sep=0.5mm,label=90:{Source 2}] {};
\node (ob) at (-0.2,0.6) [draw,fill=white,circle,inner sep=0.5mm,label=270:{Observer}] {};
\draw [->] (s1) -- (ob);
\draw [->] (s2) -- (ob);
\end{tikzpicture}
}{Two interfering wave sources}

But we know that the phase of each wave will differ from their source according to equation \eqref{wave-phase-shift}. In addition, the two sources may not be in phase with one another. The interference type at the observation point is a combination of all these factors. The total phase difference is therefore
$$\Delta \phi = \frac{2\pi d_1}{\lambda} - \frac{2\pi d_2}{\lambda} + \phi_0$$ 
where $d_1$ and $d_2$ are the distances from the sources to the observer and $\phi_0$ is the phase difference between the sources.

\prep{If we assume the initial phase difference is zero ($\phi_0 = 0$), then we will have constructive interference when $d_1 - d_2 = n\lambda$. This simply says that an \hide{integer} number of wavelengths need to fit into the path-length difference between the sources and observer.} The key is to calculate the number of wavelengths that fit into the path-length difference:
$$\frac{d_1 - d_2}{\lambda}$$
If this number is an integer, we have constructive interference (assuming the sources are in phase). If this number is a half-integer, we have destructive interference. In this way most of these interference type questions reduce to analyzing the geometry of the situation.

% Reflection off a boundary acts as a second source that can produce standing waves.

We now turn to a different topic: wave \jargon{reflection}. \prep{Whenever a wave encounters a sharp \hide{change} in its medium it will generally split in two. One part will continue on into the new condition, but the other part will bounce off the interface and return.} The first part is said to be the \jargon{transmitted wave}, the second is the \jargon{reflected wave}, and the initial incoming wave is the \jargon{incident wave}. If the medium increases in its wave speed, the amplitude of the transmitted wave will increase. This surplus is compensated by a reflection in the opposite direction. See Figure \ref{fig:reflection-hi2lo}.\footnote[-0.5in]{The following two images are taken from \href{http://paws.kettering.edu/~drussell/Demos/reflect/reflect.html}{here}, which is a really great website to help understand vibrations and waves.}

%\fig[]{reflection-hi2lo}{0.4}{Reflection in a string with 2x wave speed}
\pics[]{reflection-hi2lo}{
\begin{tikzpicture}
\node at (0,0) {\includegraphics[scale=0.4]{images/reflection-hi2lo.png}};
\draw [->] (-3.5,0) -- +(0.5,0);
\draw [->] (1.3,0) -- +(-0.5,0);
\draw [->] (3.0,0) -- +(1.0,0);
\end{tikzpicture}
}{Reflection in a string with 2x wave speed}

If, however, the wave speed decreases, the transmitted amplitude will be smaller. The deficit is compensated in the reflected wave, which now has the opposite polarity. These two negatives (backward motion, opposite polarity) make a positive and balances the initial amplitude. See Figure \ref{fig:reflection-lo2hi}.

%\fig[]{reflection-lo2hi}{0.4}{Reflection in a string with 1/2 wave speed}
\pics[]{reflection-lo2hi}{
\begin{tikzpicture}
\node at (0,0) {\includegraphics[scale=0.4]{images/reflection-lo2hi.png}};
\draw [->] (-3.0,0) -- +(1.0,0);
\draw [->] (1.7,0) -- +(-1.0,0);
\draw [->] (4.0,0) -- +(0.5,0);
\end{tikzpicture}
}{Reflection in a string with 1/2 wave speed}

So far we have been talking about intermediate cases. The extremes represent boundaries which may be either hard or soft. A \jargon{hard boundary} (or fixed end) will reflect with the opposite polarity and represents the extreme version of Figure \ref{fig:reflection-lo2hi}. A \jargon{soft boundary} (or open end) will reflect with the same polarity.

So far we have been talking about a pulse disturbance. If we now turn to discuss a wave like that represented in equation \eqref{wave-formula}, the reflected wave can run back into the region of the incident wave and they may interfere with one another. In effect, the boundary acts as a second source.

In a one-dimensional situation between two sources (with the same amplitude and frequency) a special thing occurs. \prep{Since the wave energy is coming from both directions equally, a \jargon{standing wave} develops: the wave profile is \hide{fixed}.}\footnote{Mathematically this is because the combined wave can be decomposed into a space and time factors. The wave profile is captured in the space component which does not move, and the oscillation is captured in the time component which does not depend on location. You'll need \href{http://en.wikipedia.org/wiki/List_of_trigonometric_identities\#Product-to-sum_and_sum-to-product_identities}{this} to prove it.} The standing wave continues to oscillate up and down, but the profile does not move at all. This standing wave occurs regardless of the distance or phase differences between the sources. The points of destructive interference are the \jargon{nodes} (these elements of the medium don't move at all), and the points of constructive interference of the standing wave (these are the elements with the largest movement) the \jargon{anti-nodes}. 

% The harmonic frequencies of standing waves depend upon the nature of the boundaries.

Now consider a string of length $L$ with one end fixed and at the other end a source of vibration (with frequency $f$). As the initial disturbance propagates through the string, it will reflect off the fixed end and form a standing wave. But when the reflected wave reaches the other end (with the original source) what happens? It will reflect again. But this time there is a difference---this ``third'' source is right on top of the first. \prep{Only if the geometry creates a situation in which these two constructively interfere will the \hide{standing} waves accumulate.} In other words, unless the situation is just right, the reflections will work against the vibration source.

But if the secondary reflection is constructive, the standing waves will resonate. And this is how every stringed musical instrument works. The required condition is simply that the wave repeat after it has traveled the length of the string and back. In other words, 
$$n\lambda = 2L$$
We can rewrite this in terms of the vibration frequency using equation \eqref{vfl}:
\begin{equation} \label{string-harmonics}
f_n = n \frac{v}{2L}
\end{equation}
These are called the frequency \jargon{harmonics} of the string. The first harmonic, $f_1$ is called the \jargon{fundamental frequency}. Since the speed of propagation is related to tension via equation \eqref{wave-speed-string}, we can see how tuning a guitar string can manipulate its resonant pitch and how different string weights can extend the guitar's range of notes.

Another one-dimensional class of musical instrument are the wind instruments. These set a column of air in motion and can be analyzed in a similar way. The main exception is that frequently these instruments are open at one end. This means that the reflected compression wave has the same polarity as the incident wave. But when the second reflection occurs the polarity flips (hard reflection).\footnote{We were able to ignore this in the previous paragraph because the two hard reflections flipped the polarity twice.} We are off by half of a wavelength in order to get the standing waves to resonate. The formula for the harmonics of a half-open column of air can be written as
\begin{equation} \label{tube-harmonics}
f_n = (2n - 1) \frac{v}{4L}
\end{equation}
A column of air open at both ends follows the same logic as the string, so it is also governed by equation \eqref{string-harmonics}.

% Standing waves in more dimensions are more complicated, but some similarities remain.

The third major class of musical instruments is the percussion instruments, which involve banging things together. Although we could consider the triangle as a one-dimensional percussion instrument, usually we think of the drum. The vibration of a two-dimensional membrane is complex and very interesting.\footnote{ \href{http://paws.kettering.edu/~drussell/Demos/MembraneCircle/Circle.html}{This} website is a fantastic resource on this topic.} Essentially, the geometry of the boundary will determine the way the waves are reflected back into the membrane. 

\fig{standing-waves-2d-circle}{0.15}{Standing waves on a circular membrane}
\fig{standing-waves-2d-rectangle}{0.15}{Standing waves on a rectangular membrane}

The main constraint is that the membrane cannot move on this boundary (this is called a \jargon{nodal line}). The notion of a one-dimensional harmonic is replaced with the idea of a vibrational \jargon{mode}. Each mode has its own frequency and is primarily characterized by its nodal lines. \prep{Since these membranes are two-dimensional, each mode is characterized by \hide{two} integers (for example, the number of circular and radial nodal lines).}

We can talk about standing waves in three dimensions (applications to sound production and echoes are relevant here). In this case we need the mathematics of \href{http://en.wikipedia.org/wiki/Spherical_harmonics}{spherical harmonics} which are classified by three integers.

It is even possible to consider the four quantum numbers used in defining the structure of the atomic orbitals as defined by standing matter waves (see Figure \ref{fig:Hydrogen_Density_Plots}). There are four numbers in this case that correspond to the four dimensions of space-time. But we will leave that discussion for Lecture \ref{ch:quantum-mechanics}.

\fig[]{Hydrogen_Density_Plots}{0.4}{Atomic orbitals of the hydrogen atom (image credit \href{http://en.wikipedia.org/wiki/File:Hydrogen_Density_Plots.png}{here})}

% When the frequencies of two sources differ, non-sinusoidal beats result.

This nearly completes our initial survey into wave motion. There is one more topic worth discussing. At the beginning of this lecture we decided to focus on wave interference from sources with the same frequency. But equation \eqref{wave-superposition} works whether the frequencies are the same or not. \prep{If we have two sources with different \hide{frequencies}, they will generate \jargon{beats}.} This is easiest to understand if the two frequencies are similar. Initially, the two sources are in phase and constructive interference occurs. Over time, however, the slower frequency begins to lag behind until the two are completely out of phase. This cycle of constructive and destructive interference continues. The amplitude of the interference cycles in time (see Figure \ref{fig:beats}). This \jargon{beat frequency} can be shown to be simply the difference between the two original frequencies.

\tikzfig[side]{beats}{
\begin{tikzpicture}[scale=0.8]
\begin{scope}[yshift=0mm]
\draw (-0.2,0) -- (6.2,0);
\draw [domain=0:6,samples=200] plot (\x,{0.5*sin(\x*540)});
\end{scope}
\begin{scope}[yshift=-20mm]
\draw (-0.2,0) -- (6.2,0);
\draw [domain=0:6,samples=200] plot (\x,{0.5*sin(\x*660)});
\end{scope}
\begin{scope}[yshift=-40mm]
\draw (-0.2,0) -- (6.2,0);
\draw [domain=0:6,samples=200] plot (\x,{0.5*sin(\x*540)+0.5*sin(\x*660)});
\draw [dotted,domain=0:6,samples=200] plot (\x,{cos(\x*60)});
\draw [dotted,domain=0:6,samples=200] plot (\x,{-cos(\x*60)});
\end{scope}
\end{tikzpicture}
}{Two waves of similar frequency will combine as non-sinusoidal beats}

% Fourier analysis breaks down an arbitrary wave shape into its harmonic components.

We can extend this idea of beats to as many frequencies as we want. The resulting wave profile will be further and further removed from the simple sine and cosine functions with which we are familiar. However, we can turn this to our advantage using Fourier analysis.

\prep{We use \jargon{fourier analysis} to break an arbitrary profile into its \hide{sine wave} components.} Each component can then be analyzed separately. Combining them all back together yields the net motion for the wave profile under investigation. 

\pics[full]{fourier-analysis}
{
\begin{tikzpicture}

\begin{scope}[xshift=-6cm]
\draw [domain=-2:2,samples=400] 
  plot (\x,{
  sin(180*\x)
+ sin(180*\x*3)/3
+ sin(180*\x*5)/5
+ sin(180*\x*7)/7
+ sin(180*\x*9)/9
+ sin(180*\x*11)/11
+ sin(180*\x*13)/13
});
\node [] at (3,0) {\Huge$=$};
\end{scope}

\draw [domain=-2:2,samples= 50,yshift=2.4cm] plot (\x,{sin(180*\x)});
\draw [domain=-2:2,samples=100,yshift=0.6cm] plot (\x,{sin(180*\x*3)/3});
\draw [domain=-2:2,samples=150,yshift=-0.3cm] plot (\x,{sin(180*\x*5)/5});
\draw [domain=-2:2,samples=200,yshift=-1.0cm] plot (\x,{sin(180*\x*7)/7});
\draw [domain=-2:2,samples=250,yshift=-1.6cm] plot (\x,{sin(180*\x*9)/9});
\draw [domain=-2:2,samples=300,yshift=-2.1cm] plot (\x,{sin(180*\x*11)/11});
\draw [domain=-2:2,samples=350,yshift=-2.5cm] plot (\x,{sin(180*\x*13)/13});


\begin{scope}[xshift=4cm]
\node [] at (-1,0) {\Huge$=$};
\begin{scope}[yshift=-1cm]
\draw [->] (0,0) -- (4.6,0) node [pos=0.5,below=5mm] {Frequency spectrum};
\draw [->] (0,0) -- (0,2.4) node [pos=0.5,left] {$A$};
\foreach \i in {1,3,...,13}
{
\draw ({-0.1+0.3*\i},0) rectangle +(0.4,{2/(2*\i-1)});
\draw ({0.1+0.3*\i},0) -- +(0,-0.0) node [below] {\i};
}
\end{scope}
\end{scope}

\end{tikzpicture}
}{Example Fourier analysis for a step wave profile}

Figure \ref{fig:fourier-analysis} shows how a step profile can be decomposed into sine wave components. The analysis determines the amplitude required for each component to combine into the desired shape. The sharpest corners correspond to the highest frequency components---which typically move fastest. This is why these corners are first to wash out in the profile. The highest frequencies determine how faithfully a digitized recording of sound can reproduce the original.

% Next week

Next week we will move on to discuss light. We will examine the relationship between the wave motion we have been discussing and the ray picture of light. By doing this we are implicitly ignoring the wave nature of light (which is valid when the dealing with objects larger than the microscopic. This is called geometric optics and is governed by three simple laws regarding the propagation of rays, their reflection and refraction. We will investigate the operation of mirrors and lenses and how to correct their weaknesses. Finally we will quickly touch on Fermat's principle which is closely related to the principle of least action.
========
20:geometric-optics
--------
Geometric Optics
--------
Read sections 25.1--25.6 and 26.1--26.9, look back at 16.10
--------
% Wave fronts are defined by constant phase, rays are perpendicular to these wave fronts.

The study of light is one of those subjects that go back to antiquity. It's truly marvelous that a subject so common and essential to our daily lives would have such a deeply profound character. We now know that light is waves of electromagnetic energy governed by the laws of quantum electrodynamics. As such, light has a connection to all of the areas of modern physics: electromagnetism, relativity, and quantum mechanics.

\prep{For now, we will ignore these fundamental facts and focus on the way light \hide{moves}. We will do this by using the idea of a \jargon{light ray}.} In Lecture \ref{ch:waves-radiation} we introduced the idea of waves as the radiation of energy. In this lecture we will make that idea more concrete.

When we draw the radiation of wave energy from a point source, it is common to do this with slowly increasing arcs (see Figure \ref{fig:wave-fronts}). Mathematically, each arc represents all the points of the wave pattern with the same phase. As time progresses, each point along this line oscillates up and down together. These lines are each called a \jargon{wave front} of the radiation pattern. 

\tikzfig[side]{wave-fronts}{
\begin{tikzpicture}
\clip (-0.8,-1.8) rectangle (3.5,1.8);
\begin{scope} 
\clip (0,0) -- (-45:3) arc (-45:45:3) -- cycle;
\draw (0,0.0) circle (0.6);
\draw (0,0.0) circle (1.2);
\draw (0,0.0) circle (1.8);
\draw (0,0.0) circle (2.4);
\end{scope}
\draw [->] (0,0) -- ( 30:3);
\draw [->] (0,0) -- (  0:3);
\draw [->] (0,0) -- (-30:3);
\draw [rotate= 30] (1.800,0.000) rectangle +(0.1,0.1);
\draw [rotate=  0] (1.800,0.000) rectangle +(0.1,0.1);
\draw [rotate=-30] (1.800,0.000) rectangle +(0.1,0.1);
\fill (0,0) circle (0.1);
\end{tikzpicture}
}{Wave fronts and rays from a point source}

\prep{The light rays are defined as the lines that propagate through each wave front \hide{perpendicularly}.} Remember in three dimensions these wave fronts are actually surfaces of constant phase, so the rays are perpendicular to this surface.\footnote{We can create a \jargon{propagation vector} which points in this direction and defines the ray completely if we give it a magnitude equal to the wave-number as defined on page \pageref{idx:wave number}.} One important consequence of this definition is that in variable media, the rays will curve (see Figure \ref{fig:wave-fronts2}). 

\tikzfig[side]{wave-fronts2}{
\begin{tikzpicture}
\clip [shade,top color=white,bottom color=black!20] (-0.8,-1.5) rectangle (3.5,2.5);
\begin{scope} 
\clip (0,0) -- (-45:3) arc (-45:45:3) -- cycle;
\draw (0,0.0) circle (0.6);
\draw (0,0.2) circle (1.2);
\draw (0,0.4) circle (1.8);
\draw (0,0.6) circle (2.4);
\end{scope}
\draw [->,rotate= 45] (0,0) arc (90:60:6.0);
\draw [->,rotate= 15] (0,0) arc (90:63:6.0);
\draw [->,rotate=-15] (0,0) arc (90:66:6.0);
\draw [rotate= 26] (1.980,0.340) rectangle +(0.1,0.1);
\draw [rotate= -3] (1.787,0.305) rectangle +(0.1,0.1);
\draw [rotate=-32] (1.594,0.270) rectangle +(0.1,0.1);
\fill (0,0) circle (0.1);
\end{tikzpicture}
}{Wave fronts and rays from a point source in a variable medium}

In variable media, the speed of the waves changes therefore so does the wavelength according to equation \eqref{vfl} (the frequency is constant). \prep{The wave fronts in \hide{slower} media will be closer together which has a tendency to pull the rays into this area. This is called \jargon{refraction} and can occur for any multi-dimensional wave.} This bending of wave energy occurs for earthquake waves as they move through the earth. This is one of the main ways we know that the earth's core has both liquid and solid layers (see \href{http://en.wikipedia.org/wiki/P-wave\#Seismic_waves_in_the_Earth}{here} for more info). It also explains why mirages can sometimes be seen on a hot day and how fiber-optic cables work.

% Geometric optics ignores the wave nature of light and is based on three geometric laws.

So far we have made no simplifying assumptions in our description. This approach using rays is mathematically equivalent to the use of the wave equations from the previous two lectures.\footnote{There is actually something profound in this which is related to the ``wave-particle duality'' we will see in Lecture \ref{ch:quantum-mechanics}.} This explains why it was possible to consider a particle theory of light for so long, since it is easy to imagine particles of light moving along trajectories defined by these light rays.

\prep{Also, the wavelength of light is on the order of a \hide{micrometer} or less. This means that the typical wave characteristics like diffraction and interference are only manifest when dealing with microscopic objects.} In every-day applications we can ignore the wave nature of light and assume that light rays obey the laws of \jargon{geometric optics}:
\begin{items}
\item Rectilinear propagation. In a uniform transparent medium without obstacles, light rays move in straight lines. (This is why shadows are sharp).
\item Law of reflection. When encountering a reflective surface, light rays will bounce so that the angle of reflection equals the angle of incidence.
\item Law of refraction. When encountering a change in transparent media, the refraction angle of the ray is governed by Snell's law \eqref{snells-law}.
\end{items}

% A curved mirror will act as a lens creating a magnified image based on its focal length.

We will discuss refraction shortly---for now we focus our discussion of reflection. In and of itself, reflection is pretty easy to understand: it's not unlike a ball bouncing off of a wall. Where things start to get interesting is when we use this reflection to focus light with the use of a \jargon{lens}.

Circular lenses are not the optimal cross-section for a lens, but circular lenses are much easier to make and they work reasonably well if the size is not too large.\footnote{The best cross-section is a parabola which is why high precision instruments like radio telescopes are this shape. The headlights on your car are this shape too.} This is called the ``thin lens approximation''.

\prep{If we take a small circular mirrored lens, it will focus incoming rays of light at a point \hide{halfway} between the center of the circle and the far edge of the lens} (see Figure \ref{fig:focal-point}). This is because the angle of reflection is measured off of the perpendicular from the mirror which goes through the center. This is called the \jargon{focal point} of the lens.

\tikzfig[side]{focal-point}{
\vspace{-0.25in}
\begin{tikzpicture}
\coordinate (c) at (0,0);
\coordinate (x) at (2,0);
\coordinate (f) at ($(c)!0.5!(x)$);
\begin{scope}
\clip ($(c)+(-0.1,-0.8)$) rectangle ($(x)+(0.1,0.8)$);
\fill [black] (0,-5) rectangle (5,5);
\node (m) [draw,fill=white,circle through=(x)] at (c) {};
\end{scope}
\foreach \y in {0.75,0.25,...,-0.75}
{
\coordinate (p1) at (-2,\y);
\coordinate (p2) at ($(p1)+(1,0)$);
\coordinate (p3) at (intersection of p1--p2 and m);
\draw [->,help lines] (p1) -- (p3) -- ($(p3)!1.5!(f)$);
}
\draw [fill=white] (f) circle (0.05) node [below=1mm] {$f$};
\draw [fill] (c) circle (0.05) node [below=1mm] {$C$};
\end{tikzpicture}
}{Focal point of a circular mirrored lens}

\prep{The defining characteristic of the focal point is that parallel rays will meet at the \hide{focal point} after being reflected off the mirror.} We can use this fact to determine the location of the image reflected from the mirror.

\tikzfig[side]{mirror-real-image}{
\vspace{0.5in}
\begin{tikzpicture}
\coordinate (c) at (0,0);
\coordinate (x) at (3,0);
\coordinate (f) at ($(c)!0.5!(x)$);
\coordinate (obj) at (-1,0.6);
\begin{scope}
\clip ($(c)+(-0.1,-0.8)$) rectangle ($(x)+(0.1,0.8)$);
\fill [black] (0,-5) rectangle (5,5);
\node (m) [draw,fill=white,circle through=(x)] at (c) {};
\end{scope}
\coordinate (r1) at (obj -| x);
\coordinate (x1) at (intersection 1 of obj--r1 and m);
\coordinate (x2) at (intersection 1 of obj--f and m);
\coordinate (r2) at (x2 -| x);
\coordinate (img) at (intersection of x1--f and x2--r2);
\draw [->] (obj) -- (x1) -- ($(x1)!1.4!(img)$);
\draw [->] (obj) -- (x2) -- ($(x2)!1.4!(img)$);
\draw [->,ultra thick] (obj |- c) -- (obj);
\draw [->,ultra thick] (img |- c) -- (img);
%\draw [dotted] (obj |- c) -- (x) -- (img |- c) -- (c);
\draw [dotted] (obj |- c) -- (x);
\draw [fill=white] (f) circle (0.05);% node [below=1mm] {$f$};
%\draw [fill] (obj) circle (0.05);
%\draw [fill] (img) circle (0.05);
\end{tikzpicture}
}{The image of an object outside the focal length is inverted and real}

Consider Figure \ref{fig:mirror-real-image}. The object is on the left and we consider two very particular light rays which leave the tip of the arrow. The first ray runs horizontal and we know that this ray will bounce through the focal point and continue on down. The second ray goes directly to and through the focal point. We know that this ray will bounce and then run horizontal because the geometry is the same whether the rays run backward or forward. These two lines intersect at the location of the image. If we were to put a screen here, we would get a sharp image of the object. The rays of light appear to be generated from this spot and it is therefore called a \jargon{real image}.

After examining the geometry of this situation (the upper and lower triangles are similar), the \jargon{lens equation} that governs this is
\begin{equation} \label{lens-equation}
\frac{1}{d_o} + \frac{1}{d_i} = \frac{1}{f} 
\end{equation}
where $d_o$ is the distance from the object to the lens and $d_i$ is the distance from the image to the lens. The magnification of the height of the image is
\begin{equation} \label{lens-magnification}
m = - \frac{d_i}{d_o}
\end{equation}
The negative sign indicates the image is inverted.

Though equation \eqref{lens-equation} is the commonly used lens equation, it can also be shown that
\begin{equation} \label{lens-equation-newton}
x_o x_i = f^2
\end{equation}
where $x_o$ and $x_i$ are the distances from the focal point to the object and image, respectively. This form of the lens equation is due to Newton (the other is associated with Gauss) and to my mind a bit easier to derive from the ray diagram in Figure \ref{fig:mirror-real-image}. 

After playing with these equations for a while, you may notice that equation \eqref{lens-equation} gives a negative image distance if the object is within the focal length of the mirror (i.e., $d_o < f$). This is still correct and is telling us that the image is located on the other side of the mirror (see Figure \ref{fig:mirror-virtual-image}).

\tikzfig[side]{mirror-virtual-image}{
\begin{tikzpicture}
\coordinate (c) at (0,0);
\coordinate (x) at (3.5,0);
\coordinate (f) at ($(c)!0.5!(x)$);
\coordinate (obj) at (3,0.5);
\begin{scope}
\clip ($(c)+(-0.1,-0.8)$) rectangle ($(x)+(0.1,0.8)$);
\fill [black] (0,-5) rectangle (5,5);
\node (m) [draw,fill=white,circle through=(x)] at (c) {};
\end{scope}
\coordinate (r1) at (obj -| x);
\coordinate (x1) at (intersection 1 of obj--r1 and m);
\coordinate (x2) at (intersection 2 of obj--f and m);
\coordinate (r2) at (x2 -| x);
\coordinate (img) at (intersection of x1--f and x2--r2);
\draw [dotted] (x1) -- ($(x1)!2!(img)$);
\draw [dotted] (x2) -- ($(x2)!2!(img)$);
\draw [dotted] (x2) -- ($(x2)!2!(f)$);
\draw [->] (obj) -- (x1) -- ($(x1)!-5!(img)$);
\draw [->] (obj) -- (x2) -- ($(x2)!-5!(img)$);
\draw [->,ultra thick] (obj |- c) -- (obj);
\draw [->,ultra thick] (img |- c) -- (img);
\draw [dotted] (c) -- (img |- c);
%\draw [dotted] (obj |- c) -- (x) -- (img |- c) -- (c);
\draw [fill=white] (f) circle (0.05);% node [below=1mm] {$f$};
%\draw [fill] (obj) circle (0.05);
%\draw [fill] (img) circle (0.05);
\end{tikzpicture}
}{The image of an object inside the focal length is upright and virtual}

In this case \prep{the image is said to be a \jargon{virtual image} because although the light rays \hide{appear} to be coming from this point in space, they never do go there.} Putting a screen behind the mirror will not capture a sharp image of the object no matter how hard you try. Notice that the magnification equation \eqref{lens-magnification} still works because the negative image distance yields a positive magnification which implies the image is upright.

So far we have only discussed lenses that are convex. All the same principles apply for a mirror that is concave in shape (see Figure \ref{fig:concave-convex}). For a concave mirror, the focal length is negative since parallel lines will diverge giving the impression that the image is behind the mirror. In fact, the image in a concave mirror is always virtual.

\tikzfig[side]{concave-convex}{
\begin{tikzpicture}
\begin{scope}
\coordinate (c) at (0,0);
\coordinate (x) at (2,0);
\node at ($(x)+(-0.1,1.2)$) {Convex};
\clip ($(x)+(-0.3,-0.8)$) rectangle ($(x)+(0.1,0.8)$);
\fill [black] (0,-5) rectangle (5,5);
\node (m) [draw,fill=white,circle through=(x)] at (c) {};
\end{scope}

\begin{scope}[xshift=20mm,scale=-1]
\coordinate (c) at (0,0);
\coordinate (x) at (2,0);
\node at ($(x)+(-0.1,-1.2)$) {Concave};
\clip ($(x)+(-0.3,-0.8)$) rectangle ($(x)+(0.1,0.8)$);
\fill [white] (0,-5) rectangle (5,5);
\node (m) [draw,fill=black,circle through=(x)] at (c) {};
\end{scope}
\end{tikzpicture}
}{Lenses concave and convex}

We can continue and talk about combinations of mirrored lenses, but the mathematics always involves using equations \eqref{lens-equation} and \eqref{lens-magnification}. The important point to remember is that the image of the first lens becomes the object of the next. In this way we can daisy-chain our way through any combination of lenses.

% Snell's law governs the angles involved in refraction and is related to the speed of light.

We are now ready to discuss the third law of geometric optics: refraction. Though the ancient Greeks knew about the law of reflection, they never could quite get the law of refraction. The correct law (known as \jargon{Snell's law}) was discovered in the early 1600s:
\begin{equation} \label{snells-law}
n_1 \sin \theta_1 = n_2 \sin \theta_2
\end{equation}
This governs the angles involved when a light ray encounters a sharp boundary in the transparent medium. The values of $n_1$ and $n_2$ are called the \jargon{index of refraction} for the material and the angles $\theta_1$ and $\theta_2$ are measured from the normal line to the surface (see Figure \ref{fig:snells-law}).

\tikzfig[side]{snells-law}{
\begin{tikzpicture}
\clip (-2,-2) rectangle (2,2);
\draw [fill=black!20] (-3,-3) rectangle (3,0);
\draw [dotted] (0,2) -- (0,-2);
\draw (-2,2) -- (0,0) -- (1,-2);
\draw [dashed] (0,0) -- (2,2);
\node at (110:0.8) {$\theta_1$};
\node at (-75:1.2) {$\theta_2$};
\node at (1,0.5) [fill=white] {$n_1 = 1.00$};
\node at (-1,-0.5) {$n_2 = 1.58$};
\end{tikzpicture}
}{Snell's law of refraction}

\prep{The index of \hide{refraction} is a measure of the ``refractive power'' of the material. The higher the value of $n$, the more light will bend when entering it from the air.} Though values can vary based on the composition of the material, typical values are listed in Table \ref{tbl:refraction-indexes}. By definition, the index of refraction of vacuum is one.

\tbl[side]{refraction-indexes}{cc}{
Air & 1.0 \\
Water & 1.3 \\
Glass & 1.5 \\
Diamond & 2.4 \\
}{Typical indexes of refraction}

If we shine a ray of light from inside a larger index of refraction material to a smaller one, the ray will bend outward according to Snell's law \eqref{snells-law}. There is a particular angle (called the \jargon{critical angle}) in which the refracted ray is effectively at 90\dg to the surface. Any incident angle beyond this is said to suffer total internal reflection because none of the light energy is transmitted out. The measurement of the critical angle for a substance is an easy way to accurately determine its index of refraction.

As we noted at the beginning of this lecture, the refraction of a wave is related to the propagation speed of the medium. This is true of the index of refraction as well. The relationship is simple:
\begin{equation} \label{index-speed}
n = c / v
\end{equation}
where $c$ is the speed of light in vacuum and $v$ is the speed of light in the material.

% Most optical problems involve locating the image of an object and its magnification.

Of course we can use the refractive power of a material to create a lens too. In just the same way as with a reflective lens we define the focal point to be the location where parallel lines meet after passing through the lens. Interestingly because this definition is the same as with mirrors, the geometry in the ray diagrams is very similar and the equations \eqref{lens-equation} and \eqref{lens-magnification} also hold for thin transparent lenses also. The one difference is that the sign conventions are different because images from a lens tend to be on the opposite side of the object. Table \ref{tbl:lens-conventions} outlines the differences.

\tbl[]{lens-conventions}{ccc}{
This is positive when\ldots & Mirror & Lens \\
\hline
Focal length ($f$) & Convex & Convex \\
Object distance ($d_o$) & To the left & To the left \\
Image distance ($d_i$) & To the left & To the right \\
}{Sign conventions for use in the lens equations}

Just as with multiple mirrored lenses, we can combine transparent lenses and analyze the images using the lens equations. As before, the main principle is that the image of the first lens becomes the object of the next. Most microscopes and telescopes involve multiple lenses in order to magnify the objects under investigation.

One simple example is from optometry. The \jargon{optical power} of a lens is defined as the reciprocal of its focal length (so stronger lenses have higher numbers). This refractive power is measured in \jargon{diopters} which is simply one over one meter. \prep{When two lenses are \hide{touching}, the refractive powers add.}\footnote{This follows directly from equation \eqref{lens-equation}.}. Since glasses and contact lenses are typically quite close to the lens of the eye, this simplifies the analysis of correcting vision by simply adding or subtracting diopters from the natural power of the patient's eye. The optical power of a normal eye is about \href{http://en.wikipedia.org/wiki/Dioptre\#In_optometry}{60 diopters}.

% Most transparent materials are dispersive---which explains prisms and rainbows.

Isaac Newton was very interested in the study of light, performed many experiments, and wrote a major treatise on the subject. And it was he who discovered the principle behind the rainbow: that \prep{white light is actually all the colors of the rainbow mixed. We can understand this realizing that most transparent materials are \hide{dispersive} (that is, the speed of wave propagation varies with frequency).} Since the color of light corresponds to the frequency of the wave, we expect the index of refraction to be color-dependent as well. Typically differences in color account for about a 2\% change in the index of refraction.

% The fact that most real lenses cannot focus an image to a single point is called aberration.

We have already noted that circular lenses will only focus the light along a relatively small arc of the curve. If the arc is extended, the curve is too fast and pulls the rays in and away from the focus. This ``de-focused'' effect is called the \jargon{aberration} of the lens and is generally a thing to be avoided. The shape that will focus all the parallel rays of light perfectly is a parabola and has no aberration due to its shape.

However, another way lenses are aberrant is due to dispersion. Aberration of this sort is called ``chromatic''. It is sometimes possible to correct this kind of aberration by combining lens of different indexes of refraction to bring all the colors of light back together at the final focal point.

% Fermat's principle: Light travels the path that takes the least total time.

Other than equation \eqref{index-speed}, we have essentially ignored the speed of light. Nothing in the laws of geometric optics touches on the speed of light. Perhaps this is because light speed is so fast. For all intents and purposes it travels instantaneously. Of course we now know this is not the case, but geometric optics is just that: geometric. There is no time component involved, no dynamics.

\prep{In the late 1600s, Pierre de Fermat discovered that all three \hide{geometric} laws could be summarized in one simple principle: the \jargon{principle of least time}. The time required to travel from point A to point B is along any other path than the true one takes more time.} This was the first (and simplest) example of a variational principle in physics and became an archetype for \href{http://en.wikipedia.org/wiki/Variational_principle\#Examples}{several others} including the principle of least action which we mentioned in Lecture \ref{ch:energy}.

% Next week

Next week will bring our study of waves and light to a close. We will discuss the wave nature of light---including diffraction and interference phenomena. Nearly all of the concepts have been already introduced, but some interesting applications will be reviewed. We will mention how light is polarized. Also we will touch on the distinction between coherent and incoherent light---which is the difference between laser light and ordinary light. Finally we will finish the discussion on a philosophical note regarding the existence of the ether.
========
21:physical-optics
--------
Physical Optics
--------
Read sections 27.1--27.7 and 27.9 then 24.1--24.2 and 24.6
--------
In the previous lecture we focused on the properties of light that ignores its wave-like nature. This left us primarily with the simple radiation of energy which we found convenient to describe using the light ray. In this lecture we broaden this scope to discuss how light is like a wave.\footnote{There is a third level of analysis awaiting us: the electromagnetic nature of light. We will touch on that in Lecture \ref{ch:em-and-relativity}.} 

\prep{There are three observable properties that are associated with waves: interference, \hide{diffraction}, and attenuation.} Of the three really only interference requires a wave, but diffraction and attenuation are easier to understand with waves.

% The double slit experiment provides definitive evidence for the wave nature of light.

In the early 1800s, Thomas Young published his definitive experiment which provided evidence for the wave nature of light. We will start by describing his \jargon{double slit} experiment. (Quantum mechanics casts a shadow over the interpretation of these results---but we will leave that for the next lecture.)

The double slit experiment is simply that: two parallel slits close together. If we send a single coherent wave through these slits, they both act like waves sources that are in phase with one another and interfere. If we place a screen in the distance, we can capture the pattern of constructive and destructive interference.

\tikzfig{double-slit}{
\def\y{2}
\def\L{6}
\def\x{1.5}
\def\a{0.5}
\begin{tikzpicture}
\draw [thick] (0,\y) -- (0,-\y);
\draw [thick] (\L,\y) -- (\L,-\y);
\coordinate (s1) at (0,\a);
\coordinate (s2) at (0,-\a);
\coordinate (x) at (\L,\x);
\draw [<->] (0,-0.8*\y) -- (\L,-0.8*\y) node [pos=0.5,fill=white] {$L$};
\draw [dotted] (0,0) -| (x) -- cycle;
\node at ($(0,0)!0.1!($(x)!0.5!(\L,0)$)$) [fill=white] {$\theta$};
\draw (s1) -- (x);
\draw (s2) -- (x);
\node [fill=white] at (s1) {};
\node [fill=white] at (s2) {};
\draw [decorate,decoration=brace,xshift=-2mm] (0,-\a) -- (0,\a) node [pos=0.5,left=1mm] {$d$};
\draw [decorate,decoration=brace,xshift=2mm] (\L,\x) -- (\L,0) node [pos=0.5,right=1mm] {$x$};
\node (c) at (s1) [circle through = (s2)] {};
\coordinate (p) at (intersection of c and s2--x);
\coordinate (d) at ($(s2)!0.5!(p)$);
\node at ($(s2)!0.5!(d)$) [pin=-45:{$\Delta$}] {};
\fill [opacity=0.2] (s1) -- (s2) -- (d);
\end{tikzpicture}
}{Geometry for the double slit experiment}

Consider Figure \ref{fig:double-slit}. In particular the gray triangle which highlights the path-length difference, $\Delta$, between the two rays. If $L$ is sufficiently large in comparison to $d$, we can consider this to be right triangle with $d$ as the hypotenuse. The angle opposite to the path-length difference is the same as the angle $\theta$. This means that
$$\Delta = d \sin \theta$$
Based on the discussion in Lecture \ref{ch:waves-interference}, we know we will have constructive interference whenever this distance is an integer number of wavelengths. Thus, we expect to see a bright band on the screen if the angle is given by
\begin{equation} \label{double-slit-interference}
\sin \theta = n \lambda / d
\end{equation}
Of course, this same angle is given by $\tan \theta = x/L$. So we can reverse equation \eqref{double-slit-interference} to determine the wavelength of this light by measuring the distance $x$.

The main obstacle to overcome when observing the interference of light is the small wavelength. The range for the human eye is about 390 to 750 nanometers for blue and red light respectively. The interference pattern depends on this wavelength so it is typically very hard to see unless the geometry is of the same order. Also the wavelength dependence means that the pattern is best seen for monochromatic (single color) light.

% Michelson-Morley experiment

\prep{The double slit experiment requires that light wave as the two slits be \hide{in phase}. This is why firing two lasers at a screen will not produce interference. The way Young accomplished this was by placing a preparatory screen in front of the double slit. In this screen was a single slit essentially acting as a wave source for the double slit.}

Another way to accomplish this is by taking splitting a coherent beam of light. This is usually done with a half-silvered mirror which reflects half the beam and transmits the other half. The arrangement in Figure \ref{fig:michelson-interferometer} is called the Michelson \jargon{interferometer} is able to measure the speed of light with great accuracy. Essentially the interferometer is able to measure the distances between the two mirrors within 0.1 microns (the wavelength of light). Michelson and Morley originally designed this apparatus to detect the ``ether wind'' (a topic to which we will return in Lecture \ref{ch:em-and-relativity}).

\tikzfig{michelson-interferometer}{
\begin{tikzpicture}

\fill (0,-2) circle (0.05); 
\fill (-0.5,2-0.05) rectangle (0.5,2+0.05);
\fill (-2-0.05,-0.5) rectangle (-2+0.05,0.5);
\fill [gray,rotate=45] (-0.05,-0.5) rectangle (0.05,0.5);

\node at (135:0.5) [pin=135:{Half silvered mirror}] {};
\node at (0,-2) [below] {Source};
\node at (0,2) [above] {Mirror};
\node at (-2,0) [above,rotate=90] {Mirror};
%\node at (2,0.5) [above] {\small Lens};

\draw [] (0,-2) -- (-0.05,0.05) -- (-2,0.10) -- (-0.15,0.15) -- (2,0.20) -- (4,0);
\draw [] (0,-2) -- (0.05,-0.05) -- (0.10,2) -- (0.15,-0.15) -- (2,-0.20) -- (4,0);

\begin{scope}[xshift=20mm]
\draw [fill=black!10] ($(-1.90,0)+(-15:2)$) arc (-15:15:2) -- ($(1.90,0)+(165:2)$) arc (165:195:2) -- cycle;
\end{scope}

\draw (4-0.05,-1) rectangle (4+0.05,1);

%\begin{scope}[xshift=52mm,white]
%\fill [black] (-1,-1) rectangle (1,1);
%\fill [] (0,0) circle (0.2);
%\draw [ultra thick] (0,0) circle (0.4);
%\draw [thick] (0,0) circle (0.6);
%\draw [very thin] (0,0) circle (0.8);
%\end{scope}

\end{tikzpicture}
}{Schematic of the Michelson interferometer}

% Single slit diffraction can be understood as the interference of a series of single sources.

\prep{Young's original \hide{double} slit experiment depends upon the \jargon{diffraction} of light.} This is the tendency for waves to bend around obstacles and why you can hear around corners. This is why the light bends and interferes in his double slit experiment rather than simply casting a very sharp shadow of the two slits.

\prep{If we were to remove a slit from Young's arrangement, the remaining slit will cast its shadow on the screen. But since the slit is small, the shadow will be fuzzy due the \hide{diffraction}.} In fact, the intensity of the diffraction pattern is given by\footnote{The function $\sin(x)/x$ is called the \href{http://en.wikipedia.org/wiki/Sinc_function}{sinc function} and happens to be the Bessel function shown in Figure \ref{fig:bessel-function}. The connection here is merely coincidental as far as I know.}
\begin{equation} \label{diffraction-pattern}
%I = \text{sinc}^2 (\pi a \theta / \lambda)
I = \left[ \left( \frac{\lambda}{\pi a \theta} \right) \sin \left( \frac{\pi a \theta}{\lambda} \right) \right]^2
\end{equation}
where $a$ is the width of the slit (see Figure \ref{fig:diffraction-pattern}). This function assumes that the distance to the screen is much larger than the slit width so that the rays of light are effectively parallel from the slit.\footnote{Technically, $L \gg a^2 / \lambda$. This approximation is called \href{http://en.wikipedia.org/wiki/Fraunhofer_diffraction}{Fraunhofer diffraction}. For screens very close \href{http://en.wikipedia.org/wiki/Fresnel_diffraction}{Frensel diffraction} corrects the calculation.}

\tikzfig[]{diffraction-pattern}{
\begin{tikzpicture}
\fill [] (-2,0) circle (0.05) node [left] {$\lambda$}; 
\begin{scope}[very thick]
\draw (0,2) -- (0,0.5) (0,-0.5) -- (0,-2);
\draw (2,2) -- (2,-2);
\end{scope}
\foreach \x/\y in {-20/0,0/5,0/-5}
{
\begin{scope}[xshift=\x mm,yshift=\y mm]
\clip (0,-1) rectangle (2,1);
\foreach \r in {0.3,0.6,...,2.4} {\draw [help lines] (30:\r) arc (30:-30:\r);}
\end{scope}
}
\foreach \y in {1.75,1.25,...,-1.75}
{
\pgfmathparse{100/(1+4*(\y+0.25)^2)} 
\pgfmathtruncatemacro{\s}{\pgfmathresult} 
\shade [bottom color=black,top color=white!\s!black] (2.1,\y+0.25) rectangle (2.9,\y);
\pgfmathparse{100/(1+4*(\y-0.25)^2)} 
\pgfmathtruncatemacro{\s}{\pgfmathresult} 
\shade [bottom color=white!\s!black,top color=black] (2.1,\y) rectangle (2.9,\y-0.25);
}
\begin{scope}[xshift=30mm,rotate=-90]
\draw [domain=-2:2,samples=100] plot (\x,{cos(\x*360)^2/(1 + 4*\x^2)});
\end{scope}
%\node [pin=-90:{\tiny Interference pattern}] at (2.5,-2) {};

\draw [|-|] (-0.2,0.5) -- node [left] {$a$} (-0.2,-0.5);
\fill [opacity=0.2] (0,0) -| (2,1) -- cycle;
\node at (1,0.25) {$\theta$};
\end{tikzpicture}
}{Single slit diffraction pattern (slit width exaggerated for clarity)}

The diffraction given by equation \eqref{diffraction-pattern} drops to zero whenever
\begin{equation} \label{diffraction-zeros}
\theta = n \lambda / a
\end{equation}
except when $n=0$ which is the brightest point of all. So even with a single slit we can see the wave nature of light. However, the side lobes of equation \eqref{diffraction-pattern} are usually very faint, so effectively the image is spread over the range defined by \eqref{diffraction-zeros} with $n=1$.

% Sources can be resolved only if their central diffraction peaks do not overlap.

The previous analysis was all performed assuming the diffraction aperture was a thin slit. Another common type of aperture is a small circular hole. The diffraction pattern in this case is radial, but has the same characteristics as equation \eqref{diffraction-pattern} except the pattern is slightly wider.\footnote{This radial pattern is called the \href{http://en.wikipedia.org/wiki/Airy_disk}{Airy disk}. Calculating the diffraction pattern from any aperture involves Fourier transforms which are closely related to the Fourier analysis we mentioned in Lecture \ref{ch:waves-interference}.} The width of the central diffraction peak is given by
\begin{equation} \label{rayleigh-criterion}
\theta = 1.22 \lambda / a
\end{equation}
where $a$ in this case is the diameter of the circular aperture.

Since the typical aperture in a telescope is circular, we expect the images of stars to exhibit just this kind of diffraction. An important consideration is the resolution of the images from two stars. We can use equation \eqref{rayleigh-criterion} as an objective measure of resolution. We say that we can distinguish two sources if the diffraction peaks do not overlap. This is called the \jargon{Rayleigh criterion} (see Figure \ref{rayleigh-criterion}). In fact, when using the human eye, the pupil is the effective aperture. Using equation \eqref{rayleigh-criterion} and 570 nanometers as the average wavelength of light, we can say that the human eye can resolve images with an angular separation of \sci{1.4}{-5} radians, or about 100 arc-seconds. % 0.0008 degrees.

\tikzfig[side]{rayleigh-criterion}{
\begin{tikzpicture}
\fill (-1.5,-1) rectangle (1.5,1);
\foreach \x in {-2,2}
{
\begin{scope}[xshift=\x mm,white]
\fill (0,0) circle (0.2);
\draw [ultra thick] (0,0) circle (0.4);
\draw [thick] (0,0) circle (0.6);
\draw [very thin] (0,0) circle (0.8);
\end{scope}
}
\end{tikzpicture}
}{Point sources are resolved if the central diffraction peaks do not overlap}

% A diffraction grating (large number of slits) also creates an interference pattern.

\prep{A \jargon{diffraction grating} is effectively a double slit analysis on steroids. A diffraction grating is good at displaying the wave nature of light because it separates the colors through \hide{interference} rather than dispersion.} Consider for a moment the geometry of the triple slit in Figure \ref{fig:triple-slit}.

\tikzfig{triple-slit}{
\def\y{2}
\def\L{6}
\def\x{1.5}
\def\a{0.5}
\begin{tikzpicture}
\draw [thick] (0,\y) -- (0,-\y);
\draw [thick] (\L,\y) -- (\L,-\y);
\coordinate (s1) at (0,\a);
\coordinate (s2) at (0,0);
\coordinate (s3) at (0,-\a);
\coordinate (x) at (\L,\x);
\draw [<->] (0,-0.8*\y) -- (\L,-0.8*\y) node [pos=0.5,fill=white] {$L$};
\draw [dotted] (0,0) -| (x) -- cycle;
%\node at ($(0,0)!0.1!($(x)!0.5!(\L,0)$)$) [fill=white] {$\theta$};
\draw (s1) -- (x);
\draw (s2) -- (x);
\draw (s3) -- (x);
\node [fill=white] at (s1) {};
\node [fill=white] at (s2) {};
\node [fill=white] at (s3) {};
\draw [decorate,decoration=brace,xshift=-2mm] (0,-\a) -- (0,\a) node [pos=0.5,left=1mm] {$2d$};
\draw [decorate,decoration=brace,xshift=2mm] (\L,\x) -- (\L,0) node [pos=0.5,right=1mm] {$x$};
\node (c) at (s1) [circle through = (s3)] {};
\coordinate (p) at (intersection of c and s3--x);
\coordinate (d) at ($(s3)!0.5!(p)$);
%\node at ($(s3)!0.5!(d)$) [pin=-45:{$\Delta$}] {};
\fill [opacity=0.2] (s1) -- (s3) -- (d);
\end{tikzpicture}
}{Geometry for a triple slit}

The path-length difference emphasized by the gray triangle still governs the interference pattern. The lower slit introduces a third ray with an extra $\Delta$ of path-length difference. What this means is that when the double-slit angle produced constructive interference, the triple-slit also does. However, when the top two slits are in destructive interference, the third will propagate through. The diffraction pattern still peaks at the constructive interference points given by equation \eqref{double-slit-interference}, but the peaks are much shaper (narrower and taller).

A typical diffraction grating will have much more than three slits. Typically we are told the number of slits per centimeter or some similar metric. The angle of diffraction is proportional to this number.

A diffraction grating will disperse light into a rainbow because equation \eqref{double-slit-interference} is wavelength dependent. A standard DVD produces this effect because of the closely spaced tracks on the disk. The regular spacing in crystals will also act like a diffraction grating for certain wavelengths of light. This kind of analysis is how the double helix structure of DNA was first discovered.

% One simple application of physical optics involves thin films: e.g., soap bubbles.

\prep{Usually the \hide{iridescence} seen in nature is not from a diffraction grating, however. It is much more common for this effect to be produced by \jargon{thin-film interference}.} Simple examples include soap bubbles and the colorful sheen of oil on water.

Physically this occurs because both the inner and outer boundary act as reflection points. The light from the front of the layer will constructively interfere with the light from the back of the layer if the distances are just right (see Figure \ref{fig:thin-film}). 

\tikzfig[side]{thin-film}{
\begin{tikzpicture}
\fill [black!10] (-2,0) rectangle (3,1);
\fill [] (-0.5,3) circle (0.05) node [above] {$\lambda_1$};
\draw [->] (-0.5,3) -- (-0.1,1) -- (0,0) -- (0.1,1) -- (0.5,3);
\draw [->] (-0.1,1) -- (0.3,3);
\draw [|-|] (2.5,0) -- node [right] {$t$} (2.5,1);
\node at (1.5,1.5) {$n_1$};
\node at (1.5,0.5) {$n_2$};
\end{tikzpicture}
}{Thin film interference}

If the thickness of the film is $t$, the path-length difference is $2t$, so you might think we require $2t = m\lambda$ (we use $m$ to avoid confusion with the index of refraction). However, the reflection from the front is a hard reflection because the refractive index of the film is larger than air. The reflection off the back is a soft reflection for similar reasons, so the interference acts something like the open tube from Lecture \ref{ch:waves-interference}. This means we require
$$2t = (m+\half)\lambda_2$$
where $\lambda_2$ is the wavelength of the light in the medium. But we know that the wavelength of the light changes with any change in the index of refraction because its speed will change. We combine equations \eqref{index-speed} and \eqref{vfl} with the previous condition to yield the thin-film interference formula:
\begin{equation} \label{thin-film}
2t = (m + \half) \left( \frac{n_1}{n_2} \right) \lambda_1
\end{equation}
where we give the wavelength the subscript 1 to emphasize that this is the source wavelength.

You might wonder why the film must be thin. The reason is that the \prep{two rays must be of comparable \hide{amplitude} in order to interfere.} Typically as light moves through a transparent medium, it loses intensity. This is called \jargon{attenuation} and is a kind of optical friction or resistance. It is possible to incorporate this attenuation by allowing the index of refraction to be a complex number, though we will not do so here. The attenuation of light causes the intensity to fall exponentially. 

% The difference between incandescent and laser light is the coherence of the waves.

There is another characteristic of light that is a consequence of its wave nature: \jargon{coherence}. This is the difference between incandescent light and laser light. \prep{In laser light, each pulse of light is aligned by both phase and polarization.\footnote{This occurs because a type of standing wave is built in the lasing material which excites more coherent light via a quantum mechanical process. Although the production is based on quantum mechanics, the coherence of the light is understandable with classical ideas.} This means that effectively all the light rays constructively interfere all the time. With an incandescent light, the alignment of phase and polarization is \hide{random}: sometimes its constructive, sometimes its destructive.}

Since the intensity of the light is proportional to the square of the amplitude, when the intensity of the incandescent bulb increases two-fold, the intensity of laser light increases four-fold. So, the high intensity of laser light is due to the coherence of its light---which is a wave phenomena.

% On polarization ....

Another piece of evidence for the wave nature of light is its polarization. The polarization of light was first discovered through \href{http://en.wikipedia.org/wiki/Birefringence}{\jargon{birefringence}}: a material in which the index of refraction depends upon the polarization of the light. A typical image seen through this material will double as the light is polarized relative to its crystal structure.

The best way to explain why the polarization of light cannot be explained by particles is by considering two crossed polarizing filters. When we pass light through a filter, the component of the light wave aligned with the polarizer axis passes through. If we place a second polarizer at 90\dg to the original, it will block the light because there is no component left to pass through.

If, however, we insert a third polarizer in between them aligned at an angle, light will begin to pass through again. When two polarizers are at an angle $\theta$, the intensity of light that passes through is given by \jargon{Malus' law}:
\begin{equation} \label{malus-law}
I = I_0 \sin^2 \theta
\end{equation}
This is because the intensity is proportional to the square of the amplitude and the polarizer allows a component $A = A_0 \sin \theta$ through.

If the middle polarizer is set at 45\dg then it will let half of the intensity of light through. The final polarizer is also at 45\dg to the middle, so one-quarter of the intensity of light is allowed through even though the two outer polarizers are crossed.

% But what is waving? The ether\ldots

So, \prep{the evidence is pretty clear that light is a wave phenomena. Of course every wave does so in a medium and it is natural to ask what is the medium for light waves? In the 19th century this medium was given the name the \jargon{ether} and one of the main goals was to determine its \hide{mechanical} properties.}

But what is it? Like an elastic solid transmitting sound waves? This substance must be present everywhere light is---including the depths of outer space. Apparently it is everywhere, yet we do not experience any ``ether drag'' like we do with air. If we model this as an elastic solid, its wave speed is given by equation \eqref{wave-speed-solid}. But the speed of light is enormous. This implies a very rigid solid which is less dense than air---yet its presence is undetectable mechanically. The search for an ``ether wind'' was a hot topic around the turn of the 20th century. 

\prep{As the evidence piled up, it began to be more and more difficult to imagine any mechanical model that could act as a \hide{medium} for light.} During this time, Einstein's special theory of relativity altered our views of space and time effectively declaring the ether concept dead. Now, with the advent of quantum field theory, we no longer even think of light as waves---but that's the subject for next week.

% Next week

Next week we will continue discussing mechanical models for the ether. We will find that the more we refine this model, the more problems we uncover. This is one of three major breeches in classical mechanics. In this case, the problem is finally resolved in the theory of relativity. On the other hand, we have quantum mechanics as the resolution of the other two problems (kinetic theory and atomic theory). In this way we will finish the term recognizing the limits of classical mechanics.
========
22:classical-limits
--------
Limits of Classical Mechanics
--------
Review Lectures \ref{ch:kinetic-theory} and \ref{ch:physical-optics}. Sneak a peak at sections 28.6--28.7, 29.1--29.3 and 30.3
--------
% Light carries momentum (Maxwell) -- perhaps ether is a fluid? Atomic vorticies

In the last lecture we left open the question on the ultimate nature of light. The evidence for some sort of wave picture is clear. However, the mechanical nature of the medium doing the waving was less clear. \prep{By the middle of the 19th century, some connection between electricity, magnetism, and light was understood. As \hide{electromagnetic} theory matured (culminating in Maxwell's equations), the problem became worse.}

One clear example is that light (as an electromagnetic wave) should carry momentum. The problem is that mechanical waves do not carry momentum. The transfer of momentum implies a transfer of mass: movement of the medium itself.

Well, perhaps the ether is a fluid. A fluid can easily carry momentum and support wave motion. \prep{In fact, a thought at the time held that elementary particles might be modeled as a vortexes in the fluid. Like a \hide{smoke ring}, a vortex can maintain its structure over an extended period of time.}

Unfortunately, a fluid cannot support a polarized wave. Because a fluid only has pressure stress (no shear or normal stress), the compression wave has only one degree of freedom. But electromagnetic theory and experimental results require a polarized wave theory of light.

% No ether wind? Epicycles, again

Whether solid or fluid, we expect a basic result called the ``ether wind''. When you are riding a car and roll down the window, can you tell you are moving? Of course you can: the wind gives it away. The air is not moving: the wind is caused by your motion through the medium. In the same way, we ought to be able to detect our motion through the ether.

Of course, our motion needs to be comparable to the speed of light---which is fast. One trick was to measure this ether wind by using the motion of the earth. Around the turn of the 20th century, \prep{Michelson and Morley performed a number of experiments to detect the motion of the earth through the light ether. The now famous ``\hide{null result}'' caused quite a bit of controversy at the time.} Theory after theory was proposed\footnote{For example, maybe the earth moves in some sort of ether bubble.} but the whole thing reminds one of the epicycles of Ptolemaic astronomy. Tweak after tweak attempting to fit a dying theory to unyielding facts.

% Special relativity: the ether is dead. $E = mc^2$ and $v \ne v_1 + v_2$.

The answer was summarized in 1905 by Einstein in the special theory of relativity. \prep{By the statement that $E = mc^2$, we can see that every wave moves \hide{mass} through the energy it moves.} For everything except a light wave, the amount of mass is completely negligible. But for light, the momentum transfered follows from this formula.

However any mechanical model of light based on Newton's laws was in contradiction with the principle of relativity (see page \pageref{idx:principle of relativity}). Because this medium is universal and everywhere, it acts as an absolute reference frame. But \prep{Einstein showed that it is possible to have our cake (electromagnetic theory) and eat it too (principle of relativity) and declared the \hide{ether} dead.}

The trade-off is that we must reassess our assumptions about space and time. Because of this \prep{the speed of light acts as a universal \hide{speed limit} which implies that speed and velocity works in a way that is non-Newtonian.} This explains the null result of Michelson and Morley, but at the expense of bizarre consequences like length contraction and time dilation. We will return to these ideas in Lecture \ref{ch:em-and-relativity}.

% Photoelectric effect: $E \propto nf$ rather than $E \propto A^2$

Relativistic mechanics wasn't the only correction required to classical mechanics. In many ways quantum mechanics was an even more radical correction than relativity. Interestingly, Einstein played a large role in development of quantum mechanics too.

\prep{Looking back now, the first hint how wrong we were to assume the subatomic world operated under \hide{classical} principles of mechanics was the \jargon{ultraviolet catastrophe}.} This comes from the analysis of the spectrum of radiation from a heated object. The net power radiated is given by equation \eqref{heat-radiation}, but what we seek is the distribution of this energy across the electromagnetic spectrum. Classical theory predicts an ever-increasing amount of energy in the lowest wavelengths, which is nonsense. 

In 1893, a result known as \href{http://en.wikipedia.org/wiki/Wien's_displacement_law}{\jargon{Wien's Law}} was empirically derived:
\begin{equation} \label{wiens-law}
\lambda_\text{max} = \frac{\sci{2.898}{-3}}{T}
\end{equation}
In this formula, the peak wavelength in the spectrum is inversely proportional to the absolute temperature. Ultimately, quantum theory predicts a spectrum in line with reality (see Figure \ref{fig:uv-cat}) and justifies Wien's law.

\pics[side]{uv-cat}{
%See http://hyperphysics.phy-astr.gsu.edu/hbase/mod6.html
\begin{tikzpicture}
\draw [->,dotted] (0,0) -- (4.2,0) node [right] {$\lambda$};
\draw [->,dotted] (0,0) -- (0,4.2) node [above] {$dE$};
%\draw [decorate,decoration=brace] (0.8,-0.1) -- (0.4,-0.1) node [pos=0.5,below=1mm] {Visible};
%\node [draw=black!20] at (2,5) {$T$ = 5000 K};
\clip (0,-0.5) rectangle (4,4);
\draw plot [smooth] coordinates { 
% Rayleigh-Jeans = \frac{8\pi kT}{\lambda^5}
% Rayleigh-Jeans = \frac{8\pi f^2}{c^3} kT
(1.20,4.1815)
(1.30,3.0359)
(1.40,2.2571)
(1.50,1.7127)
(1.60,1.3231)
(1.70,1.0382)
(1.80,0.8260)
(1.90,0.6653)
(2.00,0.5419)
(2.10,0.4458)
(2.20,0.3701)
(2.30,0.3098)
(2.40,0.2613)
(2.50,0.2220)
(2.60,0.1897)
(2.70,0.1632)
(2.80,0.1411)
(2.90,0.1226)
(3.00,0.1070)
(3.10,0.0939)
(3.20,0.0827)
(3.30,0.0731)
(3.40,0.0649)
(3.50,0.0578)
};
\node at (1.30,3.0359) [pin=45:{Classical}] {};
\node at (1.30,0.8226) [pin={[white,pin edge={white,line width=1mm}]45:{Quantum}}] {};
\node at (1.30,0.8226) [pin=45:{Quantum}] {};
\begin{scope}
\clip [draw] plot [smooth] coordinates { 
% Planck = \frac{8\pi hc}{\lambda^5} \frac{1}{\exp(hc/\lambda kT) - 1}
% Planck = \frac{8\pi f^2}\frac{hf}{\exp(hf/kT) - 1}
% By \exp(1 + \delta) \approx 1 + \delta, Planck => RJ when kT >> hf
(0.10,0.0000)
(0.20,0.0430)
(0.30,0.6907)
(0.40,1.8118)
(0.50,2.5151)
(0.60,2.6556)
(0.70,2.4607)
(0.80,2.1356)
(0.90,1.7933)
(1.00,1.4824)
(1.10,1.2179)
(1.20,0.9998)
(1.30,0.8226)
(1.40,0.6796)
(1.50,0.5643)
(1.60,0.4711)
(1.70,0.3956)
(1.80,0.3340)
(1.90,0.2836)
(2.00,0.2421)
(2.10,0.2077)
(2.20,0.1791)
(2.30,0.1552)
(2.40,0.1351)
(2.50,0.1181)
(2.60,0.1036)
(2.70,0.0913)
(2.80,0.0807)
(2.90,0.0716)
(3.00,0.0637)
(3.10,0.0569)
(3.20,0.0510)
(3.30,0.0458)
(3.40,0.0412)
(3.50,0.0372)
};
\fill [blue!20] (0.4,0) rectangle +(0.1,4);
\fill [green!20] (0.5,0) rectangle +(0.1,4);
\fill [yellow!20] (0.6,0) rectangle +(0.1,4);
\fill [red!20] (0.7,0) rectangle +(0.1,4);
\end{scope}
\draw [|-|] (0.8,0) -- (0.4,0) node [pos=0.5,below=1mm] {Visible};
\end{tikzpicture}
}{Ultraviolet catastrophe: Expected spectrum of energy by wavelength from a hot object. Both curves assume a temperature of 5000 kelvin---the approximate temperature of the sun.}

In both classical and quantum theory, the number of ways a medium can vibrate (i.e., its modes, see page \pageref{idx:mode}) is proportional to the square of the frequency.\footnote{This assumes the medium is three dimensional. For a string (one-dimensional), the number of modes is constant across frequency. For a sheet, the number of modes increases linearly with frequency.} If the medium is in thermal equilibrium at a particular temperature, the equipartition principle from kinetic theory (page \pageref{idx:equipartition principle}) implies that each mode will hold $kT$ units of energy. 

\prep{If the ether is a classical wave medium, this implies that the amount of radiant energy from a \hide{hot} object should be dominated by the high frequency, low wavelength (ultraviolet) range of the electromagnetic spectrum}---in other words, hot objects should be blue rather than red. Classic theory is not even close. Relativity doesn't save us here because the energies involved are no where near relativistic.

In 1900, Max Planck was able to mathematically reverse engineer the actual radiation spectrum and came to the conclusion that the problem was the equipartition principle. He found that with a single simple assumption, he could derive the correct spectrum:
\begin{equation} \label{photon-energy}
\Delta E = hf
\end{equation}
In other words, the modes are only allowed to exchange energy in increments that are proportional to the frequency of that mode. This has the effect of suppressing the higher frequency modes because the probability of a large energy exchange is exponentially small in thermal equilibrium.

Another phenomena points to an unusual connection between energy and frequency\footnote{Remember: classically, energy in a wave is related to its amplitude not its frequency.} of light called the \jargon{photoelectric effect} first discovered in 1839. If one shines intense light on metal it will ionize and the electrons thus stripped off can be captured in an electric current and measured. The odd thing is that the speed of the escaping electrons depends on the frequency of the light. In fact, for very low frequency light no electrons are released no matter how intense the light.

But why? A few years later, Einstein realized that both Planck's assumption and the photoelectric effect can be explained through a particle theory of light. Each particle, called a \jargon{photon}, has energy related to its frequency according to \eqref{photon-energy}. It is actually this work rather than relativity for which Einstein received his \href{http://nobelprize.org/nobel_prizes/physics/laureates/1921/}{Nobel Prize in 1921}.

\prep{Einstein realized that the explanation of the \hide{photoelectric effect} is simple if light comes in streams of photons.} Each photon only carries $hf$ worth of energy, so if the frequency is not high enough, the light particle does not have enough energy to lift the electrons out of the potential well that binds them in the atom. Increasing the intensity of light only increases the number of photons---none of which are powerful enough to move the electrons.

The most important thing about the photoelectric effect is that it cannot be explained with waves. This frequency dependence of energy is without parallel in the classical theory. The fact that energy transfer is quantized by \eqref{photon-energy} is unprecedented.

% Problems in kinetic theory: uv catastrophe, specific heats of solids, superstuff (superconductivity, superfluids) \ldots bosons versus fermions

And there were other problems---particularly at low temperatures. The specific heat of solids predicted by classical theory \href{http://en.wikipedia.org/wiki/Dulong-Petit_law}{was wrong} (Einstein also proposed the first approximation of a solution using quantum ideas). Superconductivity was discovered in which the electrical resistance of a metal disappears. Liquid helium below about 2.17 degrees kelvin completely loses all viscosity (now known as a superfluid).

% Problems in atomic theory: spectroscopy, orbital radiation

Beside issues with classical kinetic theory, deep inconsistencies were discovered in the structure of the atom. Classical electromagnetic theory implies that an orbiting electron will continually radiate energy. Based on the size of the atom, the theory predicts that all the orbital energy should be radiated away in $10^{-11}$ seconds or so. Atoms are a bit longer lived than that: another blatant contradiction between theory and reality.

Spectroscopy is the study of the spectrum of radiation from materials. It was discovered that the elements only emit radiation along certain frequencies: creating a pattern of lines rather than a smooth spectrum. Both this and the non-radiating orbital electron seem to imply that energy transfer is limited in the microscopic realm. The \jargon{Bohr model} of the atom (see Lecture \ref{ch:solid-state}) was successful in collecting these facts, but left unexplained the fundamental reason of why energy is quantized. 

% Quantum mechanics = matter waves; $n \propto A^2$

Out of this cacophony of confusion quantum mechanics was born. Nearly 30 years of struggle and debate finally gelled into a single explanation---which is the subject of Lecture \ref{ch:quantum-mechanics}. \prep{Einstein's photon idea combining particle and wave (in some obscure way) led Louis de Broglie to postulate that perhaps elementary particles (in particular: electrons) have both particle and wave characteristics too. These ``\hide{matter waves}'' are critical in understanding the structure of the atom and form the foundation of chemistry.}

% QM + SR = QFT, the most natural combination. QED the ``crown jewel''. Also explains the particle zoo

So around 1925 order was brought back to the land of physics. Except one thing. Quantum mechanics is not relativistic. And the most straightforward way to combine the two was fraught with problems (like negative kinetic energy, infinite numbers of particles, etc.). It took another quarter of a century to realize that the conflict between quantum mechanics and special relativity was only on the surface. The development of quantum electrodynamics (QED) has been described as the ``crown jewel of physics'' by Feynman due to its \href{http://en.wikipedia.org/wiki/Precision_tests_of_QED}{astonishing accuracy} (better than ten parts per billion so far).

The mathematical framework for QED is called quantum field theory (see Lecture \ref{ch:quantum-mechanics}). One important consequence of quantum field theory is the division of the world of elementary particles into \jargon{fermions} and \jargon{bosons}. The electron is an example of a fermion which ultimately explains the periodic table. The photon is an example of a boson which ultimately explains Planck's solution to the ultraviolet catastrophe. Fermions are the building blocks of matter and bosons are the carriers of force.

Quantum field theory has been utilized to explain the two nuclear forces as well. Though more complicated, these theories are also accurate to within current experimental precision. So the fundamental framework of subatomic physics is able to explain every experiment to date. This is called the \jargon{Standard Model} of physics (see Lecture \ref{ch:high-energy}).

But the holy grail, the ``theory of everything'', still eludes us. Oddly enough, it is gravity---the first force of them all---that stands alone. It took Einstein a dozen years to discover a relativistic theory of gravity (general relativity). No one has discovered a quantum theory of gravity. Stay tuned.
========
23:electric-field
--------
The Electric Field and Potential
--------
Read sections 18.1--18.9 and 19.1--19.5
--------
% The electric force is one of the three basic long-range forces in nature.
% The electric force obeys an inverse square law (Coulomb's law).

Electricity, magnetism, and gravity are all long-range forces. Rather than acting via the direct contact of objects (like elasticity or friction), these forces act ``at a distance''. Though gravity was the first to be quantified in Newton's inverse square law \eqref{n4l}, magnetism was the first to be studied. Perhaps due to its portability: one can play with magnets much easier than planets.

In 1783, it was discovered that the electric force also obeys the inverse square law\footnote{All three long-range forces roughly obey an inverse square law. Interestingly, only the electric force obeys the inverse square law exactly.}
\begin{equation} \label{coulombs-law}
F = \frac{kqQ}{r^2}
\end{equation}
which is called \jargon{Coulomb's law}. Each $q$ represents the electric charge on the object and $k$ has a value of $\sci{8.9876}{9}$ in SI units.\footnote{We will see why in Lecture \ref{ch:em-and-relativity}, but this happens to be the speed of light squared times $10^{-7}$.}

Unlike gravity (and like magnetism), the electric force is both attractive and repulsive. This implies that there are two different kinds of electric charge. The convention to call them ``positive'' and ``negative'' goes back to Benjamin Franklin. One advantage to this convention is that equation \eqref{coulombs-law} now tells us when the electric force is attractive (charges of the same charge) or repulsive (charges of opposite charge).

% Electric charge (electrons) can be manipulated through conduction or induction.

It is not hyperbole to say that our modern standard of living depends on the correct understanding and harnessing of electric power. In general, materials fall into two categories: \jargon{conductors} which easily allow the flow of electric charge and \jargon{insulators} which essentially block the flow.\footnote{These terms are used in the context of anything that flows: for example, heat.} 

Take an object with some excess charge on it. If we touch this object with a conductor, some of the excess charge will flow into and through the conductor because all of the individual charges are repelled from one another. In general, any excess charge will distribute itself through a conductor in order to maximize the distance between the charges. This is also why any excess charge will reside on the surface of a conductor.

There is another, trickier, way to transport electric charge. Take the same object as before with the same excess charge on it. Move the conductor close to the object without touching it (or place a thin insulator between them). The charge in the object will repel similar charge in the conductor and attract the opposite charge. In this way, a separation of charge is induced in the conductor. If we drain the repelled charge (by connecting it to the ground---literally), we are left with a net charge in the conductor of the opposite polarity.

% Nearly every non-nuclear force is ultimately electric\ldots
% The electric dipole shows how a neutral object can still be electrically active.

These tricks were essential to the initial study of electricity. They also reveal an important fact of nature: matter is electrically active. Of the three long-range forces, electricity is the most powerful. Ironically, this strength acts to conceal the electrical nature of matter. Negative electrons\footnote{There are about 6.25 trillion electrons in a coulomb, the SI unit of electric charge.} are strongly attracted to the positive nucleus and lock into an overall neutral atom. Except for unusual (and dramatic) circumstances, electricity is only manifest on the microscopic scale.

But, indirectly, electricity is everywhere because it is the source of all elastic, contact, and chemical forces. In fact, every macroscopic interaction except gravity is ultimately electric. In most cases, we need quantum mechanics to fully understand how this is true (in particular, the solidity of matter and the covalent bond). The key insight is to recognize that any asymmetry in charge distribution can induce a similar asymmetry in adjacent atoms. This charge separation is idealized in the \jargon{dipole moment} which is the product of magnitude of the charges and the separation between them (see Figure \ref{fig:dipole-moment}).

\pics[side]{dipole-moment}{
\begin{tikzpicture}
\node (+) [draw,circle] at (1,-1) {$+q$};
\node (-) [draw,circle] at (-1,1) {$-q$};
\draw [->] (+) -- (-) node [pos=0.5,fill=white] {$p = qd$};
\end{tikzpicture}
}{Dipole moment calculation}

% The net effect of electric charges is captured in a new concept called the electric field.

In the mid-19th century, Micheal Faraday introduced the idea of the electric field into the physics community. He found it necessary to conceptualize what was happening in certain electromagnetic experiments (we will see these in Lecture \ref{ch:induction-and-ac}). A couple of decades later, Maxwell summarized the dynamics of the electromagnetic field in his four famous laws. Forty years later, Einstein realized that these laws are not compatible with Newton's laws of motion and developed the special theory of relativity. He \href{http://www.amazon.com/Evolution-Physics-Albert-Einstein/dp/0671201565}{later} emphasized that the field concept was the key to uncovering the incorrect assumptions underneath Newton's laws of motion.

The field also occupies a middle ground for those uncomfortable with ``action-at-a-distance'' by offering an intermediate entity to carry the influence of the force. We take Coulomb's law \eqref{coulombs-law} and divide it into two pieces
$$F = (q)\left[\frac{kQ}{r^2}\right]$$
which isolates (in square brackets) the part that is not associated with the charge experiencing the force. We call this the \jargon{electric field} generated by the charge $Q$. In short, the electric field from a point charge is
\begin{equation} \label{field-point-charge}
E = \frac{kQ}{r^2}
\end{equation}
and we can rewrite equation \eqref{coulombs-law} as $F = qE$ which makes clear why the SI unit for the electric field is newtons per coulomb. The field from multiple charges is simply the sum of the fields from each. Though recognize that the field is a vector (because force is) so some vector addition may be required.

\pics[side]{point-charge-field}{
\begin{tikzpicture}
\node (+) [draw,circle] at (0,0) {$+q$};
\foreach \q in {0,30,...,330} \draw [->] (+) -- (\q:2);
\end{tikzpicture}
}{The electric field around a point charge represented by lines of flux}

We can draw the electric field around a charge as in Figure \ref{fig:point-charge-field}. Each line represents electric \jargon{flux} which points in the direction of the force and the field strength is represented by the density of flux lines in the diagram. Lines of flux always point from positive charges and end with negative charges (or drift off to infinity).

% Both conductors and capacitors offer simple situations to picture the electric field.
% The capacitor is an electrical component that traps charge and holds electric energy.

The superposition of multiple charges can easily create quite complicated field line patterns. The simplest is produced by an infinite sheet of charge. Assuming the charge density is constant (which it should be if the charges are at rest), then by symmetry we can see that the field lines will simply be straight lines perpendicular to the sheet. Since the field lines don't diverge, this represents a constant electric field. 

If we place a dipole in the presence of a constant electric field, the positive charge will be pulled along the field and the negative charge will be pulled against the field. In Lecture \ref{ch:torque} we called this a force couple and the effect is to produce a net torque on the dipole. The total torque acting on the dipole is given by
\begin{equation} \label{dipole-torque}
\tau = pE \sin \theta
\end{equation}
where $\theta$ is the angle between the dipole moment and the electric field. So the dipole will twist until it lines up with the field. %In addition, the potential energy of a dipole in an electric field is given by
%\begin{equation} \label{dipole-energy}
%PE = -pE \cos \theta
%\end{equation}
%which also shows that the potential energy is minimized when the dipole is oriented with the field.

Suppose we place a second sheet of opposite charge parallel to the first. This creates a \jargon{capacitor} (see Figure \ref{fig:capacitor-field}). A capacitor is said to store charge since the charges on the two plates are held in place by their mutual attraction to one another. For a perfect (infinitely long) capacitor, there is no electric field on the outside. True capacitors always have \jargon{edge effects}, so not all the electric field is contained inside the system. Also, the two plates of a capacitor are typically separated by an insulator which allows a small amount of charge to flow and will eventually neutralize the charge separation. This is called \jargon{leakage} in the capacitor.

\pics[side]{capacitor-field}{
\begin{tikzpicture}
\draw (-2,-1) -- (-2,1);
\draw (2,-1) -- (2,1);
\foreach \y in {-0.8,-0.4,0,0.4,0.8}
{
  \node at (-2,\y) [left] {\tiny $+$};
  \node at (2,\y) [right] {\tiny $-$};
  \draw [->] (-1.8,\y) -- (1.8,\y);
}
\node [fill=white] at (0,0) {$E$};
\end{tikzpicture}
}{The electric field inside an ideal capacitor is constant}

% Electric ``flux'' is conserved because of Coulomb's inverse square law.

From Lecture \ref{ch:waves-radiation} we know that the power intensity \eqref{point-intensity} from a point source falls off according to an inverse square law. The total energy is conserved but as the radiation propagates through space it is spread across a larger and larger surface area according to $4\pi r^2$. The mathematics is similar for the electric field from a point charge. This means that for the electric field, the total flux is conserved. This is summarized in \jargon{Gauss' law}:
\begin{equation} \label{gauss-law}
\sum_\text{surf} \Phi_\text{ele} = Q_\text{tot} / \epsilon_0
\end{equation}
where $\Phi_\text{ele}$ is the total electric flux that passes through the surface of interest and $Q_\text{tot}$ is the net charge inside the surface. The symbol $\epsilon_0$ is called the \jargon{electric constant}\footnote{I learned this under the name ``permittivity of free space'', but the ``electric constant'' is much easier to remember!} and is equal to $1/4\pi k$ which is $\sci{8.854}{-12}$ in SI units. One way to interpret this equation is that every line of flux starts with a charge---no lines of flux start (or end) in thin air.

We need to be careful to account for only the component of the field line that passes perpendicularly through the surface, so the formula for the flux is
\begin{equation} \label{dfn-flux}
\Phi_\text{ele} = ( E \cos \theta )( A )
\end{equation}
where $\theta$ is the angle between the field vector and the normal vector to the surface area $A$.

\pics[]{dipole-field}{
\begin{tikzpicture}
\clip (-5,-2.3) rectangle (5,2.3);
\node at (0,0) {\includegraphics[scale=0.2]{images/VFPt_dipole.png}};
%\draw [fill=black,opacity=0.2] (1.2,1.2) circle (0.8);
\draw [dashed] (0,0) circle (2);
%\node at (225:2) [fill=white] {Gaussian surface};
\node at (-30:2) [pin={[fill=white]-45:{Gaussian surface}}] {};
\end{tikzpicture}
}{Applications of Gauss' Law to the electric field around a dipole (image credit \href{http://upload.wikimedia.org/wikipedia/commons/thumb/d/df/VFPt_dipole_electric.svg/1000px-VFPt_dipole_electric.svg.png}{here})}

As an example of Gauss' law in action, consider the dashed circle in Figure \ref{fig:dipole-field}. Notice how each field line that goes out is compensated by a line that goes in. The net flow of flux is zero which corresponds to the total enclosed charge being equal to zero. 

\pics[]{gauss-law-capacitor}{
\begin{tikzpicture}[scale=1]
\draw (0,-1) -- (0,1);
\foreach \y in {-0.8,-0.4,0,0.4,0.8}
{
  \node at (0,\y) [left] {\tiny $+$};
  \draw [->] (0.2,\y) -- (1.8,\y);
}
\draw [dashed] (-0.6,-0.6) rectangle (0.6,0.6);
\draw [decorate,decoration=brace] (-0.8,-0.6) -- (-0.8,0.6) node [pos=0.5,left=1mm] {$A$};
\draw [decorate,decoration=brace] (2,0.6) -- (2,-0.6) node [pos=0.5,right=1mm] {$\Phi_\text{ele} = EA$};
\node at (-0.2,-0.2) [pin=225:{$Q_\text{tot} = \sigma A$}] {};
\end{tikzpicture}
}{Calculating the electric field in a capacitor with Gauss' law}

A more substantial application of Gauss' law is to calculate the magnitude of the field in an ideal capacitor. According to Figure \ref{fig:gauss-law-capacitor}, the total charge\footnote{Remember, all the charge is collected on the surface of the conducting plate.} enclosed in a rectangular box parallel to the positive plate is $\sigma A$, where $\sigma$ represents the charge density (i.e., $\sigma = Q/A$). The only flux contribution is from the face that is parallel to the surface, so the total flux coming out of the box is $EA$. Using Gauss' law \eqref{gauss-law} we can solve for the electric field as
\begin{equation} \label{capacitor-field}
E = \sigma / \epsilon_0
\end{equation}

% The electric potential is to the potential energy as the field is to the electric force.

Mathematically, we say that Gauss' law tells about the \jargon{divergence} of the field. Field lines are only created at positive charges (known as ``sources'') and they are consumed at negative charges (known as ``sinks''). The field is also characterized by its \jargon{curl} which tells how much the field twists and turns as we follow the flux (think about a whirlpool in water). The way we evaluate this curl is by following a closed path and calculating the component of the field parallel to the path. The total accumulation of field along this path is the amount of curl in the field. The electric field has no curl because it comes from a central force. In symbols we have:
\begin{equation} \label{electric-curl}
\sum_\text{loop} E_t \Delta s = 0
\end{equation}
where $E_t$ is the component of the field parallel to the little bit of loop $\Delta s$ we are at in the sum.

This should remind you of the discussion of conservative and non-conservative forces in Lecture \ref{ch:energy} (see page \pageref{idx:non-conservative force}). The electric force is conservative and a potential energy function exists. So far, we have drawn an analogy between intensity and flux. There is also a correspondence to this potential energy: the \jargon{field potential}. Both stem from the connection between field and force in the equation $F = qE$. The field potential is defined\footnote{Unfortunately, the negative sign here makes the signs in some calculations confusing---in particular the next equation \eqref{pot-ene-ele}. This sign convention propagates through all of electromagnetism, so beware of signs!} as
\begin{equation} \label{dfn-potential}
\Delta V = -E_t \Delta s
\end{equation}
In other words, the electric potential $V$ increases as we move against the flux lines in the field. This is similar to pushing up a ball against the force of gravity. This formula also implies that the potential does not change as we move directly across the lines of force. The formula for the electric potential energy is simply\footnote{Compare this with the gravitational potential energy \eqref{pot-ene-wgt}: $mgh$. Apparently the gravitational field is simply $-g$!}
\begin{equation} \label{pot-ene-ele}
PE_\text{ele} = -qV
\end{equation}

The SI unit for electric potential is the volt. A common unit of energy at the microscopic level is the ``electron-volt'' which is the charge of the electron ($\sci{1.602}{-19}$ coulombs) times a volt. This is also why the electric potential is also called \jargon{voltage}.

% The electric field is always perpendicular to the contours of the electric potential.

An \jargon{equipotential} surface is the collection of all the points in the electric field with the same value of potential or voltage. The previous paragraph implies that at each point the equipotential is perpendicular to the field lines. These equipotential surfaces are similar to the contour lines on a topographical map and the way wave-fronts and rays are related (see Lecture \ref{ch:geometric-optics}).

When we place a conductor in the middle of an electric field, the surface of the conductor will form an equipotential. The reason is that any voltage difference corresponds to a net electric force along the surface. But the charge in the conductor will flow until this pressure is equalized. This also implies that the field lines that touch a conductor will be perpendicular to the surface. The conductor pulls the field lines toward itself by redistributing its internal charge (see Figure \ref{fig:VFPt-sphere}) until they are perpendicular.

\pics[side]{VFPt-sphere}{
\begin{tikzpicture}
\node at (0,0) {\includegraphics[scale=0.15]{images/VFPt_sphere.png}};
\end{tikzpicture}
}{Adding a conducting sphere to a constant electric field will cause the field lines to bend into the conductor (image credit \href{http://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/VFPt_superconductor_ball_E-field.svg/1000px-VFPt_superconductor_ball_E-field.svg.png}{here})}

The formula for the electric potential from a single point charge is
\begin{equation} \label{point-potential}
V = \frac{kQ}{r}
\end{equation}
From this formula, you can see that the equipotential surfaces around the charge are spherical shells of increasing radius.

The advantage of using the field potential rather than the field directly is that it is not a vector. So the total potential is the simple sum of the potentials from each charge. For example, the potential from a dipole is
\begin{equation} \label{dipole-potential-near}
V = \frac{kq}{r_+} - \frac{kq}{r_-}
\end{equation}
where $r_+$ and $r_-$ are the distances to the positive and negative charges respectively (see Figure \ref{fig:dipole-potential-near}). 

\pics[side]{dipole-potential-near}{
\begin{tikzpicture}
\coordinate (o) at (0,0);
\coordinate (+) at (1,0);
\coordinate (-) at (-1,0);
\coordinate (x) at (60:3);

\draw [dotted] (-) -- (x) node [pos=0.5,above left] {$r_-$};
\draw [dotted] (+) -- (x) node [pos=0.5,below right] {$r_+$};
\draw (o) -- (x) node [pos=0.5,fill=white] {$r$};
\draw (0:0.3) arc (0:60:0.3);
\node at (30:0.6) {$\theta$};
\node at (+) [right] {$+q$};
\node at (-) [left] {$-q$};

\draw [decorate,decoration=brace] ($(+)+(0,-0.2)$) -- ($(-)+(0,-0.2)$) node [pos=0.5,below=1mm] {$d$};

\fill (+) circle (0.05);
\fill (-) circle (0.05);
\draw [fill=white] (x) circle (0.05);
\end{tikzpicture}
}{Calculating the electric potential of a dipole}

If we are far from the dipole, these distances are nearly parallel and can be approximated by\footnote{This is similar to the trick we used to analyze the double slit in Lecture \ref{ch:physical-optics}.}
$$r_\pm = r \pm \half d \cos \theta$$
where $r$ is the distance from the center of the dipole and $d$ is the distance between the charges. In addition, since $r$ is much larger than $d$ when we are far away, we can use the binomial theorem \eqref{binomial-theorem} to say
$$\frac{1}{r_\pm} = \frac{1}{r} \left[ 1 \pm \dfrac{\half d \cos \theta}{r} \right]^{-1} = \frac{1}{r} \left[1 \mp \frac{\half d \cos \theta}{r} \right]$$
Putting this result into equation \eqref{dipole-potential-near} gives us the \jargon{far-field} approximation for the dipole potential:
\begin{equation} \label{dipole-potential}
V = \frac{kp}{r^2} \cos \theta
\end{equation}
where $p$ is the dipole moment equal to $qd$ and shows that the potential drops with the square of the distance from the dipole.

% Inserting a dielectric material into a capacitor can dramatically increase its capacitance.

The simplest calculation of potential is inside a capacitor because the field is constant. Using equations \eqref{dfn-potential} and \eqref{capacitor-field}, the voltage difference across the capacitor is simply
$$\Delta V = Qd/\epsilon_0 A$$
Though an insulator can introduce leakage into the capacitor, it can also dramatically increase the ability of the capacitor to store charge. This is due to the fact that the charges on the capacitor plates induce dipole moments in the insulator (called the \jargon{dielectric}) which effectively reduces the distance between the positive and negative charges. So with the same voltage difference, the capacitor will hold a lot more charge. This relationship is called its \jargon{capacitance}:
\begin{equation} \label{dfn-capacitance}
C = Q/V
\end{equation}
For an ideal capacitor, we have
\begin{equation} \label{capacitance-geometry}
C = \kappa \epsilon_0 A/d
\end{equation}
The symbol $\kappa$ is called the \jargon{dielectric constant} and is the factor of increase due to the dielectric between the capacitor plates.

Charging up a capacitor takes work. Each incremental charge that is added takes more work because it is repelled by the ones that are already there. The work required for each must overcome the potential energy given by equation \eqref{pot-ene-ele}. But the voltage is constantly increasing. The total work required to bring a capacitor up to voltage is\footnote{The factor of one-half occurs here in the same way it occurs in the formula for kinetic energy.}
\begin{equation} \label{capacitor-energy}
W = \half CV^2
\end{equation}

% Next week

Next week, we will cover two topics: electricity and magnetism. In the present lecture we have only discussed what happens when charges are in equilibrium or at rest. In the following lecture we will discuss the flow of charge, or current. This will allow us to investigate some simple electronic circuits with resistors and capacitors. 

In addition, we will introduce the magnetic force and discuss its basic properties. We will find a strong parallel between the electric force and the magnetic force with one significant exception: there is no such thing as a magnetic charge. The apparent parallel will continue to erode as we discover that every flow of current creates a magnetic field. Ultimately, natural magnetism is nothing but the result of electric charges in motion.
========
24:dc-and-magnetism
--------
Basic Electronics and Magnetism
--------
Read sections 20.1--20.8, 20.11--20.14 and 21.1--21.8
--------
% Electromotive ``force'' (i.e., voltage) from a battery drives current through a circuit.

Every electric circuit is designed to control and harness the flow of electric charge. Electric \jargon{current} is defined as the amount of charge that flows through a particular surface area each second:
\begin{equation} \label{dfn-current}
I = \frac{\Delta q}{\Delta t}
\end{equation}
The SI unit for current flow is the \jargon{ampere} equal to one coulomb per second. Current is driven by a differential in electric potential or voltage. When a charge is exposed to such a differential, it will accelerate according to Newton's second law \eqref{n2l}. This is what happens in a cathode ray tube, for example. But normally, the flow of current in an electric circuit is controlled through resistance. This means that current is flowing at some constant terminal velocity. And just to add more confusion, this potential difference is typically called the ``electromotive force'' or \jargon{EMF} although it is technically not a force. 

When current flows, energy is moving through the circuit. The power consumed by any electric circuit can be obtained by combining equations \eqref{pot-ene-ele} and \eqref{dfn-current}. We get:
\begin{equation} \label{dc-power}
P = IV
\end{equation}
An ideal battery is an electrical component which is able to maintain a constant voltage difference across its terminals regardless of how much current flows. All batteries wear out, but good ones last, so we will assume that our batteries carry a constant voltage differential. A battery provides direct current which is constant over time. We will consider a different form of current (alternating current) in Lecture \ref{ch:induction-and-ac}. 

\pics[side]{simple-circuit}{
\begin{tikzpicture}
\node (v) [nde,label=below:{$V$}] at (0,-1.5) {}; 
\draw [bat] (v)
  +(-0.5, 0.2) node {\tiny $+$}
  +(-0.3,-0.1) -- +(-0.3,0.1)
  +(-0.1,-0.3) -- +(-0.1,0.3)
  +( 0.1,-0.1) -- +( 0.1,0.1)
  +( 0.3,-0.3) -- +( 0.3,0.3)
  +( 0.5, 0.2) node {\tiny $-$} 
;

\node (r) [draw,inner sep=3mm] at (0,1.5) {Load}; 

\draw (v) -| ($(r)+(-2,0)$) -- (r) -- ($(r)+(2,0)$) |- (v);

\draw [->,dotted] (-0.8,-0.8) arc (270:90:0.8);
\draw [->,dotted] ( 0.8,-0.8) arc (-90:90:0.8);
\node at ( 1,0) {$I$};
\node at (-1,0) {$e^-$};
\end{tikzpicture}
}{A simple electric circuit}

Every circuit has a source of voltage difference (a battery, a solar cell, an antenna). The rest of the circuit is called the ``load'' and is said to ``drop'' the voltage (see Figure \ref{fig:simple-circuit}). Remember that a perfect conductor does not support a voltage difference. So, in order for the circuit to be in a stable state, the voltage differential from the battery must be absorbed in the rest of the circuit somewhere. 

Notice that electrons are actually leaving the negative terminal of the battery and traveling to the positive terminal. However, we will ignore this and consider the current to flow from the positive to the negative terminal.\footnote{This is just a historical accident because the current carrier has a negative charge. When Franklin established the convention in the 18th century, he guessed wrong.} Surprisingly, it rarely makes a difference which way you imagine the current to flow. 

% Resistors have the same resistance (defined by Ohm's law) over a large voltage range.

The simplest electric circuit consists of a battery, a resistor, and two wires connecting them. A \jargon{resistor} is specifically designed to drop the voltage and disperse the energy through heat. The ratio of the amount of current that flows per volt through a substance is called its \jargon{conductivity}, though it is much more common to quote its reciprocal called \jargon{resistivity} which may depend on temperature. An ideal resistor has a constant resistance over all voltage ranges and therefore obeys
\begin{equation} \label{ohms-law}
V = IR
\end{equation}
which is called \jargon{Ohm's law}. The total resistance of a particular resistor will be a combination of its geometry and the natural resistivity of the material used. We have: 
\begin{equation} \label{resistor-geometry}
R = \rho d/A
\end{equation}
where $\rho$ is the resistivity of the material, $d$ is the length of the resistor, and $A$ is its cross-sectional area.

% The total resistance of a combination of resistors depends on how they are connected.

\pics[side]{series-circuit}{
\begin{tikzpicture}
\node (v) [nde,label=below:{$V$}] at (0,0) {}; 
\draw [bat] (v)
  +(-0.5, 0.2) node {\tiny $+$}
  +(-0.3,-0.1) -- +(-0.3,0.1)
  +(-0.1,-0.3) -- +(-0.1,0.3)
  +( 0.1,-0.1) -- +( 0.1,0.1) 
  +( 0.3,-0.3) -- +( 0.3,0.3)
  +( 0.5, 0.2) node {\tiny $-$} 
;

\node (r1) [nde,label=above:{$R_1$}] at (-0.8,2) {}; 
\draw [res] (r1) +(-0.4,0) -- +(0.4,0);

\node (r2) [nde,label=above:{$R_2$}] at (0.8,2) {}; 
\draw [res] (r2) +(-0.4,0) -- +(0.4,0);

\draw (v) -| ($(r1)+(-1.2,0)$) -- (r1) -- (r2) -- ($(r2)+(1.2,0)$) |- (v);
\end{tikzpicture}
}{A simple series circuit}

Now suppose we have two resistors connected to a battery as shown in Figure \ref{fig:series-circuit}. These are said to be \jargon{in series} because the current must from through one before the other. Clearly, the current through each resistor is equal, and the voltage drop is split between them. The total resistance is simply the sum of the two resistors:
\begin{equation} \label{resistors-in-series}
R = R_1 + R_2
\end{equation}

\pics[side]{parallel-circuit}{
\begin{tikzpicture}
\node (v) [nde,label=below:{$V$}] at (0,0) {}; 
\draw [bat] (v)
  +(-0.5, 0.2) node {\tiny $+$}
  +(-0.3,-0.1) -- +(-0.3,0.1)
  +(-0.1,-0.3) -- +(-0.1,0.3)
  +( 0.1,-0.1) -- +( 0.1,0.1)
  +( 0.3,-0.3) -- +( 0.3,0.3)
  +( 0.5, 0.2) node {\tiny $-$} 
;

\node (r1) [nde,label=above:{$R_1$}] at (0,4) {}; 
\draw [res] (r1) +(-0.4,0) -- +(0.4,0);

\node (r2) [nde,label=above:{$R_2$}] at (0,2) {}; 
\draw [res] (r2) +(-0.4,0) -- +(0.4,0);

\draw (v) -| ($(r1)+(-2,0)$) -- (r1) -- ($(r1)+(2,0)$) |- (v);
\draw (v) -| ($(r2)+(-2,0)$) -- (r2) -- ($(r2)+(2,0)$) |- (v);
\end{tikzpicture}
}{A simple parallel circuit}

Another way to connect the two resistors is in parallel---see Figure \ref{fig:parallel-circuit}. In this case, the current runs through the two resistors simultaneously. The current is split and both resistors drop the total voltage. The net resistance of the two parallel resistors is given by:
\begin{equation} \label{resistors-in-parallel}
\frac{1}{R} = \frac{1}{R_1} + \frac{1}{R_2}
\end{equation}
Both equations \eqref{resistors-in-series} and \eqref{resistors-in-parallel} can be seen as consequences of equation \eqref{resistor-geometry}. In the case of resistors in series we effectively increase the length of the resistor: since distance is in the numerator, the resistances add. But in the case of resistors in parallel we effectively increase the area of the resistor and since the area is in the denominator, the reciprocal of the resistances add. Equation \eqref{resistors-in-parallel} can also be rearranged as 
$$R = \frac{R_1 R_2}{R_1 + R_2}$$
We can add and combine resistors in many combinations. It is even possible to combine them in ways which are neither in series or parallel. The flow of current through any circuit is governed by two basic principles called \jargon{Kirchoff's laws}:
\begin{items}
\item The current at any junction sums to zero. Be careful to take into account the direction of the current.
\item The voltage around any loop sums to zero. Be careful to take into account the direction of the potential difference.
\end{items}
The first is based on the conservation of charge and the second on the conservation of energy---compare equation \eqref{electric-curl}. For seriously complicated circuits it is sometimes easier to set up the problem using these laws. But typically, we can work the problem by considering the resistors in pairs, either series or parallel.

% A resistor and capacitor in series will interact with a characteristic time period.

\pics[side]{rc-circuit}{
\begin{tikzpicture}
\node (v) [nde,label=below:{$V$}] at (0,0) {}; 
\draw [bat] (v)
  +(-0.5, 0.2) node {\tiny $+$}
  +(-0.3,-0.1) -- +(-0.3,0.1)
  +(-0.1,-0.3) -- +(-0.1,0.3)
  +( 0.1,-0.1) -- +( 0.1,0.1)
  +( 0.3,-0.3) -- +( 0.3,0.3)
  +( 0.5, 0.2) node {\tiny $-$} 
;

\node (r) [nde,label=above:{$R$}] at (-0.8,2) {}; 
\draw [res] (r) +(-0.4,0) -- +(0.4,0);

\node (c) [nde,label=above:{$C$}] at (0.8,2) {}; 
\draw [cpr] (c) 
  +(-0.4,  0) -- +(-0.1,   0)
  +(-0.1,0.3) -- +(-0.1,-0.3)
  +( 0.1,0.3) -- +( 0.1,-0.3)
  +( 0.1,  0) -- +( 0.4,   0);

\draw (v) -| ($(r)+(-1.2,0)$) -- (r) -- (c) -- ($(c)+(1.2,0)$) |- (v);
\end{tikzpicture}
}{A simple RC circuit}

We can also add capacitors to our circuits. Consider Figure \ref{fig:rc-circuit}. Initially, current flows through the resistor and charges up the capacitor. All the voltage drops across the resistor. But as the capacitor begins to charge up, it also begins to drop voltage according to equation \eqref{dfn-capacitance}. Since the voltage drop across the resistor is less, the total current flow is less by Ohm's law \eqref{ohms-law}. The flow of current exponentially decreases until the capacitor is essentially fully charged. The formula for the current is given by
\begin{equation} \label{charging-capacitor}
I(t) = I_0 \exp( -t / RC )
\end{equation}
where $I_0 = V/R$. The quantity $RC$ is sometimes called the \jargon{time constant} for the circuit. Typically the capacitor is considered fully charged after five time constants since the current flow is under 1\% of its original level.

% Natural magnetism only occurs in a dipole field pattern: poles only occur in pairs.

We are now ready for a complete change of subject\ldots. Let's talk magnetism. The awareness of magnets and magnetism appears to go back thousands of years, but the Chinese were the first to write about using magnetic compasses for navigation in the 11th century. The study of magnetism was also one of the few sciences to advance in Europe during the Middle Ages culminating the work of William Gilbert (a contemporary of Galileo) in 1600.\footnote{In this work, Gilbert explained the working of the compass needle by assuming the Earth to be a large magnet. He did not know why the Earth is a large magnet, and neither do we.}

After one has played with a set of bar magnets, it becomes clear that the ends of the magnet are special---we call them the \jargon[magnetic poles]{poles} of the magnet.\footnote{The poles of a magnet are not actually located at the ends of the magnet. Rather they are somewhat inside (about 1/6 from the end or so).} We say that like poles repel while unlike poles attract. There really is nothing to prevent us from calling one positive and the other negative, but for obvious historical reasons we call these groups north poles and south poles. 

Suppose we bring the north poles of two magnets together. They will repel while the south poles attract. This pair of forces will tend to twist the magnet. In other words, each magnet experiences a net torque. This torque guarantees that two magnets will always be attracted to one another, even if they have to twist around first.

Coulomb performed experimentation to quantify this magnetic force. The force law is the same inverse square law that he found for electricity:
\begin{equation} \label{coulombs-law-magnetic}
F = \frac{1}{4\pi \mu_0} \frac{p_1 p_2}{r^2}
\end{equation}
where each $p$ represents the strength of the poles and the constant $\mu_0$ is assigned the value $\sci{4\pi}{-7}$. This constant is called the \jargon{magnetic constant}.\footnote{Again, I learned this as the ``permeability of free space'', but this is easier to remember} A pole strength of one \jargon{weber} will repel a like pole placed at one meter with a force of $10^7/(4\pi)^2$ newtons. The magnetic field and flux are defined in just the same way as with the electric force.

But if one splits a magnet in two, one gets two magnets, not two poles. The smallest element of magnetism observed physically is not a magnetic pole but a magnetic dipole.\footnote{For this reason many authors avoid discussing magnetic poles in detail.} In other words, there is no ``magnetic charge''. This is why there is no such thing as a magnetic conductor nor magnetic circuits. It also implies that Gauss' law for magnetic flux is simply
$$\sum_\text{surf} \Phi_\text{mag} = 0$$

% A moving electric charge will experience a magnetic force proportional to its velocity.

Though an exact parallel between electricity and magnetism is broken, the two are deeply interconnected. So much so that we are justified in considering them two aspects of a single electromagnetic force. The first step in this discovery is by recognizing that an electric charge can experience a magnetic force. This is called the \jargon{Lorentz force}:
\begin{equation} \label{lorentz-force}
F = qvB \sin \theta
\end{equation}
where $v$ is the speed of the charge and $\theta$ is the angle between the velocity and the magnetic field.\footnote{This is exactly the force that is used to guide the electron beam in a standard CRT.} Notice that the charge only experiences this force when it is in motion. Also, the direction of this force is perpendicular to both the velocity and the field.

The perpendicular nature of the Lorentz force is unusual, but not unheard of. We encountered a force that acts perpendicular to velocity in the Coriolis force from Lecture \ref{ch:rotation} (page \pageref{idx:Coriolis force}) and in gyroscopic motion. However, knowing that the force is perpendicular to the plane formed by the velocity and field leaves us still uncertain: which way? The rule to distinguish which is called the \jargon{right hand rule} and goes like this. Take the four fingers of your right hand and point them in the direction of the field. Point your thumb in the direction of the charge's motion. If the charge is positive, your palm pushes in the direction of the force.

This weird rule means that magnetic force problems are usually three-dimensional. As such, a convention exists for drawing these things. When we want to indicate the direction of something is pointing out of the paper and toward the reader we use a circular symbol with a dot in the center. If the direction is away from the reader (into the paper), we use a circular symbol with an $\times$ in it. These are supposed to represent the tip and tail of an arrow. For example, see Figure \ref{fig:lorentz-force}.

\pics[side]{lorentz-force}{
\begin{tikzpicture}

\clip (-2.5,-2.5) rectangle (2.5,2.7);

\begin{scope}[yshift=15mm]
\node at (0.9,1) [right=1mm] {$B$};
\foreach \x in {-0.9,-0.3,0.3,0.9} \draw [->] (\x,-1) -- +(0,2);
\draw [->] (-1.5,0) -- (1.5,0) node [pos=1.1] {$v$} ;
\node [inout,point=out,label=270:{$F$}] {};
\node [left=2mm] at (-1.5,0) {$+q:$};
\end{scope}

%\node at (0,0) {\small $F = qvB \cos \theta$};

\begin{scope}[yshift=-15mm]
\node at (0.9,1) [right=1mm] {$B$};
\foreach \x in {-0.9,-0.3,0.3,0.9} \draw [->] (\x,-1) -- +(0,2);
\draw [->] (-1.5,0) -- (1.5,0) node [pos=1.1] {$v$} ;
\node [inout,point=in,label=270:{$F$}] {};
\node [left=2mm] at (-1.5,0) {$-q:$};
\end{scope}

\end{tikzpicture}
}{The magnetic force on a moving electric charge (Lorentz force)} 

% Because the magnetic force is perpendicular to the velocity, it does no work.

Because this force is always perpendicular to the velocity of the charge, the magnetic force never does work on the charge. The force will deflect its motion without changing its speed. In fact, the magnetic force acts as a perfect centripetal force---the typical motion for a charge in a magnetic field is in a circle. Combining equations \eqref{lorentz-force} and \eqref{centripetal-force}, the radius of this circle will be 
\begin{equation} \label{magnetic-circle}
r = \frac{mv}{qB}
\end{equation}
This is how a mass spectrometer works. By sending an ionized sample through a magnetic field, the sample will separate as it bends according to the mass-to-charge ratio ($m/q$) thus giving important information regarding the constituents of the sample. If we accelerate the sample with a constant electric field, then we can calculate it speed upon entering the magnetic field. Initially, the potential energy of the sample is $qV$ which is converted to kinetic energy $\half mv^2$. Setting these equal to one another and combining with equation \eqref{magnetic-circle} yields
\begin{equation} \label{mass-spectrometer}
\frac{m}{q} = \frac{B^2 r^2}{2V}
\end{equation}
which shows how the mass-to-charge ratio can be determined from the settings in the mass spectrometer.

% This also means that a current carrying coil will feel torque, which is how a motor works.

Clearly, if a moving charge experiences a magnetic force, so will a straight line of current. Combining equations \eqref{lorentz-force} and \eqref{dfn-current} yields 
$$F = ILB \sin \theta$$
where $L$ is the length of the wire of current.

If we take the same line of current and wrap it into a circle, the coil will experience a torque in the magnetic field since one side will be pulled while the other side is pushed down. In Figure \ref{fig:electric-motor}, the ring of current is pushed into the paper on the top and out of the paper on the bottom. This force couple puts a total torque on the ring of
\begin{equation} \label{electric-motor}
\tau = NIAB \sin \theta
\end{equation}
where $N$ is the number of coils and $A$ is the area formed by the ring. 

\pics[side]{electric-motor}{
\begin{tikzpicture}
\foreach \x in {-1.8,-0.6,0.6,1.8} \draw [->] (\x,-2) -- (\x,2);
%\draw [white,double distance=2mm,double=black] (0,0) circle (1.3);
\draw [black,line width=2mm] (0,0) circle (1.3);
\foreach \q in {90,270} \draw [->,thick,white] ({\q-45}:1.3) arc ({\q-45}:{\q+45}:1.3);
%\foreach \q in {0,180} \draw [->,thick,white] ({\q-45}:1.3) arc ({\q-45}:{\q+45}:1.3);
\node at (45:1.7) {$I$};
\node at (225:1.7) {$I$};
\node at (0,1.3) [inout,point=in,label=270:{$F$}] {};
\node at (0,-1.3) [inout,point=out,label=90:{$F$}] {};
\end{tikzpicture}
}{How to build a simple motor} 

This torque is how a basic electric motor works. The magnetic forces tend to twist the coil to align perpendicular to the magnetic field. As it rotates, the torque gets smaller according to $\sin \theta$. Once it is perpendicular, the torque disappears (the magnetic forces are now trying to pull the ring apart). The inertia in the ring will cause it to continue its rotation. If you time it just right and flip the direction of the magnetic field, you can pull the ring back to its original position. By alternating the magnetic field back and forth we can drive the coil around and around indefinitely.

% An electric current also generates a magnetic field that curls around the wire.

In 1820, Oersted \href{http://en.wikipedia.org/wiki/Hans_Christian_Oersted\#Electromagnetism}{stumbled} upon a further connection between electric current and magnetism. Current is not only affected by a magnetic field, but it can also generate a magnetic field. He discovered this by a very simple experiment you can do at home. Take a battery and connect the terminals with a wire (it will get hot, so be careful and quick). Bring the wire close to a typical compass. The compass needle will be deflected in the presence of the wire.

In the end, it was discovered that the magnetic field actually wraps itself around the current. Again, the weird perpendicular nature of magnetism is manifest. And we need another right hand rule to guide us here too. Point the thumb of your right hand in the direction of the current flow. Your fingers naturally curl in the direction of the magnetic field generated by the current.

% Ampere's law summarizes the magnetic field generated by current, similar to Gauss' law.

Shortly afterward, Ampere discovered a general law for the generated magnetic field. \jargon{Ampere's law} is
\begin{equation} \label{amperes-law}
\sum_\text{loop} B_t \Delta s = \mu_0 I
\end{equation}
which states that the amount that the field curls around the wire is directly proportional to the current in the wire. 

Recall in the previous lecture (page \pageref{idx:field potential}) that we stated that when a field has zero curl, we may define a field potential. Ampere's law shows that we cannot do the same thing for the magnetic field: there is no magnetic ``voltage''. 

On the other hand, we know that the magnetic field does no work, so the magnetic force is conservative. A type of magnetic potential does exist---but it is a vector (typically given the symbol $A$). As a consequence, there is no great mathematical advantage to using the magnetic potential, so we will generally ignore it. It does play a role in quantum electrodynamics (see Lecture \ref{ch:quantum-mechanics}), but we will table the concept for now.\footnote{The vector potential is used to derive the Lorentz force law from the principle of least action. The Lagrangian for a charged particle in an electromagnetic field is $$\half mv^2 - qV + qv \cdot A$$}

For a simple straight wire, it follows from equation \eqref{amperes-law} that the magnetic field is given by
\begin{equation} \label{magnetic-field-wire}
B = \dfrac{\mu_0 I}{2 \pi r}
\end{equation}
This implies that two wires with parallel currents will attract one another. Ampere calculated the total force between the wires to be
\begin{equation} \label{currents-attract}
F = \mu_0 \frac{I_1 I_2}{2\pi r}
\end{equation}
Which looks a bit like Coulomb's law and emphasizes the fact that an electric current acts like the magnetic ``charge'' we were seeking earlier.

% A solenoid is a large number of coils; inside the solenoid the magnetic field is constant.

We can drive this analogy a bit further because the magnetic field around a coil of wire is shaped like a dipole field (see Figure \ref{fig:dipole-field-coil}).

\pics[]{dipole-field-coil}{
\begin{tikzpicture}
\clip (-5,-2.3) rectangle (5,2.3);
\node at (0,0) {\includegraphics[scale=0.2]{images/VFPt_coil.png}};
\end{tikzpicture}
}{Magnetic field around a coil of wire is like a dipole field (image credit \href{http://upload.wikimedia.org/wikipedia/commons/thumb/3/39/VFPt_dipole_magnetic1.svg/1000px-VFPt_dipole_magnetic1.svg.png}{here}). Compare with Figure \ref{fig:dipole-field}}

The dipole moment associated with the current ring is simply
\begin{equation} \label{magnetic-moment}
m = IA
\end{equation}
where $A$ is the area of the ring. The calculation of force is fairly difficult (like the electric dipole), but the magnetic field in the center of the ring has a magnitude of
\begin{equation} \label{magnetic-field-coil-center}
B = \frac{\mu_0 I}{2r}
\end{equation}
where $r$ is the radius of the coil. Don't confuse this with equation \eqref{magnetic-field-wire}!

The system with the simplest magnetic field is called a \jargon{solenoid}. If we take coils of wire and stack them, the magnetic field trapped inside the wires approaches uniformity. This is more commonly known as an \jargon{electromagnet}. If we extend the stack infinitely, we have a ideal solenoid and the magnetic field is given by
\begin{equation} \label{magnetic-field-solenoid}
B = \mu_0 n I
\end{equation}
where $n$ is the number of coils per unit length, i.e., $n = N/L$. All of the magnetic field is trapped inside an perfect solenoid and in many ways this offers a magnetic parallel to the electric capacitor.

% A spinning charge is like a small bar magnet, which is the source of natural magnetism.

Ampere's law also works at the subatomic level. Electrons in orbit around the nucleus and even the quantum mechanical spin of elementary particles all have a magnetic moment associated with them. In fact, one of the precision tests of quantum electrodynamics involves the calculation of the magnetic moment of the electron. All this means that each elementary particle and each atom act like little magnets. Typically the orientation of these little magnets is randomized due to thermal agitation. So this natural magnetism is normally hidden at the macroscopic level.

But some materials naturally align their magnetic moments. This is called \jargon{ferromagnetism} since iron has this property. The standard bar magnet is made of a ferromagnetic material. Why some materials are ferromagnetic rather than others is a question for solid state physics (see Lecture \ref{ch:solid-state}).

There is another way in which large scale objects can be magnetic. As we mentioned earlier, a magnetic dipole in the presence of a magnetic field will tend to align itself with the field. In this way we can induce a dipole moment in an object by bringing it close to another magnet. This is called \jargon{paramagnetism} and is similar to the way that static electricity on a balloon will stick to the wall due to an induced electric dipole moment in the wall. In the same way, the effect is typically very slight and difficult to detect.

There is a third way magnetism shows itself on the macroscopic scale called \jargon{diamagnetism} but a proper understanding of it requires knowing Lenz' law which will learn about in the next lecture. Unlike the other two, diamagnetism is repulsive so it can create some interesting effects including \href{http://www.ru.nl/hfml/research/levitation/diamagnetic/}{levitating frogs}.

% Next week

Next week we will continue to explore the way in which electricity and magnetism are intertwined. We will find that we can reverse the way a motor converts electric current into motion. This provides a simple way to generate electricity and is the reason for the prevalence of alternating current in applications. We will explore the way the solenoid works in this context and describe how electrical energy can be transported between separated circuits through the magnetic field. We talk about AC circuits in some detail and finish with a discussion of resonance in electric circuits. This will complete our investigation of electromagnetism with one small but important insight which we will pick up in Lecture \ref{ch:em-and-relativity}.
========
25:induction-and-ac
--------
EM Induction and AC Electronics
--------
Read sections 22.1--22.4, 22.7--22.9 and 23.1--23.4
--------
% Moving through a magnetic field will generate EMF; a changing magnetic flux will do the same.

An \href{http://en.wikipedia.org/wiki/Electrodynamic_tether}{electrodynamic tether} is essentially a huge wire that hangs off a satellite or space craft as it travels through the magnetic field of the earth. The electrons in the conductor are free to move and since they are moving through a magnetic field they are pushed by the Lorentz force. Thus a current is induced in the conductor (see Figure \ref{fig:electrodynamic-tether}). This way of driving current is called \jargon{motional EMF} and is a simple way (in principle) to extract energy from the earth's magnetic field.

\pics[side]{electrodynamic-tether}{
\begin{tikzpicture} 
\fill [black!20] (-1.5,-1.5) rectangle (1.5,1.5);
\foreach \x in {-1,0,1}
\foreach \y in {-1,0,1}
\node at (\x,\y) [inout,pointing in] {};
\coordinate (+) at (1.5,1.5);
\coordinate (-) at (1.5,-1.5);
\draw [ultra thick] (+) -- (-);
\draw [->] (1,0.5) -- (2,0.5);
\draw [->] (1,-0.5) -- (2,-0.5);
\node at (2,0) {$v$};
\begin{scope}
\tikzstyle {every node} = [circle,inner sep=0pt,draw,shade=ball]
\node (1+) at (+) [below=2pt] {\tiny$\boldsymbol+$};
\node (2+) at (1+.south) [below] {\tiny$\boldsymbol+$};
\node (1-) at (-) [above=2pt] {\tiny$\boldsymbol-$};
\node (2-) at (1-.north) [above] {\tiny$\boldsymbol-$};
\end{scope}
\draw [decorate,decoration=brace,xshift=-2mm] (-1.5,-1.5) -- (-1.5,1.5) node [pos=0.5,left=1mm] {$L$};
\draw [decorate,decoration=brace,yshift=2mm] (-1.5,1.5) -- (1.5,1.5) node [pos=0.5,above=1mm] {$x = vt$};%{$\Delta x = v / \Delta t$};
\end{tikzpicture} 
}{Motional EMF generated by an electrodynamic tether}

This is an example of a type of electromagnetic induction. We can calculate this motional EMF by blocking the current flow. As the charges separate in the wire, an electric field forms since the charges are attracted to one another (like a capacitor). This electric field counterbalances the Lorentz force caused by the motion of the charges through the magnetic field. At equilibrium the net voltage is zero, so the voltage induced by the charge separation equals the motion EMF causing the charge separation. Setting the electric and magnetic forces equal we have $E = vB$ since the charge cancels from both sides. Using the definition of field potential \eqref{dfn-potential}, the motional EMF generated in this process must be
\begin{equation} \label{motional-emf}
V_\text{emf} = vBL
\end{equation}
where $L$ is the length of the wire.

Equation \eqref{motional-emf} is a special case of \jargon{Faraday's law} of induction:\footnote{You might wonder why there is no proportionality constant here. The way we have defined the electric and magnetic constants in the previous lectures happens to make the proportionality here equal to one.}
\begin{equation} \label{faradays-law}
V_\text{emf} = -\frac{\Delta \Phi_\text{mag}}{\Delta t}
\end{equation}
In Figure \ref{fig:electrodynamic-tether}, the wire sweeps out the area given by $Lvt$. The magnetic flux cut by the wire is therefore $LvtB$, which after dividing by $t$ and rearranging gives us equation \eqref{motional-emf}.

The negative sign tells us which direction the EMF points and the rule in summarized in \jargon{Lenz' law}:
\begin{quote}
The magnetic field produced by the current driven by the induced EMF opposes the change in magnetic flux surrounded by the current.
\end{quote}
In Figure \ref{motional-emf}, the current flows up the wire which generates a magnetic field out of the paper behind the wire. This field opposes the field in the highlighted area consistent with Lenz' law.

Consider another example in which we have a conducting ring sitting perpendicular to a magnetic field (see Figure \ref{fig:ring-in-field}). If we shut the field off, current will flow in the wire attempting to restore the field (according to Lenz' law). 

\pics[]{ring-in-field}{   
\begin{tikzpicture} 
\begin{scope}[xshift=-25mm]
\fill [black!20] (-1.5,-1.5) rectangle (1.5,1.5);
%\draw [gray,double distance=2mm,double=gray] (0,0) circle (1.3);
\draw [line width=2mm] (0,0) circle (1.3);
\foreach \x in {-1,0,1}
\foreach \y in {-1,0,1}
\node at (\x,\y) [inout,pointing in] {};
\end{scope} 
\node at (0,0) {$\Delta t \newline \implies$};
\begin{scope}[xshift=25mm]
\fill [black!20] (-1.5,-1.5) rectangle (1.5,1.5);
%\draw [gray,double distance=2mm,double=gray] (0,0) circle (1.3);
\draw [line width=2mm] (0,0) circle (1.3);
\draw [<-,thick,white] (30:1.3) arc (30:120:1.3);
\node at (45:1.3) [above right] {$I$};
\node at (0,0) {$V_\text{emf}$};
\end{scope} 
\end{tikzpicture} 
}{Induced EMF in a conducting ring by a changing magnetic field}

Now, consider this question: where are the positive and negative terminals of this electromotive force? Answer: there are none---the induced EMF is circular.\footnote{This fact perhaps justifies maintaining the distinction between EMF and voltage.} In other words, when the magnetic field changes, it curls up the electric field!

% An electric generator is a motor running in reverse and creates alternating current.

Perhaps the most important application of Faraday's law is the \jargon{electric generator}. In principle, a basic generator is a electric motor operating in reverse---see Figure \ref{fig:electric-motor}. We turn the coil and current flows. Faraday's law operates here because the coil cuts through the magnetic flux. Assuming the coil rotates at a constant angular speed of $\omega$, the flux within a coil with area $A$ is given by
$$\Phi_\text{mag} = BA \cos \omega t$$
This assumes the coil is initially perpendicular to the field. Faraday's law \eqref{faradays-law} tells us that the induced EMF in the coil will be\footnote{This formula can be verified by using the projection technique we used in Lecture \ref{ch:harmonic-motion} while discussing simple harmonic motion (page \pageref{shm}). It's easiest if you use a square coil. A bit of calculus would be of use here.}
\begin{equation} \label{electric-generator}
V_\text{emf} = BA\omega \sin \omega t
\end{equation}
This equation is the reason for \jargon{alternating current} in electronics. The sinusoidal pattern of both voltage and current activates Faraday's law and allows us to play with the full power of the electromagnetic field.

\pics[full]{ac-patterns}{   
\def\xsquish{0.8}
\def\ysquish{0.5}
\hfill
\begin{tikzpicture} 
\begin{scope}[yscale=\ysquish,xscale=\xsquish]
\def\rms{1.00}
\fill [black!20] (0,-\rms) rectangle (4,\rms);
\draw (0.1,\rms) -- (-0.1,\rms) node [pin=225:{$V_\text{rms}$}] {};
\draw (0.1,1) -- (-0.1,1) node [pin=135:{$V_\text{peak}$}] {};
\draw [->,dotted] (0,0) -- (4.5,0) node [right] {$t$};
\draw (0,1.5) -- (0,-1.5);
\draw (0,1) -| (1,-1) -| (2,1) -| (3,-1) -- (4,-1);
\coordinate (x) at (current bounding box.north);
\node at (x) [above] {
\begin{minipage}{40mm}
\centering
\textbf{Square wave} \par
$V_\text{rms} / V_\text{peak} = 1$
\end{minipage}
};
\end{scope}
\end{tikzpicture}
\hfill
\begin{tikzpicture} 
\begin{scope}[yscale=\ysquish,xscale=\xsquish]
\def\rms{0.50}
\fill [black!20] (0,-\rms) rectangle (4,\rms);
\draw (0.1,\rms) -- (-0.1,\rms) node [pin=225:{$V_\text{rms}$}] {};
\draw (0.1,1) -- (-0.1,1) node [pin=135:{$V_\text{peak}$}] {};
\draw [->,dotted] (0,0) -- (4.5,0) node [right] {$t$};
\draw (0,1.5) -- (0,-1.5);
\draw (0,0) -- (0.5,1) -- (1.5,-1) -- (2.5,1) -- (3.5,-1) -- (4,0);
\coordinate (x) at (current bounding box.north);
\node at (x) [above] {
\begin{minipage}{40mm}
\centering
\textbf{Triangle wave} \par
$V_\text{rms} / V_\text{peak} = 1/2$
\end{minipage}
};
\end{scope}
\end{tikzpicture}
\hfill
\begin{tikzpicture} 
\begin{scope}[yscale=\ysquish,xscale=\xsquish]
\def\rms{0.71}
\fill [black!20] (0,-\rms) rectangle (4,\rms);
\draw (0.1,\rms) -- (-0.1,\rms) node [pin=225:{$V_\text{rms}$}] {};
\draw (0.1,1) -- (-0.1,1) node [pin=135:{$V_\text{peak}$}] {};
\draw [->,dotted] (0,0) -- (4.5,0) node [right] {$t$};
\draw (0,1.5) -- (0,-1.5);
\draw [domain=0:4,samples=50] plot (\x,{sin(180*\x)});
\coordinate (x) at (current bounding box.north);
\node at (x) [above] {
\begin{minipage}{40mm}
\centering
\textbf{Sine wave} \par
$V_\text{rms} / V_\text{peak} = \sqrt{1/2}$
\end{minipage}
};
\end{scope}
\end{tikzpicture} 
\hfill
}{Examples of AC voltage patterns and their corresponding RMS values}

Technically, alternating current can refer to any repeating pattern of current as in Figure \ref{fig:ac-patterns}, but the vast majority of the time we will be considering the sine wave pattern. In the figure I have highlighted the RMS value for the voltage which is a kind of average---a measure of where the voltage is ``most of the time''. The term RMS stands for \jargon{root-mean-square} which is how it is calculated: take the average of the voltage squared then take the square root. This trick eliminates the sign of the voltage---the simple average for all three patterns is zero.

Most of the analysis in our AC electronics will be using the RMS value of the AC voltage. In general, assume the quantities involved are RMS values unless you are otherwise told.

% Alternating current in one coil will generate current in another---this is a transformer.

Using alternating current electromagnetic energy can be transmitted between circuits that are not electrically connected. Fluctuating current in one wire will drive current through another wire according to Faraday's law \eqref{faradays-law}. This interconnection of two electric circuits through the magnetic field is called their \jargon{mutual inductance}. For a wire, the magnetic field drops off according to equation \eqref{magnetic-field-wire} so we have to bring the wires close together before this \jargon{electrical interference} manifests itself. 

However, we can concentrate this electromagnetic energy by using solenoids instead. This is how the \jargon{transformer} works. Suppose we take a solenoid and wrap another on top of it without connecting them. Since the geometries are the same, the magnetic flux in one will be the same as the magnetic flux in the other. The current in the primary coil will drive the magnetic field that influences the voltage in the secondary. 

This magnetic field is influenced by the number of coils in the primary according to equation \eqref{magnetic-field-solenoid}. The amount of voltage induced in the secondary is related to its number of coils since Faraday's law \eqref{faradays-law} applies to each coil and the EMF accumulates. This means that the voltages are related to the number of coils according to
\begin{equation} \label{transformer-equation}
\frac{V_s}{V_p} = \frac{N_s}{N_p}
\end{equation}
The ratio on the right-hand-side is called the \jargon{turns ratio}. The transformer is said to ``step-up'' or ``step-down'' the voltage depending on whether the turns ratio is greater than or less than one, respectively.

Any change in voltage comes at a cost: the currents are inversely proportional to the turns ratio. This fact will conserve the overall energy in the system according to equation \eqref{dc-power}.

% Every solenoid has a certain amount of self-inductance which stores magnetic energy.

Of course, the magnetic field from a current also induces an EMF back onto itself. This EMF actually opposes the original current flow and is called \jargon{back EMF}. It's a kind of natural resistance from the electromagnetic field itself and closely related to Lenz' law. What this means is that every circuit has its own \jargon{self-inductance}. We define the self-inductance of a circuit through the equation
\begin{equation} \label{dfn-inductance}
V_\text{emf} = L \frac{\Delta I}{\Delta t}
\end{equation}
The self-inductance defines how sensitive the back EMF a circuit is to changes in current. In particular, the self-inductance of an ideal solenoid is
\begin{equation} \label{inductor-geometry}
L = \mu_0 n^2 Ad
\end{equation}
which can be derived by combining equations \eqref{magnetic-field-solenoid}, \eqref{faradays-law} and \eqref{dfn-inductance}.

When we talk about a solenoid in an electronic circuit, we use the term \jargon{inductor}. Similar to the way a capacitor requires work to come up to full voltage, the inductor requires work to come up to full current since we are working against the back EMF from Faraday's law. The total work required can be calculated from equation \eqref{dfn-inductance}. It is
\begin{equation} \label{inductor-energy}
W = \half LI^2
\end{equation}
This energy is stored in the magnetic field inside the inductor. This parallels the way the energy required to charge a capacitor is stored in its electric field.\footnote{The parallel is not as exact as it might look. For example, see an interesting discussion on how to release the magnetic energy stored in the inductor (to ``discharge'' it) \href{http://www.physicsforums.com/showthread.php?t=70065}{here} and \href{http://www.physicsforums.com/showthread.php?t=273050}{here}.}

% Phasors are a way to account for both the magnitude and phase shifts in AC circuits.

So far, we have discussed three basic electronic components: the capacitor, resistor, and inductor. We now wish to investigate how these three components work in AC circuits. But before we do, I would like to introduce you to some mathematical trickery known as \jargon{phasors}.

Typically phasors are introduced as complex numbers, but the important thing to know is that they are two-component quantities. Essentially we are going to use the analogy we made in Lecture \ref{ch:harmonic-motion} between uniform circular motion and simple harmonic motion (see Figure \ref{fig:ucm-projected2}). We represent our oscillating quantity (i.e., voltage and current) with a vector that uniformly rotates around a circle. Its angular speed is $\omega = 2\pi f$. 

\tikzfig[]{ucm-projected2}
{
\begin{tikzpicture}[scale=2]
\def\xnudge{25mm}%{0mm}
\def\ynudge{0mm}%{-30mm}

\def\ang{30}
\def\rad{1}
\def\vel{0.7}
\def\acc{0.7*0.7}
\def\bot{-1.5\rad}

%%%%%%%% ucm-to-shm-position %%%%%%%%
\begin{scope}[]
% This shades the projection
\fill [black!10] (\ang:1) -- (0,0) |- ({cos(\ang)},\bot) -- cycle;
% This is the circular motion
\draw [help lines] (0,0) circle (\rad);
\draw [dotted] (0,0) -- (0:\rad);
\draw [->,very thick] (0,0) -- (\ang:\rad);
\draw [fill=white] (\ang:\rad) circle (0.05);
% This is the projected motion
\draw [|-|,help lines] (-\rad,\bot) -- (\rad,\bot);
\draw [->,very thick] (0,\bot) -- +({cos(\ang)},0);
\draw [fill=white] ({cos(\ang)},\bot) circle (0.05);
\node at (0,\bot) [below=1mm] {$x(t) = A \cos (\omega t)$};
\end{scope}

%%%%%%%% ucm-to-shm-velocity %%%%%%%%
\begin{scope}[xshift=\xnudge,yshift=\ynudge]
% This shades the projection
\fill [black!10] (\ang:1) -- +(90+\ang:\vel) |- ({cos(\ang)},\bot) -- cycle;
% This is the circular motion
\draw [help lines] (0,0) circle (\rad);
\draw [dotted] (0,0) -- (\ang:\rad);
\draw [->,very thick] (\ang:\rad) -- +(90+\ang:\vel);
\draw [fill=white] (\ang:\rad) circle (0.05);
% This is the projected motion
\draw [|-|,help lines] (-\rad,\bot) -- (\rad,\bot);
\draw [->,very thick] ({cos(\ang)},\bot) -- +({\vel*cos(90+\ang)},0);
\draw [fill=white] ({cos(\ang)},\bot) circle (0.05);
\node at (0,\bot) [below=1mm] {$v(t) = A \omega \sin (\omega t)$};
\end{scope}

\end{tikzpicture}
}{Actually, we have already used phasors: taken from Figure \ref{fig:ucm-projected}}

The most important thing to realize from Figure \ref{fig:ucm-projected2} is that if any quantity oscillates according to $A \cos (\omega t)$, then its rate of change also oscillates. The formula for its rate of change is $A \omega \sin (\omega t)$.

% Resistors, capacitors, and inductors all react differently under alternating voltage.
% http://www.allaboutcircuits.com/pdf/AC.pdf

For example, if we run an alternating current through an inductor we expect it to generate an EMF due to its self-inductance by \eqref{dfn-inductance}. If the pattern of the current is $I(t) = I_0 \cos (2\pi ft)$, then the voltage across the inductor will be
$$V(t) = (2\pi fL)(I_0)\sin(2\pi ft)$$
The ratio of the RMS values of the voltage and current is called the \jargon{reactance} of the inductor:
\begin{equation} \label{inductor-reactance}
X_L = \frac{V_\text{rms}}{I_\text{rms}} = 2\pi fL
\end{equation}
This self-inductance means that when an inductor is attached to a high frequency AC voltage source the resulting current will be small since most of the energy will oscillate in the magnetic field. 

A capacitor reacts quite differently to high frequency AC voltage. The faster the frequency, the faster the charges have to move to keep up according to equation \eqref{dfn-capacitance}. Since current is the flow rate of charge we can rewrite this equation as
$$I = C \frac{\Delta V}{\Delta t}$$
So if the pattern of the voltage is $V(t) = V_0 \cos (2\pi ft)$, then the current across the capacitor will be
$$I(t) = (2\pi fC)(V_0)\sin(2\pi ft)$$
Which means the capacitor has a reactance of
\begin{equation} \label{capacitor-reactance}
X_C = \frac{V_\text{rms}}{I_\text{rms}} = \frac{1}{2\pi fC}
\end{equation}
Resistors, capacitors, and inductors are called \jargon{passive components} because the magnitude of current and voltage are proportional through equations \eqref{ohms-law}, \eqref{capacitor-reactance}, or \eqref{inductor-reactance}, respectively.\footnote{Active components include diodes and transistors which we will talk about in Lecture \ref{ch:solid-state}.}

Notice that in the case of resistance the current and voltage wave patterns are in phase. But with reactive components, there is a phase shift. For inductors, the voltage is tied to the change in the current. So the voltage peaks at the initial rise of the current and drops to zero when the current hits its peak. There is a phase shift between the two wave patterns: the voltage is 90\dg in front of the current. 

For a capacitor, the current is tied to the change in voltage. So the current is 90\dg in front of the current. One way to remember the phase shifts for the two components is with the mnemonic \jargon{ELI the ICE man}: voltage (or EMF) leads current in an inductor and current leads voltage in a capacitor.

We distinguish reactance from resistance because the power is lost in resistance. With reactance the power used to maintain either the electric or magnetic field is recovered. Resistance corresponds to friction in the electron flow, while reactance corresponds to its inertia. But they both affect the relationship between voltage and current in the circuit. 

% The magnitude of the total reactance is the impedance and the angle is related to power.

Because of the phase shifts involved, calculating the net current flow through a particular AC circuit is a challenge. To facilitate the mathematics we define the \jargon{impedance} of a circuit to be the phasor with a magnitude equal to the ratio of voltage and current (like reactance and resistance) and with an angle equal to the phase angle that the voltage leads the current. The impedances for our three electrical components are listed in Table \ref{tbl:impedances}.

\tbl[side]{impedances}{ccc}{
\multirow{2}{*}{Component} & \multicolumn{2}{c}{Impedance} \\
          & Mag.         & Ang. \\
\hline
Resistor  & $R$          &   $0\dg$ \\
Capacitor & $1/2\pi f C$ & $-90\dg$ \\
Inductor  & $2\pi f L$   &  $90\dg$ \\
}{Component impedances with their phasor direction}

In this way we can summarize equations \eqref{ohms-law}, \eqref{capacitor-reactance}, and \eqref{inductor-reactance} in the single AC version:
\begin{equation} \label{ohms-law-ac}
V = IZ
\end{equation} 
where $Z$ represents the impedance of the component. This equation is even better than it looks because if we use complex numbers, the phase shift relationships are accounted for automatically.

The phase angle of the total impedance is related to the power consumption in the circuit. The formula is
\begin{equation} \label{ac-power}
P = IV \cos \phi
\end{equation}
Although this looks a lot like equation \eqref{dc-power} from which it is derived, the symbols have a slightly different meaning in this AC context. The current and voltage are RMS values and the power is the average power consumed over time. Consider Figure \ref{fig:ac-power}. It's an odd mathematical coincidence that when two sine waves with a phase shift are multiplied the result is another sine wave which is displaced vertically. This displacement is equal to the average power consumption.

\pics[]{ac-power}{
\begin{tikzpicture}
\def\xnudge{45mm}
\def\ynudge{-15mm}
\begin{scope}[yshift=0mm]
\draw [gray] (0,0.5) -- (0,-0.5);
\draw [gray] (0,0) -- (3,0) node [pos=0,left=1mm] {\color{black}$I$};
\draw [domain=0:3,samples=50] plot (\x,{0.5*sin(180*\x)});
\draw [dotted] (0.5,0.5) -- +(0,-1.5);
\end{scope}
\begin{scope}[yshift=\ynudge]
\draw [gray] (0,0.5) -- (0,-0.5);
\draw [gray] (0,0) -- (3,0) node [pos=0,left=1mm] {\color{black}$V$};
\draw [domain=0:3,samples=50] plot (\x,{0.5*sin(180*\x-60)});
\draw [dotted] (0.825,0) -- +(0,1);
\end{scope}
\draw [<-] (0.5,-0.75) -- +(-0.2,0);
\draw [<-] (0.8,-0.75) -- +(0.2,0);
\node at (0.65,-0.75) {$\phi$};
\begin{scope}[xshift=\xnudge,yshift=0.5*\ynudge]
\draw [gray] (0,0.5) -- (0,-0.5);
\draw [gray] (0,0) -- (3,0) node [pos=0,left=1mm] {\color{black}$P$};
\draw [domain=0:3,samples=50] plot (\x,{0.5*sin(180*\x)*sin(180*\x-60)});
\draw [dotted,->] (0,0.125) -- +(3.5,0) node [pos=1,right] {$\avg{P}$};
\end{scope}

\end{tikzpicture}
}{How power is consumed in an AC circuit}

What is happening is that when the power curve is on the up swing, the energy from the voltage source is being consumed by the resistor and reactance. In other words, some of the energy is going into feeding the electric and magnetic fields. On the down swing, this energy is released back to the circuit though the resistor is still consuming energy. On average we are left with just the impact of the resistor---which is the net consumer of power.

By the way, equation \eqref{ac-power} shows explicitly that a capacitor and inductor consume no net power because $\cos(90\dg) = \cos(-90\dg) = 0$.

\label{ex:rcl-circuit}

Clearly our analysis will be fairly challenging for complex circuits, but we will keep it simple (relatively speaking). Consider the RCL circuit in Figure \ref{fig:rcl-circuit}. The components are in series so the impedances add. But we must add them like vectors to take into account the phase differences. We will end up with a Figure like \ref{fig:phasor-calculation}. This diagram assumes a signal frequency of 100 hertz and the RCL values are 33 ohms, 100 microfarads, and 8.2 millihenries respectively. 

\pics[side]{rcl-circuit}{   
\begin{tikzpicture}

\node (v) [nde,label={[label distance=1mm]below:{$V(t) = V_\text{rms} \sqrt{2} \sin(2\pi ft)$}}] at (0,0) {}; 
\draw [acv] (v) circle (0.4) ++(-0.2,0) 
  sin +(0.1, 0.1) 
  cos +(0.1,-0.1) 
  sin +(0.1,-0.1) 
  cos +(0.1, 0.1)
;

\node (r) [nde,label=above:{$R$}] at (-1.2,2) {}; 
\draw [res] (r) +(-0.4,0) -- +(0.4,0);

\node (c) [nde,label=above:{$C$}] at (0,2) {}; 
\draw [cpr] (c) 
  +(-0.4,  0) -- +(-0.1,   0)
  +(-0.1,0.3) -- +(-0.1,-0.3)
  +( 0.1,0.3) -- +( 0.1,-0.3)
  +( 0.1,  0) -- +( 0.4,   0);

\node (l) [nde,label=above:{$L$}] at (1.2,2) {}; 
\draw [ind] (l) +(-0.4,0) -- +(0.4,0);

\draw (v) -| ($(r)+(-1,0)$) -- (r) -- (c) -- (l) -- ($(l)+(1,0)$) |- (v);

\end{tikzpicture}
}{Simple RCL circuit}

%%%%%%

\pics[]{phasor-calculation}{   
\begin{tikzpicture}[scale=0.15]
\def\r{33.0}
\def\c{15.9}% = 1 / 2pi * 100 * 100e-6
\def\l{5.15}% = 2pi * 100 * 8.2e-3

\coordinate (r) at (\r,0);
\coordinate (c) at (0,-\c);
\coordinate (l) at (0,\l);
\coordinate (x) at ($(r)+(c)+(l)$);

\draw [->] (0,0) -- (r) node [right] {$Z_R = \r \unit{$\ohm$}$};
\draw [->] (0,0) -- (c) node [below] {$Z_C = \c \unit{$\ohm$}$};
\draw [->] (0,0) -- (l) node [above] {$Z_L = \l \unit{$\ohm$}$};

\draw [dotted] (0,0) rectangle (x);

\draw [->] (0,0) -- (x) node [right] {$Z_\text{tot}$};
\fill (0,0) circle (0.5mm);

\end{tikzpicture}
}{Phasor calculation}

The total impedance for this series combination is 34.7 $\ohm$ with a phase angle of $-18\dg$. If the signal voltage (RMS) is 10 volts, the current will be 0.29 amps, and the power consumption will be 2.74 watts.

Notice that the voltage across the RCL components are 9.51, 4.59, and 1.48 volts respectively. Clearly these numbers do not add back to the 10 volts from the source. Remember that these individual voltages are the RMS values across the components. If we were to account for the phase differences (the picture would look just like Figure \ref{fig:phasor-calculation}) we do get back to the original 10 volts.

% In between low and high AC frequencies, an RCL circuit will resonate.

One important aspect of a circuit like Figure \ref{fig:rcl-circuit} is that the current flow is dependent on the frequency of the source voltage. When the frequency is high, the inductor has a high reactance which blocks current. At low frequency, the capacitor has high reactance which blocks the current. In the middle, we have a spike in current flow. This is an example of electrical resonance (see Lecture \ref{ch:harmonic-motion}). The inductor acts like the mass, the capacitor acts like the spring, and the resistor is the damping force. Once the current reaches its steady state, the capacitor and inductor require no more power: the energy merely oscillates between the electric and magnetic fields. This leaves the resistor as the only source of impedance. The formula for the resonant frequency of the series RCL circuit is:
\begin{equation} \label{rcl-resonance}
f_0 = \frac{1}{2\pi} \frac{1}{\sqrt{LC}}
\end{equation}
The phase shift also depends on the frequency. A plot of the power consumption of our circuit from Figure \ref{fig:rcl-circuit} is the upper plot of Figure \ref{fig:rcl-resonance}. If we reduce the resistance by a factor of ten we get the plot underneath it.

\pics[side]{rcl-resonance}{   
\begin{tikzpicture}

\begin{scope}
\draw [dotted] (0,0) -- (0,3) node [pos=1,above] {$P$};
\draw [dotted] (0,0) -- (4,0) node [pos=1,right] {$f$};
\node at (2,3) [draw,above=5mm] {$R = 33 \unit{\ohm}$};
\draw plot [smooth,xscale=0.01,yscale=10] coordinates {
(000,0.0000)
(003,0.0012)
(010,0.0126)
(020,0.0455)
(030,0.0882)
(050,0.1697)
(070,0.2268)
(090,0.2621)
(110,0.2829)
(130,0.2947)
(150,0.3007)
(170,0.3029)
(190,0.3025)
(210,0.3001)
(230,0.2964)
(250,0.2917)
(270,0.2861)
(290,0.2800)
(320,0.2701)
(350,0.2597)
(400,0.2417)
};
\draw [dotted] (1.76,3) -- (1.76,-0.1);
\draw (1.76,0.1) -- (1.76,-0.1) node [below] {$f_0$};
\end{scope}

\begin{scope}[yshift=-55mm]
\draw [dotted] (0,0) -- (0,3) node [pos=1,above] {$P \times 10$};
\draw [dotted] (0,0) -- (4,0) node [pos=1,right] {$f$};
\node at (2,3) [draw,above=5mm] {$R = 3.3 \unit{\ohm}$};
\draw plot [smooth,xscale=0.01] coordinates {
(000,0.0000)
(036,0.0180)
(076,0.1087)
(096,0.2238)
(116,0.4616)
(136,0.9924)
(156,2.1019)
(166,2.7461)
(171,2.9561)
(176,3.0303)
(181,2.9601)
(186,2.7742)
(196,2.2427)
(216,1.3266)
(236,0.8249)
(256,0.5569)
(276,0.4022)
(316,0.2409)
(356,0.1627)
(400,0.1148)
};
\draw [dotted] (1.76,3) -- (1.76,-0.1);
\draw (1.76,0.1) -- (1.76,-0.1) node [below] {$f_0$};
%\draw [dotted] (0,1.5) -- (1.45,1.5);
\draw [fill] (1.45,1.5) circle (0.05) -- (2.11,1.5) circle (0.05);
\node at (2.11,1.5) [pin=45:{$\Delta f$}] {};
\end{scope}

\end{tikzpicture}
}{Resonance in the RCL circuit}

The reduction in resistance increases the current flow which increases the overall power consumption of the circuit. But it also sharpens the resonance peak. The range of frequencies for which the power exceed half of its maximum value is called the \jargon{bandwidth} of the circuit. For this RCL circuit the bandwidth is
\begin{equation}
\Delta f = R/L
\end{equation}
A better measure of the sharpness of the peak will normalize for the resonant frequency it surrounds. This is called the \jargon{quality factor} for the circuit. In this example we have
\begin{equation} \label{q-factor}
Q = \frac{f_0}{\Delta f} = \frac{1}{R} \sqrt{\frac{L}{C}}
\end{equation}
This Q-factor is important if we are trying to target a particular frequency with our resonant circuit (in a radio, for example).

% Next week

Next week we will tie up one last loose end in electromagnetic theory. With this last piece, we will see that light is an electromagnetic wave. This will open up the whole non-visible spectrum of frequencies for investigation: radio waves, microwaves, gamma rays, etc. The dark side of this story is that the new theory is in conflict with Newton's laws of motion. Ultimately the resolution is found in Einstein's special theory of relativity. We will end up redefining space, time, mass, momentum and energy before we are done. Finally, we will touch on how relativity theory affects our other long-range force: gravity---which will require the general theory of relativity.
========
26:em-and-relativity
--------
Electromagnetism and Relativity
--------
Read sections 24.1--24.4 and 28.1--28.7, review Lectures \ref{ch:newtons-laws}, \ref{ch:energy}, and \ref{ch:momentum}
--------
% Maxwell's laws predict the existence of EM waves---which travel at the speed of light.

There is a problem in what we have developed so far---the problem is in Ampere's Law \eqref{amperes-law}. It only works if the flow of current is continuous. To see why, consider what happens when we charge a capacitor. If we draw the circle $A$ around the incoming current, Ampere's law tells us that the magnetic field curls around the wire (see Figure \ref{fig:displacement-current}). What Ampere's law does not tell us is which surface to use to determine $I$. No current pierces the dashed surface indicated. Using this surface, we could conclude that there is no magnetic curl at all.

\pics[side]{displacement-current}{
\begin{tikzpicture}
\draw (90:0.2 and 1) arc (90:270:0.2 and 1);
\draw [fill] (1,0) circle (0.15 and 0.75);
\node at (0,-0.3) [pin=225:{$A$}] {};
\draw [line width=1mm] (-1,0) -- (1,0);
\draw [white,line width=0.5mm] (-1.01,0) -- (1,0);
\draw [fill=white,fill opacity=0.8] (-90:0.2 and 1) arc (-90:90:0.2 and 1);
\draw [->] (-0.5,0.2) -- (0.5,0.2) node [pos=0.5,above] {$I$};
\node at (1,0.75) [pin=135:{$\Delta q$}] {};
\draw [dashed] (0,1) -- (2,1) (0,-1) -- (2,-1) (2,0) +(90:0.2 and 1) arc (90:270:0.2 and 1);
\foreach \y in {-0.3,0,0.3} \draw [->] (1.5,\y) -- (2.75,\y);
\draw [dashed,fill=white,fill opacity=0.8] (2,0) +(-90:0.2 and 1) arc (-90:90:0.2 and 1);
\node at (2.75,0) [right] {$\Delta \Phi_\text{ele}$};
\end{tikzpicture}
}{Ampere's law needs Maxwell's correction}

This inconsistency went unnoticed until Maxwell offered a solution in 1861. Physically, we know that if current is flowing into a region without coming out, charge must be piling up somewhere. In Figure \ref{fig:displacement-current} the charge is piling up on the plate of the capacitor. Gauss' law \eqref{gauss-law} tells us that the electric flux is increasing too. Although current doesn't pierce the dashed surface, this flux does. So Maxwell added a correction to Ampere's law by assuming that a changing electric flux will also curl the magnetic field:\footnote{Don't worry: I know this formula is ugly. I only include it for completeness. We won't have to use it in this class.}
\begin{equation} \label{displacement-current}
\sum_\text{loop} B_t \Delta s = \mu_0 \epsilon_0 \frac{\Delta \Phi_\text{ele}}{\Delta t}
\end{equation}
I like to call this \jargon{magnetoelectric induction} to emphasize an analogy to Faraday's law \eqref{faradays-law}.\footnote{Maxwell called the term $\epsilon_0 \Delta \Phi_\text{ele} / \Delta t$ on the right \jargon{displacement current}.} In Faraday's law we see that a changing magnetic field can create an electric one. In Maxwell's correction \eqref{displacement-current} we see that a changing electric field can create a magnetic one.

Maxwell took this one step further. Prior to Maxwell, physicists had suspected a connection between light and electromagnetism. He was able to show that his additional term implied that the electromagnetic field could act as a medium supporting a wave. The energy of the wave resonates back and forth between the electric field and the magnetic field, like an RCL circuit without the circuitry.

He calculated the speed of this wave as
\begin{equation} \label{em-speed}
c = \sqrt{\frac{1}{\mu_0 \epsilon_0}} = \sci{2.998}{8}
\end{equation}
which is the speed of light.\footnote{Equation \eqref{em-speed} shows that Maxwell's correction \eqref{displacement-current} is on the order of $1/c^2$. We will see in a bit that this should be considered a relativistic correction.} So with one minor modification Maxwell completed electromagnetic theory and derived a wave theory of optics. For this, these equations are now collectively called \jargon{Maxwell's equations}.

In general, the energy density of the electromagnetic field is given by 
\begin{equation} \label{em-energy}
u = \half (\epsilon_0 E^2 + B^2/\mu_0)
\end{equation}
for which equations \eqref{capacitor-energy} and \eqref{inductor-energy} are special cases. Notice how the energy is proportional to the square of the field magnitude similar to \eqref{energy-and-amplitude}. 

%In addition, the flow of energy is given by
%\begin{equation} \label{poynting-vector}
%S = \frac{1}{\mu_0} EB \sin \theta
%\end{equation}
%in the direction perpendicular to both the electric and magnetic fields. 
%
%The field also carries momentum. One consequence of Maxwell's equations is that the electromagnetic influence occurs at the speed of light.\footnote{This is true always not just with electromagnetic radiation.} If a charge moves here, the charge over there will move, but with a time delay. During this time frame, momentum is not conserved unless we attribute it to the field. The momentum density (momentum per unit volume) in the EM field is simply
%\begin{equation} \label{em-momentum}
%p / V = S / c^2
%\end{equation}
%It can also be shown that the electric field can transport stress.
%%EM stress: $T_{ij} = \epsilon_0 (E_i E_j - \half \delta_{ij}E^2) + (B_i B_j - \half \delta_{ij} B^2) / \mu_0$

% The intensity of an EM wave is very simply related to the energy density in the wave.

But for the special case of electromagnetic waves, the electric and magnetic fields are perpendicular to each other. In addition, the magnitude of the fields are related by $E = cB$. The oscillation of the fields are transverse and they are perpendicular to flow of energy.\footnote{The polarization of the wave is usually defined by the direction of the electric field.} In fact, the intensity of the radiation is given by\footnote{Compare this intensity calculation with that in Lecture \ref{ch:waves-radiation}.}
\begin{equation} \label{em-intensity}
I = P/A = cu = \half c \epsilon_0 E^2
\end{equation}
The factor of one-half is there because the electric field is oscillating. The value of $E$ represents the amplitude or peak value of the wave.

% Whenever a charged particle is accelerated it will radiate electromagnetic energy.

\pics[side]{larmor-formula}{
%$S = \frac{1}{4\pi \epsilon_0} \left( \frac{q^2}{4\pi c^3} \right) \frac{a^2 \sin^2 \theta}{r^2}$
\begin{tikzpicture}
%\tikzstyle {fieldline} = [smooth,variable=\q,samples at={0,-5,...,-360}]
\clip (-2,-2) rectangle (2,2.5);
\def\r{sqrt(pow(sin(\q),2)/\s)}
\def\x{\r*cos(\q)}
\def\y{\r*sin(\q)}
%\foreach \s in {0.25} \draw [fieldline,dotted] plot ({\x},{\y});
\def\s{0.25}
\foreach \q in {15,30,...,165,195,210,...,345} \draw [->] (0,0) -- ({\x},{\y});
\draw [->] (1,0) -- (1.5,0) node [pos=1,right] {$a$};
\draw [fill=black] (0,0) circle (0.1);
\end{tikzpicture}
}{Radiation pattern from a charge accelerating to the right (or left)}

This electromagnetic radiation occurs whenever a charged particle accelerates. Most of the energy is distributed perpendicular to the direction of the acceleration as in Figure \ref{fig:larmor-formula}. The total power radiated is given by \jargon{Larmor's formula}:
\begin{equation} \label{larmor-formula}
P = \frac{a^2 q^2}{6\pi \epsilon_0 c^3}
\end{equation}
where $q$ is the magnitude of the charge and $a$ is its acceleration. It is this formula which predicts the death spiral of the electron that we mentioned in Lecture \ref{ch:classical-limits}.

% Visible light is only a small portion of the total electromagnetic wave spectrum.

One of the most dramatic consequences of Maxwell's discovery of electromagnetic waves was the opening up of the entire non-visible spectrum. Shortly afterward Hertz confirmed this by generating and capturing radio waves which sit on the lower frequency end of visible light. High energy sources like quasars and nuclear radiation produce EM waves that sit on the higher end of the frequency spectrum.

By equation \eqref{larmor-formula} any wire with alternating current will generate EM radiation. Similarly, any wire will react to EM radiation. This is the basic physics behind any wireless technology (radio, TV, router, cell phone, etc.) Typically, the electromagnetic fields associated with EM waves are so feeble that some sort of amplification is required to pick up these signals. This is why sometimes a lightening strike will cause electrical interference. The use of frequency bands are regulated to avoid having people interfere with one another's electronics.

Since the acceleration of the charges is related to the frequency squared (cf. Lectures \ref{ch:induction-and-ac} and \ref{ch:harmonic-motion}), the power radiated increases with the fourth power of the AC frequency. This is why the sky is blue. As light from the sun passes through the atmosphere, it causes the atoms of the atmosphere to oscillate back and forth. This motion causes EM waves to re-radiate---perpendicular to the motion of the original radiation. This effect occurs at the highest end of the spectrum most, which is the blue end of the solar spectrum.

% The speed of light is the same regardless of who measures it or where it comes from.

Clearly we could go much deeper into the study of electrodynamics, but here we stop. We now turn to discuss special relativity. Although relativity was uncovered through the study of electromagnetism,\footnote[-0.25in]{Einstein's paper in 1905 was titled ``On the electrodynamics of moving bodies''.} Einstein saw that the consequences were not just isolated to electromagnetic theory but stuck at the very foundation of Newtonian mechanics.

% In relativity, the fundamental measurements of space, time, and mass are affected by motion.

Most explanations of relativity start with a \jargon{light clock} and so will ours. Imagine a thin tube with mirrors on the ends in which a light pulse is bouncing back and forth. Orient it vertically and allow it to move to the right with constant speed. The trajectory of the light pulse as it bounces from bottom to top forms a triangle as in Figure \ref{fig:light-clock}. This innocuous looking diagram is the Trojan horse of relativity. All of our troubles begin with the following argument. 

\pics[side]{light-clock}{
\vspace{-1in}
\begin{tikzpicture}
\def\dx{3}
\def\dt{6}
\def\v{0.5}

\node (0) [light box,dashed] at (0,0) {};
\node (1) [light box] at (\v*\dt,0) {};
\node (a) at (0.south) [event] {};
\node (b) at (1.north) [event] {};

\draw [->-] (a) -- (b) node [pos=0.5,above left] {$ct$};
\draw [brace] (-\bracenudge,0) +(0.south) -- +(0.north) node [brace note hi] {$ct_0$};
\draw [brace] (0,-\bracenudge) +(0.south) -- +(1.south) node [brace note lo] {$vt$};

\end{tikzpicture}
}{Light clock and time dilation}

Light travels with constant speed, so the height of the clock is related to the time it takes for light to travel up the clock by $ct_0$. But if the clock is moving to the right, the trajectory of the light runs up the hypotenuse of the triangle in Figure \ref{fig:light-clock}. The distance it moves to the right is $vt$ where $t$ is the time it takes the light pulse to hit the top of the clock. Clearly $t > t_0$. In fact, we have
\begin{equation} \label{light-clock}
(ct)^2 = (ct_0)^2 + (vt)^2
\end{equation}
which can be rewritten as
\begin{equation} \label{time-dilation}
t = t_0 / \sqrt{1 - v^2/c^2}
\end{equation}
Which is called the \jargon{time dilation} formula because the moving clock ticks slower.

Hopefully you are saying to yourself, ``Slow down---how can such a simple set-up lead to such a sweeping statement about the nature of time itself?'' There is one thing that makes this argument special: we are using light. If this were a bullet from a gun, the speed in the vertical direction would be unaffected by the horizontal motion. The two velocities would add (as vectors). This is an application of the principle of relativity: the bullet would take the same amount of time to cross the distance regardless of the horizontal motion.

But this is light---which only moves at the speed of light. Now, the same is true of sound: it travels at a certain speed through to its medium (air). But light is different because it always travels at the speed of light no matter what. This is what makes the Michelson-Morley null result so important. It shows that light is not like a sound wave.

Though many physicists realized that something was up, Einstein saw the heart of the issue. If light speed is the same no matter the frame of reference used, then the principle of relativity forces us to conclude that time is an individual phenomena. My time is not the same as your time---though they are related through equation \eqref{time-dilation}.

Suppose we span the distance $L_0 = vt$ with a stick. From the perspective of an observer moving with the clock, this stick is traveling the opposite direction with the same speed so $L = vt_0$. Since the times are related via equation \eqref{time-dilation}, the measured lengths are related via
\begin{equation} \label{length-contraction}
L = L_0 \sqrt{1 - v^2/c^2}
\end{equation}
Since $L < L_0$, this is called \jargon{length contraction}. In relativity, motion shrinks space and slows down time.

An objection may occur to you. If I think the moving ruler is shorter, won't the moving observer think my ruler is longer? This contradicts equation \eqref{length-contraction}. The resolution is that the moving observer will not think my measurement is valid due to another relativistic phenomena called \jargon{desynchronization}.

Whenever we measure the length of an object in motion, we have to make sure that we mark the edges at the same time. But moving observers disagree on which events are simultaneous. Suppose we flash a light from the exact center of our ruler. We wait for the beams to bounce and return to center. Based on this duration and the speed of light, we calculate the length. But the moving observer sees something like Figure \ref{fig:desynch}. The back end of the ruler runs into the light beam at event $A$. The front end of the ruler is running away and event $B$ occurs later. But I claim that the length of the ruler is the distance between these two points. The moving observer thinks, ``Of course you think your ruler is longer---you are cheating. Your ruler is actually shorter by \eqref{length-contraction}, but the time lag of $vL/c^2$ in your measurements overcompensates by a factor $1/(1 - v^2/c^2)$.''

\pics[side]{desynch}{
\begin{tikzpicture}
\def\dx{3}
\def\dt{1}
\def\v{0.3}

\coordinate (0) at (0,0);
\coordinate (v) at (\v*\dt,\dt);
\coordinate (+c) at (\dt,\dt);
\coordinate (-c) at (-\dt,\dt);

\node (box) [ruler,dashed] at (0) {};
\coordinate (a) at (box.west);
\coordinate (b) at (box.east);

\coordinate (1) at (intersection of a--{$(a)+(v)$} and 0--{$(-c)$});
\coordinate (2) at (intersection of b--{$(b)+(v)$} and 0--{$(+c)$});
\coordinate (3) at (intersection of 1--{$(1)+(+c)$} and 2--{$(2)+(-c)$});

\node (box) [ruler] at (3) {};
\coordinate (c) at (box.west);
\coordinate (d) at (box.east);

\draw (0) -- (1) -- (3) -- (2) -- cycle;
\draw [dashed] (a) -- (c) (b) -- (d);

\foreach \i in {0,1,2,3} \node [event] at (\i) {};
\node [label=0:{$A$}] at (1) {};
\node [label=180:{$B$}] at (2) {};
%\draw [dotted] (1) rectangle (2);

\draw [->] (-\bracenudge,0) ++($(a)!0.5!(c)$) -- +(0,1cm) node [above] {$t$};

\end{tikzpicture}
}{Clocks separated in space are desynchronized}

All of these effects are summarized in the \jargon{Lorentz transformation} which translates the space-time measurements between moving observers. If an observer is moving with velocity $v$ relative to you, her measurements are related to yours according to
\begin{gather} \label{lorentz-transformation}
x' = \gamma (x - vt) \qquad t' = \gamma (t - vx/c^2)
\end{gather}
where $\gamma = 1/\sqrt{1 - v^2/c^2}$. This is sometimes called the \jargon{Lorentz factor} and is the hallmark of relativity. We can neglect relativistic effects when $\gamma$ is close to one. Even when $v$ is 10\% the speed of light, $\gamma$ is within 0.5\% of one.

These equations are fundamental and affect every other calculation in mechanics you have learned so far. In particular, the velocity of an object as measured in the moving frame will be
$$u' = \frac{\Delta x'}{\Delta t'} = \frac{\gamma (\Delta x - v \Delta t)}{\gamma (\Delta t - v\Delta x / c^2)} = \frac{u - v}{1 - uv/c^2}$$
Without relativity, we would simply subtract the motion of the observer from our measurements like $u' = u - v$, but the desynchronization effect in the denominator changes how the velocity measurements interact.

This is also one of the ways we can see why no object can move faster than light. If we start with an object moving at velocity $v$ and increment the velocity by an amount $u$ (less than the speed of light), the final speed is given by
\begin{equation} \label{velocity-addition}
u' = \frac{u + v}{1 + uv/c^2}
\end{equation}
which will always be less than light speed.\footnote[-0.5in]{Here's the proof. Both $u$ and $v$ are less than $c$. Thus $c - u$ and $c - v$ are both greater than zero and so is their product. Rearranging this inequality we can say 
$$c^2(1 + uv/c^2) > c(u + v)$$
Rearrange again and the conclusion follows.}

One hidden consequence of equations \eqref{lorentz-transformation} is that between any two events, the combined quantity 
\begin{equation} \label{spacetime-interval}
I = (c \Delta t)^2 - \Delta x^2
\end{equation}
is the same for both observers.\footnote{The converse is also true: equations \eqref{lorentz-transformation} are the only linear combinations which preserve this quantity.} This \jargon{space-time interval} is truly the best representation of how space and time are united and intertwined in relativity theory. Investigating the geometry associated with this interval offers a way of viewing the theory that is illuminating and mitigates the feeling of a cosmic conspiracy that time dilation, length contraction and desynchronization generate.

% Relativistic energy is relativistic mass and is conserved in all collisions (inelastic or not).

Since velocities don't work the way we are used to in relativity, is it any surprise that momentum and energy don't either? The most egregious situation is that the conservation of our friend $mv$ is no longer invariant. For example, if the total momentum is zero in the center of mass frame, it will not be conserved in the lab frame because of the way velocities combine in equation \eqref{velocity-addition}.

Fortunately, it can be shown that the conservation of $\gamma mv$ is invariant.\footnote{The proof is straightforward, but a bit laborious. You will need to know that $$\gamma_{v'} = \gamma_u \gamma_v [1 + uv/c^2]$$} This is called the \jargon{relativistic momentum} and clearly reduces to the classical definition of momentum when $v \ll c$. However, in order for relativistic momentum to be conserved we must also have $\gamma m$ conserved. This may seem odd until one runs through the classical version of this argument and notices that it requires $m$ to be conserved. So in order for this relativistic argument to work we must redefine both momentum and mass.

The quantity $\gamma m$ is frequently called \jargon{relativistic mass}, though this usage has gone out of favor.\footnote{Although in his physics lectures, Feynman makes the claim that all of relativity can be derived from this one formula. Actually, the idea of relativistic mass goes back to Einstein himself. It's pretty easy to start a flame war on physics related websites nowadays just by bringing up the topic.} The main reason is that guessing at a relativistic formula by simply replacing $m$ with $\gamma m$ in most classical formulas won't work. The preferred approach is to multiply this quantity by $c^2$ and call it \jargon{relativistic energy} and use $m$ only to refer to the mass of an object measured from rest (i.e., its \jargon{rest mass}). Since $\gamma mc^2$ is in units of energy, we are okay to call it this but there is an even better reason. 

Using the binomial theorem \eqref{binomial-theorem} we have
\begin{equation} \label{gamma-approx}
\gamma = (1 - v^2 / c^2)^{-1/2} \approx 1 + \half v^2/c^2
\end{equation}
This is a useful approximation to be aware of it its own right. But is also means we can say
$$E = \gamma mc^2 = mc^2 + \half mv^2 + \ldots$$
The first term is a constant and is called the \jargon{rest energy} of the particle since it doesn't go away even if the particle is at rest. The second term is our friend kinetic energy. The remaining terms are relativistic corrections to this kinetic energy formula.\footnote[-0.25in]{If you are interested, the next term happens to be $\tfrac{3}{8}mv^4/c^2$.} A second verification of this approach is possible by calculating the work required to relativistically accelerate a particle from rest. If we use $p = \gamma mv$, then the total work done on the particle is\footnote{Unfortunately, I know of no non-calculus technique of deriving this equation. If you think of one, let me know!}
$$KE = (\gamma - 1)mc^2$$
which is the same way we derived the $\half mv^2$ formula in classical mechanics.

We continue to call a collision elastic if it conserves kinetic energy. But notice that in relativity the total energy $\gamma mc^2$ is conserved even in inelastic collisions.

Consider two identical particles that are flying toward one another with equal and opposite velocities. Suppose they each are moving fast enough to have a Lorentz factor of $\tfrac{3}{2}$ so the total energy of the system is $3mc^2$. If they collide and stick (completely inelastic collision), the composite still has this energy. But now it is at rest (net momentum is zero) with a Lorentz factor is one. It follows that the rest mass of the composite is $3m$---the mass of the object continues to hold the incoming kinetic energy.

The reverse of this process works too. This connection between mass and energy is completely unexpected in classical mechanics and is one of the reasons why $E = mc^2$ is so famous. We can calculate the energy locked in the nucleus of the atom by comparing the mass of the composite atom with the mass of its parts. Multiply this difference by $c^2$ and the number of atoms in a kilogram of uranium and you end up with a very big number.

Occasionally in relativity problems you know the energy and momentum of a particle and need to determine the velocity. One shortcut to use is
\begin{equation} \label{energy-momentum-velocity}
Ev = pc^2
\end{equation}
which completely skips the need to deal with $\gamma$ in the calculation.\footnote{This implies that the energy and momentum of a light pulse are related through $E = pc$. Plugging this into the next equation \eqref{energy-momentum-mass} yields $m = 0$. This is why we say a photon has zero rest mass even though a photon is never actually at rest. Reversing the argument works too, so anything with ``zero rest mass'' can only move with the speed of light.} Another useful connection between these concepts is
\begin{equation} \label{energy-momentum-mass}
E^2 - p^2 c^2 = m^2 c^4
\end{equation}
This equation is more important than it looks. This is because it parallels equation \eqref{spacetime-interval} with energy connected to time and momentum connected to space. If we were to dive down the rabbit-hole, we would combine energy and momentum into a single four-vector called \jargon{four-momentum}. Similar to the way distance and duration are ``projections'' of the space-time interval, the energy and momentum of a particle are the ``projections'' of this relativistic four-momentum. They are dilated, contracted, and mixed via the Lorentz transformation \eqref{lorentz-transformation} just like space and time.

% Magnetism may be thought of as a relativistic shadow of the electric force.

Though we have covered a lot, one obvious gap is left: Newton's second law. The gap is not as critical as it seems because most applications of relativity involve the analysis of collisions for which energy and momentum are sufficient. On the other hand, the means of relativistically correcting a particular force law is not an easy problem. 

But we already know that electromagnetism is a relativistic theory. One insight that relativity brings to electromagnetism is that the electric force and the magnetic force are not just intertwined, but can be considered as ``projections'' of a four-dimensional electromagnetic force. In a similar way to how energy and momentum are ``shadows'' of a relativistic four-momentum, the electric and magnetic forces are the ``shadows'' of electromagnetism on time and space, respectively.\footnote[-0.75in]{The two forces also mix together in formulas similar to the Lorentz transformation \eqref{lorentz-transformation}. This implies that a force we consider magnetic in one frame may be considered to be electric in another. This fact was what Einstein originally considered as the main theoretical support for relativity.} Though a bit more complicated because we are talking about combining two vectors into some four-dimensional tensor, this approach radically simplifies the equations of electromagnetism.

We have already made the point that fundamentally all the other macroscopic forces (except gravity) are electromagnetic in origin. So in principle, all that's left is a lot of calculations.\footnote[-0.5in]{This is extremely unfair, of course. The complexities of how electromagnetism manifests itself as elastic, friction, tension, and other forces depends upon a perfect understanding of the nature of matter. Until that project is done, this statement is untrue.}

% General relativity...

Then there is gravity. One key element of any relativistic force law is that its speed of influence cannot exceed the speed of light. So we know right away that Newton's law of gravity \eqref{n4l} is wrong. Einstein had the fundamental physical insight in 1907 to solve the problem. It took him another eight years to struggle through the math and find the correct theory which we call \jargon{general relativity}.\footnote{This branch of mathematics is now known as differential geometry.} This was an experience he never forgot and is why  \href{http://en.wikiquote.org/wiki/Albert_Einstein\#1940s}{he wrote} the following statement in a 1943 letter that may seem incredible to you:
\begin{quote}
Do not worry about your difficulties in mathematics. I can assure you mine are still greater.
\end{quote}
Einstein's physical insight is now called the \jargon{equivalence principle} and is the simple recognition that a reference frame accelerating under the influence of gravity (in free-fall) is inertial. Mathematically this is because the mass in Newton's second law \eqref{n2l} is the same as the mass in the law of gravity \eqref{n4l}. So everything accelerates together in tandem. Einstein saw that this special property allows one to generalize the principle of relativity to include frames in free-fall.

Here's the trick: we know how to correct Newton's laws in the freely falling frame---use special relativity. What we need to know is how to transform these corrections out of the free-fall frame to one on the ground. The answer is to replace the space-time interval in equation \eqref{spacetime-interval} with the \jargon{Schwarzschild metric}:\footnote{Confession: This is the basic idea, but I've cheated here. We need to take into account the polar coordinates used to derive this formula by replacing $x$ with $r$ and we need to add a couple of terms. For the full meal deal see \href{http://en.wikipedia.org/wiki/Schwarzschild_metric}{Wikipedia}.}
\begin{equation} \label{schwarzschild-metric}
I(r) = \left( \frac{r-r_s}{r} \right) (c \Delta t)^2 - \left( \frac{r}{r-r_s} \right) \Delta x^2
\end{equation}
where $r_s = 2GM/c^2$ and is called the \jargon{Schwarzschild radius}. This length is the characteristic distance in which general relativistic effects are important. For the Sun it is three kilometers which is negligible on an astronomic scale. The Schwarzschild radius represents the distance at which light is captured by an object and therefore represents the effective radius of a \jargon{black hole}. A black hole need not be massive: it must be very dense. If we could compress the mass of the Earth below a radius of nine millimeters, general relativity would take over and it would collapse into a black hole.

For any stationary clock $\Delta x = 0$ and the space-time interval equals $(ct_0)^2$ where $t_0$ is the proper time measured by the clock. Because of the factors in the Schwarzschild metric \eqref{schwarzschild-metric}, a stationary clock in a gravitational well will tick slower than one in deep space (\jargon{gravitational time dilation}). We have
\begin{equation} \label{grav-time-dilation}
t_0 = t \sqrt{1 - \frac{2GM}{rc^2}} \approx t - \frac{GM}{rc^2}
\end{equation}
This effect is directly confirmed in the delay of \href{http://en.wikipedia.org/wiki/Shapiro_effect}{radar beams bounced off Venus} and in \href{http://en.wikipedia.org/wiki/Pound-Rebka_experiment}{gravitational red-shift}. It can also be used to see that the speed of light appears to slows down as it approaches the Schwarzschild radius of a black hole.\footnote{Any object falling into a black hole will appear to slow down. In fact it will never appear to cross the Schwarzschild radius. From the object's point of view there is nothing unusual---it just falls, but the outside world never sees anything after this line is crossed. This is why this radius is also called the \jargon{event horizon} of the black hole.} This change in speed can deflect light (like refraction through variable media---see Lecture \ref{ch:geometric-optics}). This prediction and its dramatic confirmation in the eclipse of 1919 launched Einstein to world-wide fame.

I've left a lot out (obviously) including gravitational waves, cosmology, and how this is all related to ``curved spacetime''. For a few more insights review the end of Lecture \ref{ch:celestial-mechanics} and \ref{ch:elasticity}, but here we must stop.

Next week we make a complete shift in gears to talk about quantum mechanics. We have already discussed (Lectures \ref{ch:kinetic-theory} and \ref{ch:classical-limits}) how cracks in our understanding of the very small began to appear around 1900. We will talk about how these issues were resolved over the following 50 years through an understanding of the wave nature of matter. We will also touch on the difficulties and the ultimate success of creating a quantum theory of electrodynamics.
========
27:quantum-mechanics
--------
Quantum Mechanics
--------
Read sections 29.1--29.6 and review Lecture \ref{ch:classical-limits}
--------
%\begin{quote}
%Perhaps I'm old and tired but I always think that the chances of finding out what really is going on are so absurdly remote that the only thing to do is to say hang the sense of it and just keep yourself occupied. \par 
%\hfill Douglas Adams, \textit{Hitchhikers Guide to the Galaxy}%, Ch 30
%\end{quote}

We've already discussed some of the reasons why physicists around 1900 were beginning to witness the breakdown of classical physics. Shortly after relativity made us adjust our understanding of the fast and energetic, a much larger attack was made on our understanding of the very small. If you thought relativity was mind-blowing, you might want to sit down now.

In Lecture \ref{ch:classical-limits} we discussed how Planck and Einstein were driven by experiment to postulate a particle theory of light (in flat contradiction to classical electromagnetism). The energy relationship for the photon is given in equation \eqref{photon-energy} as $E = hf$ where $f$ is the frequency of the light. Einstein showed how this relationship could make sense out of the ultraviolet catastrophe and the photoelectric effect.

The next step down the road to quantum mechanics was taken in 1924 by Louis de Broglie. His argument was basically: if photons have both wave and particle properties, then maybe electrons do too. Since the momentum of a photon is given by $p = E/c$ and $f\lambda = c$ for any wave, we have $p = h/\lambda$ for the photon. He postulated that the electron (and any other material particle) must have an associated wavelength of
\begin{equation} \label{debroglie-wavelength}
\lambda = h/p
\end{equation} 
This is known as the \jargon{de Broglie wavelength} of the particle and characterizes its \jargon{matter wave}.\footnote{Though ``matter field'' might be a more appropriate term.}

At the time, understanding the structure of the atom was the hot topic of the day. De Broglie's hypothesis made sense out of some of the results seen at the time. We will return to this topic in the next lecture. More direct evidence for the wave nature of matter is available now in \href{http://en.wikipedia.org/wiki/Neutron_diffraction}{neutron diffraction} experiments and the \href{http://en.wikipedia.org/wiki/Double-slit_experiment\#Importance_to_physics}{electron double-slit experiment}.

\pics[]{tunneling}{
\def\a{1}
\def\b{16}
\begin{tikzpicture}[xscale=3/\b]
\draw [domain=-\b:-\a,samples=50,smooth] plot (\x,{0.5000*cos(180*\x/pi+102)});
\draw [domain=-\a:\a] plot (\x,{0.1300*exp(-\x)});
\draw [domain=\a:\b,samples=50,smooth] plot (\x,{0.0677*cos(180*\x/pi+348)});

\draw (-\b,-1) -| (-\a,1) -| (\a,-1) -- (\b,-1);
\draw [->,dotted] (-1.2*\b,0) -- (1.2*\b,0) node [right] {$E$};
\end{tikzpicture}
}{Quantum tunneling through a potential energy barrier}

One important consequence of the wave nature of matter is \jargon{quantum tunneling}. Consider Figure \ref{fig:tunneling}. A classical particle with kinetic energy $E$ approaches a potential energy barrier of twice this energy. Classically, we expect the particle to ``bounce'' off of this barrier. However, a wave will propagate into such a barrier though with exponentially decreasing amplitude we called this ``attenuation'' in Lecture \ref{ch:physical-optics}. If the barrier is small enough, there may be enough amplitude left for a small amount of this wave to be transmitted through the barrier. 

This is the explanation behind natural radioactivity. The protons are bound together by the strong nuclear force (see Lecture \ref{ch:nuclear-energy}) which creates a potential well for the nucleus. But outside the nuclear range, the protons are repelled by their electrostatic repulsion. This combination of the forces produces a barrier through which, occasionally, some of the nuclear content escapes.

Overall, De Broglie's theory is suggestive but incomplete. The \jargon[Schroedinger wave equation]{Schr\"{o}dinger wave equation} published in 1926 is what we seek:
\begin{equation} \label{schrodinger}
-\frac{\hbar^2}{2m} \pdd{\psi}{x} = (E - V) \psi
\end{equation}
where $\hbar = h/2\pi$. This form of the equation assumes the potential energy $V$ is constant so the physical system is in a standing wave mode---like a stable atom. The one-dimensional solution to this equation is
\begin{equation} \label{schrodinger-solution-wave}
\psi = A \cos(\pm kx + \phi) \quad \text{with} \quad \hbar k = \sqrt{2m(E-V)}
\end{equation}
unless $E < V$ in which case the solution is
\begin{equation} \label{schrodinger-solution-decay}
\psi = A \exp(\pm kx + \phi) \quad \text{with} \quad \hbar k = \sqrt{2m(V-E)}
\end{equation}
These are the formulas used to generate Figure \ref{fig:tunneling}. These standing waves oscillate with a frequency $f = E/h$.

By its very nature, a wave is extended in space. It is possible to ``localize'' these waves by combining them with different but similar wavelengths (similar to the Fourier analysis in Lecture \ref{ch:waves-interference}). This means that for waves there is an inverse relationship between the position and wavelength. But the wavelength of our matter waves is connected to the momentum of the particle via \eqref{debroglie-wavelength}. The \jargon{Heisenberg uncertainty principle} summarizes this relationship as
\begin{equation} \label{heisenberg}
(\Delta x)(\Delta p) \ge \hbar/2
\end{equation}
The uncertainty principle shows that identifying the exact trajectory of a quantum particle is doomed to failure.\footnote{Although there is an interesting approach to quantum mechanics by David Bohm which claims to do just that.} The more we localize the particle, the greater the uncertainty in its momentum. In other words, the more we know about where it is, the less we know about where it will be. 

So, in quantum mechanics the matter wave is primary. But what exactly is $\psi$? Some insight into this question can be gained by revisiting the photoelectric effect. The intensity of the radiation is
$$I = nhf/t$$
This is simply the total energy per photon ($hf$) multiplied by the number of photons per second ($n/t$). This is the particle viewpoint. From the standpoint of electromagnetism, the intensity is given by equation \eqref{em-intensity}. Setting these two equations equal to each another yields
$$nhf/t = \half c \epsilon_0 E^2$$
Remember that $E$ in this case represents the peak value of the electric field. As the photon is related to the electromagnetic field, so the electron is related to its matter wave. In other words, it seems reasonable to assume that the square of the wave amplitude is proportional to number of particles present. If we are talking about a single particle, then this value must represent the probability of finding the particle at that location in an experiment. In symbols,
\begin{equation} \label{qm-wave-squared}
\rho \propto \psi^2
\end{equation}
where $\rho$ is the probability density of locating the particle at this point in space. Of course, the sum of all these probabilities must be one.

We will explore how the matter wave works in the context of the atom in the next lecture. We will also get a hint of how quantum mechanics provides physical foundation for chemistry and solid state physics. But before we do, an obvious question has probably occurred to you. What about relativity? Oddly enough, there are significant conceptual difficulties in building a relativistic quantum theory. It took physicists 20 years to untangle this Gordian knot and a trio of men (Tomonaga, Schwinger, and Feynman) received the \href{http://nobelprize.org/nobel_prizes/physics/laureates/1965/}{Nobel Prize in 1965} for it.\footnote{Feynman's \href{http://nobelprize.org/nobel_prizes/physics/laureates/1965/feynman-lecture.html}{Nobel Lecture} is an interesting recounting of some of his journey to unlocking these mysteries.}

\jargon[quantum field theory]{Quantum field theory} (QFT) is the result of combining quantum mechanics and special relativity. In both there is a standard recipe for ``graduating'' or generalizing our classical models.

In special relativity we replace our notions of space and time with space-time and recognize that both distance and duration are merely components of the space-time interval between the two events. In addition, pairs of mechanical quantities are combined in an analogous way---in particular, energy and momentum are related according to $E^2 = p^2 c^2 + m^2 c^4$ \eqref{energy-momentum-mass} which replaces the Newtonian relationship $KE = p^2/2m$.

In quantum mechanics we replace the notion of an elementary particle with its ``wave-function'' $\psi(x)$ which can be used to calculate all of the mechanical quantities related to this quantum particle. In particular, the momentum of the particle is related to the slope of the wave and the energy is related to its rate of change. In symbols:
\begin{equation} \label{quantum-recipe}
p(\psi) = -i\hbar \pd{\psi}{x} \qquad E(\psi) = i\hbar \pd{\psi}{t}
\end{equation}
Starting from 
$$p^2/2m = KE = E - V$$
 yields Schr\"{o}dinger's equation \eqref{schrodinger}.

The most natural combination of these two recipes starts with the relativistic equation \eqref{energy-momentum-mass} and imposes the quantum recipe to yield
\begin{equation} \label{klein-gordon}
\frac{1}{c^2}\pdd{\psi}{t} -\pdd{\psi}{x} + \frac{m^2 c^2}{\hbar^2} \psi = 0
%-\hbar^2 \pdd{\psi}{t} = -\hbar^2 c^2 \pdd{\psi}{x} + m^2 c^4 \psi
\end{equation}
which is now known as the \jargon{Klein-Gordon} wave equation. However, this equation can be shown to yield negative probabilities for the location of the quantum particle. This makes interpreting this probability density problematic.

The correct conclusion is that there is no such thing as a quantum field theory for a single particle.\footnote[-0.5in]{It seems almost irreverent to skip Dirac's theory of the electron here. But it is truly a logical sidebar to our main point. In a way, Dirac exploits a loophole in the previous logic which delays but in the end does not deny the final conclusion. Of course we need Dirac's electron (i.e., the electron is a spinor field), but not as a motivation for QFT.} The reality is that the analysis of any high energy system must take into account the possibility of secondary creation and annihilation events. In quantum field theory, every problem is a many-body problem. We now know how to deal with that (given some reservations)---we have Feynman diagrams.

A typical Feynman diagram looks like Figure \ref{fig:feynman-diagram}. This is a space-time diagram with time flowing up the page. The lines represent electrons and the squiggly line is a photon. The black dots at the beginning and end are the actual events measured in the lab. The white dots in the middle are called ``virtual'' in the sense that they are not actually observed---the photon exchange is unseen so it is called a \jargon{virtual photon}. In quantum field theory, the electromagnetic force is mediated by the exchange of these virtual photons.

\pics[side]{feynman-diagram}{
\vspace{-1cm}
\begin{tikzpicture}[scale=2]
%\draw [fill=black!10] (-1.2,-1.2) rectangle (1.2,1.2);
\draw [->] (-1,-1) -- (1,-1) node [pos=0.5,below=1mm] {Space ($x$)};
\draw [->] (-1,-1) -- (-1,1) node [pos=0.5,sloped,above=1mm] {Time ($t$)};
\node (a1) [actual]  at (-0.6,-0.8) {};
\node (b1) [actual]  at ( 0.6,-0.8) {};
\node (a2) [actual]  at (-0.4, 0.8) {};
\node (b2) [actual]  at ( 0.8, 0.8) {};
\node (a3) [virtual] at (-0.2, 0.1) {};
\node (b3) [virtual] at ( 0.4,-0.1) {};
%\path (a1) edge [electron] node [pin=-45:{Electron}] {} (a3)
%      (a3) edge [electron] (a2);
%\path (b1) edge [electron] (b3)
%      (b3) edge [electron] (b2);
%\path (a3) edge [photon] node [pin=90:{
%\begin{minipage}{15mm}
%\centering
%Virtual Photon
%\end{minipage}
%}] {} (b3);
\path (a1) edge [electron] (a3)
      (a3) edge [electron] (a2);
\path (b1) edge [electron] (b3)
      (b3) edge [electron] (b2);
\path (a3) edge [photon] (b3);
\end{tikzpicture}
}{A typical Feynman diagram}

\jargon[quantum electrodynamics]{Quantum electrodynamics} (QED) is the application of quantum field theory to the electromagnetic force. The photon is governed by Maxwell's equations and the electron is described by the formula discovered by Dirac in 1928. Feynman calls it the ``crown jewel'' of physics and it is the most accurate physical theory in history---confirmed by experiment within  \href{http://en.wikipedia.org/wiki/Precision_tests_of_QED}{ten parts per billion}.

The nice thing about these Feynman diagrams is that you can actually see the electrons exchanging the photon. In fact, the diagram is so suggestive, it is important to emphasize what it is not. It does not represent the actual interaction between the electrons---it is a book-keeping tool used to calculate the interaction. The diagram represents a whole class of similar diagrams with the unobserved virtual events located in different places. Truly anything goes as long as the initial and final events are the same.

Each Feynman diagram is used to calculate a complex number with an angle proportional to the total action of the diagram (using the Lagrangian from classical mechanics). Those diagrams representing situations far from the classical prediction typically cancel out. In this way, Feynman found justification for the classical principle of least action. The diagrams also show us a practical method of correcting our classical predictions by including those diagrams close to the classical result.

This correction is more difficult than it may appear. Simply calculating the probability involved in one electron traveling from point A to point B involves an infinite number of diagrams (see Figure \ref{fig:anything-goes}).

\pics[]{anything-goes}{
\begin{tikzpicture}

\begin{scope}[xshift=-45mm]
%5\draw [fill=black!10] (-1.2,-1.2) rectangle (1.2,1.2);
%\draw [->] (-1,-1) -- (1,-1);
%\draw [->] (-1,-1) -- (-1,1);
\node (a) [actual] at (-0.6,-0.8) {};
\node (b) [actual] at ( 0.6, 0.8) {};
\path (a) edge [electron] (b);
\end{scope}

\begin{scope}[xshift=-15mm]
%\draw [fill=black!10] (-1.2,-1.2) rectangle (1.2,1.2);
\node at (-1.5,0) {$+$};
%\draw [->] (-1,-1) -- (1,-1);
%\draw [->] (-1,-1) -- (-1,1);
\node (a) [actual] at (-0.6,-0.8) {};
\node (b) [actual] at ( 0.6, 0.8) {};
\node (a1) [virtual] at (-0.2,-0.7) {};
\node (b1) [virtual] at (0.6,0.4) {};
\path (a)  edge [electron] (a1)
      (a1) edge [electron] (b1)
      (b1) edge [electron] (b) ;
\path (a1) edge [photon,bend left] (b1);
\end{scope}

\begin{scope}[xshift=15mm]
%\draw [fill=black!10] (-1.2,-1.2) rectangle (1.2,1.2);
\node at (-1.5,0) {$+$};
%\draw [->] (-1,-1) -- (1,-1);
%\draw [->] (-1,-1) -- (-1,1);
\node (a) [actual] at (-0.6,-0.8) {};
\node (b) [actual] at ( 0.6, 0.8) {};
\node (a1) [virtual] at (-0.2,-0.7) {};
\node (b1) [virtual] at (0.6,0.4) {};
\node (a2) [virtual] at (0.2,-0.6) {};
\node (b2) [virtual] at (0.6,0) {};
\path (a)  edge [electron] (a1)
      (a1) edge [electron] (a2)
      (a2) edge [electron,bend left] (b2)
      (b2) edge [electron] (b1)
      (b1) edge [electron] (b) ;
\path (a1) edge [photon,bend left] (b1);
\path (a2) edge [photon,bend right] (b2);
\end{scope}

\begin{scope}[xshift=45mm]
\node at (-1.5,0) {$\cdots$};
\end{scope}

%\begin{scope}[xshift=45mm]
%%\draw [fill=black!10] (-1.2,-1.2) rectangle (1.2,1.2);
%\draw [->] (-1,-1) -- (1,-1) node [above] {\tiny $x$};
%\draw [->] (-1,-1) -- (-1,1) node [right] {\tiny $t$};
%\node (a) [actual] at (-0.6,-0.8) {};
%\node (b) [actual] at ( 0.6, 0.8) {};
%\node (a1) [virtual] at (-0.2,-0.7) {};
%\node (b1) [virtual] at (0.6,0.4) {};
%\node (a2) [virtual] at (0.2,-0.6) {};
%\node (b2) [virtual] at (0.6,0) {};
%\node (a3) [virtual] at (-0.2,-0.2) {};
%\node (b3) [virtual] at (-0.2,0.4) {};
%\path (a)  edge [electron] (a1)
%      (a1) edge [electron] (a2)
%      (a2) edge [electron,bend left] (b2)
%      (b2) edge [electron] (b1)
%      (b1) edge [electron] (b);
%\path (a1) edge [photon] (a3)
%      (a3) edge [electron,bend left] (b3)
%      (b3) edge [electron,bend left] (a3)
%      (b3) edge [photon] (b1);
%\path (a2) edge [photon,bend right] (b2);
%\end{scope}

\end{tikzpicture}
}{The foremost rule of quantum field theory: anything goes as long as you don't get caught}

This shows that the bare electron is always surrounded by a cloud of virtual particles like groupies. The electron we measure in the lab is actually this cloud---one never sees a naked electron.

\pics[]{antimatter}{
\begin{tikzpicture}[scale=1.5]

\begin{scope}[xshift=-15mm]
%\draw [fill=black!10] (-1.2,-1.2) rectangle (1.2,1.2);
%\draw [->] (-1,-1) -- (1,-1);
%\draw [->] (-1,-1) -- (-1,1);
\node (a1) [actual]  at (-0.6,-0.8) {};
\node (b1) [actual]  at ( 0.6,-0.8) {};
\node (a2) [actual]  at (-0.4, 0.8) {};
\node (b2) [actual]  at ( 0.8, 0.8) {};
\node (a3) [virtual] at (-0.2,-0.1) {};
\node (b3) [virtual] at ( 0.4, 0.1) {};
\path (a1) edge [electron] (a3)
      (a3) edge [electron] node [pin={[pin distance=15mm]90:{Electron}}] {} (b3)
      (b3) edge [electron] (b2);
\path (a3) edge [photon] (a2);
\path (b1) edge [photon] (b3);
\end{scope}

\begin{scope}[xshift= 15mm]
%\draw [fill=black!10] (-1.2,-1.2) rectangle (1.2,1.2);
\node at (-1.5,0) {$=$};
%\draw [->] (-1,-1) -- (1,-1);
%\draw [->] (-1,-1) -- (-1,1);
\node (a1) [actual]  at (-0.6,-0.8) {};
\node (b1) [actual]  at ( 0.6,-0.8) {};
\node (a2) [actual]  at (-0.4, 0.8) {};
\node (b2) [actual]  at ( 0.8, 0.8) {};
\node (a3) [virtual] at (-0.2, 0.1) {};
\node (b3) [virtual] at ( 0.4,-0.1) {};
\path (a1) edge [electron] (a3)
      (a3) edge [electron] node [pin={[pin distance=15mm]90:{Positron}}] {} (b3)
      (b3) edge [electron] (b2);
\path (a3) edge [photon] (a2);
\path (b1) edge [photon] (b3);
\end{scope}

\end{tikzpicture}
}{Anything goes---including traveling backward in time}

One surprisingly simple consequence of these diagrams is that it is easy to see how QFT predicts the existence of anti-matter. Consider the pair of diagrams in Figure \ref{fig:antimatter}. The one on the left represents an electron that emits a photon then later absorbs and incoming one. But this is equivalent to the other diagram on the right with this order reversed. But what is going on in the middle? The electron is going backward in time.

From a technical standpoint, these two diagrams are indistinguishable. You can't have one without the other. Feynman interpreted the time-traveling electron as the positron.\footnote{The positron was discovered by Carl Anderson in 1932. It has all the properties of the electron except with a positive charge.} Look at the second diagram a bit closer. The incoming photon on the right splits into two particles---the one on the right is the outgoing electron. The one on the left is the backward traveling electron. But in the lab we would call this the creation of a matter-antimatter pair, one electron and one positron. Later in time, the positron strikes and annihilates the incoming electron. This leaves the outgoing photon as the byproduct. In this way Feynman explained the existence of antimatter and why every particle has an antimatter twin with the same mass. Simple. 

\pics[side]{oyster-diagram}{
\vspace{-1cm}
\begin{tikzpicture}[scale=2]

\draw [->] (-1,-1) -- (1,-1);
\draw [->] (-1,-1) -- (-1,1);
\draw [electron] (0,0) circle (0.5);
\node (b1) [virtual] at (-0.5,0) {};
\node (b3) [virtual] at (0.5,0) {};
\node (b0) [actual] at (0,-0.5) {};
\node (b2) [actual] at (0,0.5) {};
\path (b1) edge [photon] (b3);
\end{tikzpicture}
}{An oyster diagram---the vacuum is not empty}

In fact, we can even draw Figure \ref{fig:oyster-diagram}. This diagram represents the virtual creation then annihilation of an electron-positron pair. Note that there are no incoming or outgoing particles. This diagram shows that even the vacuum is full of a sea of virtual matter-antimatter pairs. This is the source of the so-called \jargon{zero-point energy} of the vacuum. In quantum field theory even the vacuum is a many-body problem!

One of the most important consequences of quantum field theory is that every quantum particle falls into one of two categories: \jargon{fermions} or \jargon{bosons}. Bosons are the exchange particles in our Feynman diagrams: they can be absorbed and emitted by fermions and mediate the interaction between them. Fermions represent the ``hard'' particles which form into atoms and all the matter we see. Fermions obey the \jargon{Pauli exclusion principle} which states that no two identical fermions can exist in the same quantum state. There is a natural ``repulsion'' between them which gives matter its stability. On the other hand, bosons are gregarious: they have a propensity to collect into the same state. This collective behavior is why they appear classically as force fields since they work together to produce a net interaction measurable on a macroscopic scale.

This also helps to explain how a \jargon{laser} works. In a typical laser the medium is designed to support the emission of photons. Usually this is done by ``pumping'' electrons into a high energy state. The electrons each radiate this energy as a photon in order to return to a lower energy state. The lasing material must be able to support the electrons in this unstable position for a relatively long time frame (a few nanoseconds). 

The laser begins with one photon. The presence of this photon induces the next photon to be aligned with itself because of this ``gregarious'' nature of bosons. Put a couple of mirrors on the end and as long as there are electrons to generate the photons, the pattern continues and multiplies. Eventually you have a significant beam of light in which all the photon waves are aligned in both phase and polarization. Since these waves constructively interfere, the total energy content of the beam scales with square of the number of photons. With classical particles the energy scales with only the number of photons. This coherence is why lasers are so much more powerful than other sources of light.

Occasionally it is possible to create a situation in which fermions lock together and act like bosons. This is what happens in \jargon{superconductivity}, for example. The electrons pair together by interacting through the metal substrate. This allows the wave function of the electron pair to constructively interfere like bosons. As a consequence, the flow of the electron pairs is self-sustaining---strong enough to overcome the natural resistance of the wire at very low temperatures.

The strange behavior of liquid helium is another example. Helium liquefies at 4.2 kelvin, but at 2.17 kelvin the viscosity of the fluid drops to zero which allows the fluid to flow without resistance. So much so that the capillary action of surface tension will cause the fluid to ``wick'' up the sides of its container. Every liquid does this, but without viscosity liquid helium crawls up and out of the container completely. This is an example of a \jargon{superfluid}.

Usually these quantum phenomena require a very low temperature to manifest because the random motion associated with heat destroys the coherence required to create these weird effects. But in 1986, the first ``high-temperature'' material (\href{http://en.wikipedia.org/wiki/YBCO}{YBa$_2$Cu$_3$O$_7$}) was discovered with a superconducting temperature above the boiling point of liquid nitrogen (77 kelvin). This made the practical use of superconductors in electronics possible.

Next lecture we will investigate how these quantum principles explain the structure of the atom. We will see that by trapping the electron field in the electrostatic potential of the nucleus it collapses into stable standing wave patterns. These electron orbitals explain the spectroscopic patterns of the elements and the Pauli exclusion principle explains the structure of the periodic table. We will then cover how solid state electronic devices work.
========
28:solid-state
--------
Atoms and Solid State Physics
--------
Read sections 30.1--30.6, review section 23.5, see also Lecture \ref{ch:classical-limits}
--------
As was mentioned in Lecture \ref{ch:quantum-mechanics}, the primary motivation behind the early development of quantum mechanics was to understand how the atom works. \href{http://en.wikipedia.org/wiki/Atomic_theory}{Atomic theory} was developed by the chemists of the early 19th century: primarily Dalton and Avagadro. In 1869 Mendeleev compiled the elements into the periodic table in a way which is ordered by atomic mass but also emphasizes their chemical similarity. The periodic table gave order to chemistry, but the reason behind the order was unknown.

In this same time frame, it was discovered that each element has its own characteristic emission spectrum. When burned or electrically excited, the atoms emit electromagnetic radiation at very specific frequencies. These spectral lines act as a kind of fingerprint for each element and this spectral analysis offers a unique way to identify the presence of elements in an otherwise unknown sample. The process works in reverse too: an otherwise continuous spectrum will possess dark lines from the absorption of light at these same frequencies. This is how the composition of distant stars and planets are \href{http://en.wikipedia.org/wiki/Absorption_spectroscopy}{analyzed}.

In the late 1880's a formula for the spectral lines of hydrogen was empirically discovered:
\begin{equation} \label{rydberg}
\frac{1}{\lambda} = R \left( \frac{1}{n_1} - \frac{1}{n_2}\right)
\end{equation}
where $R$, the \href{http://en.wikipedia.org/wiki/Rydberg_constant}{Rydberg constant}, is equal to \sci{1.097}{7} and is the most accurately measured physical constant. There are four lines that sit in the visible range for hydrogen with $n_1$ = 2 and $n_2$ = 3, 4, 5, and 6. These are called the \jargon{Balmer lines} and are useful to detect the presence of hydrogen gas in interstellar space.

Then in 1897, the electron was discovered---the first subatomic particle---showing that the atom was not in fact atomic (``atom'' in Greek means indivisible). Four years later, Rutherford showed that the bulk of the atom is confined to a central nucleus. Presumably the electron orbits this nucleus like a planet around the sun.

But this planetary model can't work. Using Larmor's formula \eqref{larmor-formula} it is possible to show that the electron will radiate all of its kinetic energy in one-hundredth of a nanosecond.

This contradiction remained unresolved until Bohr proposed a novel solution in 1913. Inspired by Planck's quantum formula for radiation, he showed that if we postulate that the orbits of the electron are quantized, we can have a stable atom and explain the spectral lines of hydrogen.

Bohr's assumed that the angular momentum of the electron orbit obeys the relation
\begin{equation} \label{bohr-assumption}
L = mvr = n\hbar
\end{equation}
Using this relationship and by setting the centripetal force of the orbit equal to Coulomb's law \eqref{coulombs-law}, one can determine that the radius of the allowed orbits are
\begin{equation} \label{hydrogen-radius}
r_n = \frac{n^2 \hbar^2}{k e^2 m}
\end{equation}
where $e$ and $m$ are the charge and mass of the electron, respectively. The minimum radius for $n = 1$ is \sci{0.529}{-10} meters, which is called the \jargon{Bohr radius}. It also follows that the energy of these orbits is given by
\begin{equation} \label{hydrogen-energy}
E_n = -\frac{ke^2}{2r_n} = -\frac{13.6 \unit{eV}}{n^2}
\end{equation}
Furthermore Bohr assumed that each transition between these orbits is accompanied by the emission or absorption of a photon with energy equal to $\Delta E = hf$. From this, the Rydberg formula \eqref{rydberg} follows. 

So with one simple condition Bohr was able to explain a large swath of atomic theory. But why this quantization? This is where de Broglie's matter wave comes in. Each of Bohr's stable orbits correspond to a standing wave similar to harmonics on a string (see Lecture \ref{ch:waves-interference}).

But this picture is too simplistic. We ought really to consider these standing waves in three dimensions (as in Figure \ref{fig:quantum-orbitals}). The solutions to Schr\"{o}dinger's equation \eqref{schrodinger} with stable energy are the atomic orbitals. These patterns are characterized by three integers $n$, $\ell$, and $m$ which define their shape. The first integer $n$ is called the \jargon{principal quantum number} and is related to the energy of the electron. The larger the $n$ value, the more energy, and the larger the size of the orbital---in the same way as in the Bohr model.

\pics[]{quantum-orbitals}{
\includegraphics[scale=0.4]{images/Hydrogen_Density_Plots.png}
}{Atomic orbitals of the hydrogen atom \newline (image credit \href{http://en.wikipedia.org/wiki/File:Hydrogen_Density_Plots.png}{here})}

\tbl[side]{quantum-numbers}{lcl}{
Principal & $n$ & $1,2,3,\ldots$ \\
Angular   & $\ell$ & $0,1,2,\ldots,(n-1)$ \\
Magnetic  & $m$ & $0,\pm 1,\pm 2,\ldots,\pm \ell$ \\
}{Quantum numbers for an electron trapped in a Coulomb spherical well}

The other two quantum numbers are related to the shape and spin of the orbital. Since they have the same energy we call them \jargon{degenerate states}. Because of the way the math works, there are more degenerate states the larger the value of $n$. The possible values are summarized in Table \ref{tbl:quantum-numbers}.

For example, the $n = 2$ energy state has a four-fold degeneracy because $\ell$ can be either zero or one. If zero, $m$ must have the value zero. If $\ell=1$, then $m$ can take the values $-1$, 0, and 1 for a total of four states at $n = 2$. When $n = 3$, there are nine degenerate states. In general, the overall degeneracy is $n^2$. However, in any real atom there are interactions and subtleties that ``break'' this energy degeneracy.\footnote{The quantum number $m$ is called magnetic because it's degeneracy can be broken with a magnetic field.} These slight differences gives us some of the most accurate means to determine whether each refinement of our mathematical model is correct or not.

The actual shape of these orbitals are determined by two factors: (1) the radial probability density and (2) its angular dependence. The functions describing this angular pattern are called \href{http://en.wikipedia.org/wiki/Table_of_spherical_harmonics}{spherical harmonics}. These mathematical functions show up in a variety of different contexts in physics: gravitational theory, electromagnetic radiation, even three-dimensional acoustic problems. These functions are what give the orbitals their characteristic spherical, tear-drop, or ring shapes. 

\pics[]{radial-function}{
\begin{tikzpicture}[xscale=1,yscale=20]
\draw plot [smooth] coordinates {
(0.00,0.0000)
(0.05,0.0023)
(0.10,0.0082)
(0.15,0.0167)
(0.20,0.0268)
(0.30,0.0494)
(0.40,0.0719)
(0.50,0.0920)
(0.60,0.1084)
(0.70,0.1208)
(0.80,0.1292)
(0.90,0.1339)
(1.00,0.1353)
(1.10,0.1341)
(1.20,0.1306)
(1.40,0.1192)
(1.60,0.1044)
(2.00,0.0733)
(2.40,0.0474)
(2.80,0.0290)
(3.20,0.0170)
(3.60,0.0097)
(4.00,0.0054)
(4.40,0.0029)
};
\draw [dashed] plot [smooth] coordinates {
(0.00,0.0000)
(0.05,0.0020)
(0.10,0.0066)
(0.15,0.0120)
(0.20,0.0172)
(0.30,0.0242)
(0.40,0.0259)
(0.50,0.0230)
(0.60,0.0173)
(0.70,0.0109)
(0.80,0.0052)
(0.90,0.0013)
(1.00,0.0000)
(1.10,0.0013)
(1.20,0.0052)
(1.40,0.0191)
(1.60,0.0376)
(2.00,0.0733)
(2.40,0.0929)
(2.80,0.0939)
(3.20,0.0823)
(3.60,0.0654)
(4.00,0.0483)
(4.40,0.0337)
(4.80,0.0225)
(5.20,0.0145)
(5.60,0.0091)
(6.00,0.0055)
};
\draw [->] (0,0) -- (7,0) node [pos=0.5,below=1mm] {$r$};
\draw [->] (0,0) -- (0,0.15) node [above] {Prob.} node [pos=0.5,above,sloped] {$r^2\psi^2$};
\end{tikzpicture}
}{Probability of finding an electron at a particular radius in the atom ($n=1$ solid, $n=2$ dashed)}

In general the radial function is an exponential decay, but because the volume decreases as $r$ gets smaller, the actual probability of finding an electron at a particular radius looks like Figure \ref{fig:radial-function}. Technically there is a non-zero probability of finding the electron at any distance. The peak of this curve matches the Bohr radius given in equation \eqref{hydrogen-radius}.

So far in this explanation I've left out an important little tidbit called \jargon{quantum spin}. There are some similarities to the classical idea of a spinning top---it gives the electron a magnetic moment, for example---but overall it is better to think of this quantum spin as a uniquely quantum effect. For Schr\"{o}dinger's equation we need to ``bolt'' on the idea of electron spin, but in quantum field theory the notion falls out quite naturally. In a way, an extra degree of freedom is expected since QFT is essentially a four-dimensional theory. For an electron, this quantum spin can only take the values of $\pm \hbar/2$.

We are starting to get enough information under our belt to begin to see the mechanical foundations of chemistry. \href{http://en.wikipedia.org/wiki/Democritus}{Democritus} in 400 BC was the first to advocate an atomic theory in which matter was composed of indivisible elements moving in random motion through the void. These elements were distinguished by shape and would lock together in accord with those shapes. Over two millennia later, we find out that he was essentially correct.

For example, the structure of the periodic table is a consequence of the Pauli exclusion principle. As protons are added to the nucleus, electrons are added to the exterior of the atom to balance the electrostatic charge. These electrons are added to the lowest energy levels first. Electrons with excess energy are said to be in an \jargon{excited state} and will eventually return to the \jargon{ground state} with the release of a photon of energy.

So we start with hydrogen with one electron in the 1s orbital.\footnote[-0.5in]{There is a labeling convention that goes back to spectroscopic studies to label these orbitals by a leading number corresponding to the $n$ value and a letter corresponding to the $\ell$ value. The letters are s, p, d, and f for $\ell=0,1,2,3$ respectively.} Helium has another electron which can also sit in the 1s orbital if the spin of the two electrons are anti-parallel. This is denoted 1s$^2$. Lithium has three electrons. Since there is only a two-fold degeneracy in the $n=1$ energy level, the third electron will sit in the 2s orbital. But the 2s orbital has an eight-fold degeneracy so the next eight elements gradually fill this shell until we get to neon.

I mentioned earlier that this energy degeneracy is broken in a real atom. In particular the shapes associated with different angular quantum numbers tend to favor the more spherical shapes, or lower $\ell$ values. So, in general, the orbitals fill from s to p to d to f if possible given the value of the principle quantum number $n$. Thus, the orbital configuration for boron is 1s$^2$2s$^2$2p$^1$.

After neon, things get a little more tricky. This is because the energy level of the 3s orbital is actually lower than the 2d orbital. In fact, the energy order of the orbitals is
\begin{quote}    
1s 2s 2p 3s 3p 4s 3d 4p 5s 4d 5p 6s 4f 5d 6p 7s 5f 6d 7p 8s 5g 6f 7d 8p 
\end{quote}
Filling the electron shells according to this order will reproduce the period table (with a couple of exceptions).

%The chemistry of the atoms are dominated by their outermost electrons. So lithium, sodium, and potassium are all alkali metals because they each have a lone electron in the outermost energy shell. Carbon and silicon are similar because the outer most shell has two electrons in the s orbital and two electrons in the p orbital.

\pics[side]{bondwf2}{
\includegraphics[scale=0.35]{images/bondwf2.png}
}{The electron fields from two hydrogen atoms can overlap constructively or destructively (image credit \href{http://hyperphysics.phy-astr.gsu.edu/hbase/molecule/hmol.html}{here})}

The covalent bond is also a uniquely quantum mechanical effect. Consider the hydrogen molecule H$_2$. As the electron fields from the two atoms overlap, they may either constructively or destructively interfere (see Figure \ref{fig:bondwf2}). It happens that the interference type is related to the quantum spin of each electron. If the two electron spins are aligned (parallel), the two waves constructively interfere and the overall energy of the system decreases. This reduction in energy is called the \jargon{exchange interaction}. 

\pics[side]{h2mol}{
\includegraphics[scale=0.5]{images/h2mol.png}
}{Energy levels for the two overlap patterns in Figure \ref{fig:bondwf2} as the atoms approach one another (image credit \href{http://hyperphysics.phy-astr.gsu.edu/hbase/molecule/hmol.html}{here})}

There is a point of equilibrium in which the electrostatic repulsion of the two electrons is compensated by this exchange interaction (see Figure \ref{fig:h2mol}). At this point the wave function for the electron pair is largest between the two hydrogen nuclei---we say the two are ``sharing'' the electrons. This constructive overlap is responsible for every covalent bond in chemistry.

A secondary consequence of the covalent bond is that it induces an electric dipole moment in the molecule by localizing the electrons between the nuclei. This effect is most pronounced when hydrogen is involved because it creates the maximum exposure of the positive nucleus. This is the source of the \jargon{hydrogen bond} which is essentially electrostatic in nature. The hydrogen bond is responsible for many of the properties of water (including the fact that ice is less dense than cold water), the structure of proteins, and holds the DNA molecule together.

The exchange interaction is also responsible for magnets. You remember from Lecture \ref{ch:dc-and-magnetism} that every spinning charge acts like a magnet. So, every atom is also magnetic because of both the intrinsic and orbital spin of all its parts. However, in classical mechanics the alignment of these atoms is \href{http://en.wikipedia.org/wiki/Bohr-van_Leeuwen_theorem}{completely random} without any long-range order. Part of the reason for this is that magnetic fields do no work. This means that classical mechanics cannot explain the existence of bar magnets!

There are actually three forms of natural magnetism: \href{http://en.wikipedia.org/wiki/Ferromagnetism}{ferromagnetism}, \href{http://en.wikipedia.org/wiki/Paramagnetism}{paramagnetism}, and \href{http://en.wikipedia.org/wiki/Diamagnetism}{diamagnetism}. \jargon[ferromagnetism]{Ferromagnetism} is the strongest type and is exhibited in the typical bar magnet. \jargon[paramagnetism]{Paramagnetism} is the type of magnetism involved in materials we would call ``magnetic'' in the sense that a natural magnet will ``stick'' to the substance. This is due to an induced dipole magnetic moment which acts to attract the magnet to the material. \jargon[diamagnetism]{Diamagnetism} occurs in ``non-magnetic'' materials like aluminum or plastic. This effect is actually repulsive and is ultimately due to Lenz's law (page \pageref{idx:Lenz's law}) applied on the atomic scale.\footnote{This phenomena has been used to stabilize some interesting levitation experiments. See \href{http://www.ru.nl/hfml/research/levitation/diamagnetic/}{here} to read about levitating live frogs\ldots}

But ferromagnetism has no classical analog. It is another manifestation of the exchange interaction which creates a lower energy state when the magnetic moments of the atoms are parallel. In a way we have a ``magnetic covalent bond'' which forms and yields an alignment of the atomic magnetic moments to create a macroscopic dipole moment.

Actually, ferromagnetism is our first step into solid state physics.\footnote[-0.5in]{Solid state physics is a branch of \href{http://en.wikipedia.org/wiki/Condensed_matter_physics}{condensed matter physics}, which includes the study of all phases of matter: gas, liquid, and solid. It also studies the electric and magnetic properties of matter including more exotic phenomena like superconductivity. Nanotechnology (the manipulation of matter on an atomic scale) is also considered a branch of condensed matter physics.} Classically we have already imagined a solid like set of balls connected by springs (cf. Lecture \ref{ch:elasticity}). We now hope to see what happens when we apply quantum mechanics to a collection of atoms locked together in a solid.

Take another look at Figure \ref{fig:h2mol}. Notice how when the separation between the hydrogen atoms is large the electrons are both at $-13.6$ eV. As they approach one another this equality splits. If we add another atom to the system, the energy levels split again. Add a whole crystal of atoms and the energy levels form an \jargon{energy band} of closely spaced levels. This allows the electrons to gain a small amount of kinetic energy to move rather than being locked into one particular energy level.

Each orbital from the original atoms creates an energy band (see \href{http://hyperphysics.phy-astr.gsu.edu/hbase/solids/band2.html\#c1}{here} for an interesting diagram). Frequently there are gaps between the bands---energy levels inaccessible to the electrons. As the atoms collect into the crystal, the electrons fill the lowest energy bands first. These bands are either completely full or completely empty. Bands that are filled are called \jargon{valence bands} and those that are empty are called \jargon{conduction bands}. It is possible that the bands overlap---if that occurs between the last valence band and the first conduction band, then the electrons are free to move and we have a conductor. On the other hand, an energy gap creates an insulator. See Figure \ref{fig:band-structure}.

\pics[side]{band-structure}{
\begin{tikzpicture}
\node at (0.5,3.5) {Insulator};
\draw [fill=gray] (0,0) rectangle +(1,1);
\draw (0,2) rectangle +(1,1);
\node at (0.5,1.5) {$E_\text{gap}$};

\node at (3.5,0.5) [right,text width=18mm] {\flushright Filled valence band};
\node at (3.5,2.5) [right,text width=18mm] {Empty conduction band};

\node at (2.5,3.5) {Conductor};
\draw [fill=gray] (2,0.6) rectangle +(1,1);
\draw (2.0,1.4) rectangle +(1,1);

\draw [->] (1.5,0) -- (1.5,2.5) node [above] {$E$};
\end{tikzpicture}
}{Energy band description of insulators and conductors}

But this description ignores the effect of temperature on the energy distribution of the electrons. At any temperature, there is a probability that any individual electron will gain enough kinetic energy to overcome this energy gap. \href{http://hyperphysics.phy-astr.gsu.edu/hbase/solids/fermi3.html\#c1}{It can be shown} that the density of electrons that do this is related to both temperature and the energy gap by
\begin{equation} \label{conduction-electrons}
\rho = (AT^{3/2})\exp(-E_\text{gap} / 2kT)
\end{equation}
where $A$ = 0.00805 mol/m$^3$. The important factor is the exponential. Unless the energy gap is on the order of an electron volt, this temperature effect is completely negligible. For example, silicon has a band gap of 1.1 eV, so at 300 kelvin (approximately room temperature), equation \eqref{conduction-electrons} implies an electron density of \sci{3.28}{-8} moles of electrons per cubic meter. Though small, this is enough to allow a small amount of current to flow.

So even if the bands don't overlap, there is a second way for a material to conduct electricity. Those materials with an energy gap around 1 eV are called \jargon{semiconductors}.

One of the reasons for the tremendous utility of semiconductors in electronics is the ability to precisely control the electrical properties through \jargon{doping}. If we diffuse a small amount of phosphorous (typically via phosphine gas PH$_3$) into pure silicon we introduce an extra energy level just below the conduction band filled with extra electrons because phosphorous has five outer electrons but the lattice structure of silicon only supports four. This is called an \jargon{n-type semiconductor} because of the addition of negative charges. 

We can do the opposite too by diffusing boron (typically via diborane gas B$_2$H$_6$) which introduces an empty energy level just above the valence band. This gives the electrons trapped in the valence band a bit of room to move. If an electron jumps up to this extra energy level it leaves behind a ``hole'' in the valence band. A neighboring electron can jump into it leaving behind another hole. This hole acts exactly like a positively charged electron in that it moves in the opposite direction as the electrons with the same speed and effective mass. Though an artifact of the gaps in the electron ``gas'' produced by introducing boron, it is convenient to consider this hole as particle in its own right,\footnote[-0.5in]{In fact, when Dirac was working out a relativistic version of Schr\"{o}dinger's equation \eqref{schrodinger}, he predicted the existence of the positron in the very same way.} so we call this a \jargon{p-type semiconductor}.

But this is just the beginning. Now take $p$-type and $n$-type materials and put them together. This is called a \jargon{pn junction} and is fundamental to any integrated circuit. At the interface between the two materials, the free electrons in the $n$-type materials jump over to holes in the $p$-type material.\footnote{Notice that the $p$-type material has a net negative charge and the $n$-type material has a net positive charge---the naming convention gets a bit confusing at this point.} This creates a separation of charges which creates an internal voltage difference across the interface. This voltage difference opposes the flow of electrons and an equilibrium state is reached as in Figure \ref{fig:pn-junction}. This internal voltage is dependent upon the nature of the two materials making the junction.

\pics[side]{pn-junction}{
\begin{tikzpicture}[scale=0.5]
\draw (-4,-1) rectangle (0,1); 
\node at (-2,0) [text height=1.5ex,text depth=.25ex] {$p$}; 
\draw (0,-1) rectangle (4,1); 
\node at (2,0) [text height=1.5ex,text depth=.25ex] {$n$};
\foreach \y in {-0.6,0,0.6} \node at (-0.4,\y) [draw,circle,inner sep=0pt] {\tiny $-$};
\foreach \y in {-0.6,0,0.6} \node at (0.4,\y) [draw,circle,inner sep=0pt] {\tiny $+$};
\draw [->] (1,1.5) -- (-1,1.5) node [pos=0.5,above] {$E$};
\begin{scope}[yshift=-3.5cm]
\draw (-4,-0.5) -- (-0.5,-0.5) -- (0.5,0.5) -- (4,0.5);
\draw [dotted] (0,-1) -- (0,1) node [above] {$V$};
\draw [dotted] (-4,0) -- (4,0);
\end{scope}
\end{tikzpicture}
}{The equilibrium state of a $pn$-junction and the internal potential that must be overcome for current to flow freely.}

Suppose we connect the positive terminal of a battery to the $p$ side of the junction and the negative terminal to the $n$ side. What happens is that the battery siphons off the electrons that collected in the $p$-type material (if the battery voltage is large enough to overcome the intrinsic voltage of the junction which is about 0.6 eV for a silicon-based diode). This disturbs the equilibrium and allows more electrons to flow from the $n$-type material and current flows freely.

Hook the battery up the other way and the current is blocked. This is because the battery voltage must exceed the internal voltage for current to flow. But as the current flows, it contributes to this internal voltage (like a capacitor) and it builds up until it is equal to the battery voltage.

So the $pn$ junction acts like a one-way street for current. When we treat this $pn$ junction as an electronic component it is called a \jargon{diode}.\footnote{This terminology actually comes from the days of vacuum tubes---which are still used in some industrial applications (see \href{http://en.wikipedia.org/wiki/Diode}{here}).} 

As current flows in a diode, each electron jumps from the conduction band in the $n$-type material to the valence band in the $p$-type material. When the diode is forward biased these levels are separated by an amount equal to the internal voltage at equilibrium. This means that each electron drops in energy just like when the electron in an exited atom falls to its ground state. However, not every $pn$ junction will emit photons: the change in momentum has to be lined up too.\footnote{This is true of the atom also: transitions between any two states is not possible in general. But typically the angular momentum states are degenerate so there is always a way to get from one energy level to another.} If so, the band gap is said to be ``direct'' and the energy drop is released as a photon (silicon based diodes have indirect band gaps). If the drop creates a photon with a frequency in the visible range, we have a \jargon{light-emitting diode}, or LED. Run this process in reverse and you have a \jargon{solar cell}.

We can't leave this subject without talking about the \jargon{transistor} which is essentially two diodes placed back-to-back. A $pnp$ transistor has an internal voltage pattern that looks like a potential barrier to current. By controlling the doping levels we can control which side has higher and lower potential. The higher potential end is called the \jargon{collector} and the lower potential the \jargon{emitter}.

The central $n$ region is called the \jargon{base} of the transistor. By applying a voltage to the base we can control the height of the potential barrier within the transistor. When the voltage on the base pulls the potential barrier down, current flows from the collector to the emitter (these names are a consequence of the fact that electrons move in the opposite direction because they have negative charge).

So a transistor acts as a miniature electronic switch which makes it ideal for computers. It also can be used as an amplifier since the base voltage---which uses a small amount of current---can control a large flow of current between the collector and emitter. Every integrated circuit is a combination of seemingly endless combinations of these diodes, transistors, and more.

Next week we continue our studies down in scale to talk about the nucleus of the atom. Each nucleus is composed of positively charged protons and particles without electric charge called neutrons. We will discuss how each nucleus is in tension balancing the electrostatic repulsion of its protons and the strong nuclear force. For larger nuclei this balance becomes unstable and natural radioactivity is a result. This tension also offers a way of unleashing the power of the strong nuclear force in controlled (and uncontrolled) ways.
========
29:nuclear-energy
--------
Nuclear Energy
--------
Read sections 31.1--31.7 and 32.1--32.5
--------
% Neutrons stabilize the nucleus by pitting the strong force against electrostatic repulsion.

Just a casual observation of the periodic table will uncover a problem: the atomic masses do not increase in step with the atomic number. One would expect that helium would be twice as massive as hydrogen, lithium three times, etc. But not so---its 1, 4, 7, 9, 11ish, 12, 14, 16, 19 for the first nine elements. And what is up with boron at 10.8?

Initially it was supposed that, for example, nitrogen had 14 protons in its nucleus (which accounts for the mass) that had somehow swallowed seven of its electrons (which accounts for the charge). However, no arrangement of 21 particles can correctly account for its quantum spin. 

In 1920, Rutherford offered the idea of a third subatomic particle in the nucleus. Without charge and with mass similar to the proton, this \jargon{neutron} was later discovered in 1932. The atomic number of the atom describes the number of protons and drives the chemistry of the element (by attracting the same number of electrons), and the remaining mass is provided by the neutrons.

We can even explain our ``11ish'' mass for boron as the average mass of several \jargon{isotopes}, or atoms with the same number of protons but a different number of neutrons. Isotopes have different masses but are indistinguishable chemically. In the case of boron we have two stable \href{http://en.wikipedia.org/wiki/Isotopes_of_boron}{isotopes}: boron-10 and boron-11 with five and six neutrons respectively.\footnote{These are usually denoted ${}^{10}_{\phantom{1}5}$B and ${}^{11}_{\phantom{1}5}$B but it is so much easier to write, type and say boron-10 and boron-11 that I will almost exclusively do so.} The relative abundance of the two are 20\% and 80\% which yields an average mass of 10.8.

The neutrons stabilize the nucleus by pitting the strong nuclear force against the electrostatic repulsion of the protons. Although protons do participate in the strong force, their repulsion is too great to allow them to bind together: helium must have at least one neutron.

On the other hand, the neutron needs the proton too. In isolation, the neutron is unstable and decays into a proton and an electron with a mean lifetime of about 15 minutes. But in the nucleus the neutron can be stable.\footnote[-0,5in]{It may look like this validates the idea of the neutron as some sort of bound state between the proton and the electron. But the story is a more complicated than that. We will pick this up again in Lecture \ref{ch:high-energy}.}

% When the nucleus decays, there are three types of nuclear shrapnel or radioactivity.

%However, when the nucleus becomes too large these balancing acts begins to fail. The heaviest stable isotope is lead-208.\footnote{Until 2003, \href{http://en.wikipedia.org/wiki/Bismuth-209}{bismuth-209} was thought to have this distinction. It was discovered to have a half-life of \sci{1.9}{19} years---which is over a billion times longer than the age of the universe.} Nuclei heavier than this are \jargon{radioactive} meaning they decompose and release nuclear radiation.

However, when the nucleus becomes too large these balancing acts begin to fail. The heaviest stable isotope is lead-208. Nuclei heavier than this are \jargon{radioactive} meaning they decompose and release nuclear radiation.

A common way for nuclei to shed excess size is by \href{http://en.wikipedia.org/wiki/Alpha_decay}{alpha decay}. One of the first forms of radiation studied, the $\alpha$-particle was later determined to be a pair of protons and neutrons (an helium nucleus).\footnote[-0.5in]{This is the source of helium on our planet. Every helium balloon you see is filled with the byproduct of billions of years of radioactivity.} This alpha radiation is easily shielded by a piece of paper or even just a few centimeters of air.\footnote{Smoke detectors work by using an alpha radiation source. The alarm is designed to sound whenever the transmission of the $\alpha$-particles is blocked (presumably by smoke).} This mode of decay is said to be \jargon{transmutation} since it actually changes the chemical element by reducing the atomic number by two.

An imbalance between the number of protons and neutrons can also cause instability in a nucleus. If there are too many neutrons, it is typical for one to decay into a proton and eject an electron. This is called \href{http://en.wikipedia.org/wiki/Beta_decay}{beta decay} and is another transmutation process (adds one to the atomic number). These particles require more shielding---five millimeters of aluminum is typical.

If there are too many protons, one of them will transform into a neutron and eject a positron in the process (subtracting one from the atomic number). Based on the discussion from Lecture \ref{ch:quantum-mechanics}, we should not be surprised to see this time-reversed, anti-matter twin of the process of neutron decay. This is also called beta decay and the two particles are often labeled $\beta^-$ and $\beta^+$ to distinguish them.

Alpha decay is the typical transmutation process for heavy nuclei while beta decay is typical for light nuclei. Other decay processes are possible, but the vast majority are one of these two. See Figure \ref{fig:isotope-decay} for a complete picture.

\pics[side]{isotope-decay}{
\includegraphics[scale=0.15]{images/1000px-Table_isotopes_en_svg.png}
}{Normal decay type by isotope (image credit \href{http://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Table_isotopes_en.svg/1000px-Table_isotopes_en.svg.png}{here})}

It is not uncommon for these transmutation processes to leave the nucleus in an excited energy state. And like the atom, the nucleus will emit a photon of electromagnetic radiation to release this energy. These photons are called \href{http://en.wikipedia.org/wiki/Gamma_ray}{gamma rays} and typically have millions of electron-volts of energy. The higher the energy, the more shielding is required to block this radiation. Three inches of lead is a generally accepted norm (any material will work including concrete and even dirt---you will just need more of it).

All three of these types of radiation are classified as \jargon{ionizing radiation} because they are energetic enough to ionize an atom (tens of electron-volts). As such they can do significant biological damage in sufficient quantity. The \jargon{radiation dose} is calculated as the amount of ionizing energy absorbed divided by the mass of the absorbing material. The SI unit of one joule per kilogram is called a gray.\footnote{The more traditional unit is the rad (radioactivity absorbed dose) which is one-hundredth of a gray, so 100 rad equals 1 gray.}

% Radiation differs in its effect---RBE and the biologically equivalent dose account for this.

But not all radiation has the same effect on our physiology. Dose for dose, alpha particles and other nuclear fragments do 20 times more damage than beta particles and gamma rays. Since neutrons do not carry charge, they interact indirectly through sheer kinetic energy and their effect therefore varies. The most damaging neutrons are in the millions of electron-volts and do damage comparable to alpha particles. This variation of biological impact is summarized in a number called the \jargon{relative biological effectiveness}, or RBE.

The absorbed dose multiplied by the RBE gives us the \jargon{biologically equivalent dose} for the radiation exposure. Based on the gray, the SI unit is called the sievert.\footnote{It is much more common (though strongly discouraged) to see this equivalent dose quoted in ``rem'' which is based on the rad.} The rule of thumb is that one sievert will cause nausea and over six is lethal. Our natural background radiation is approximately 2.4 millisieverts per year---about half from radon gas with the rest split evenly between cosmic radiation, terrestrial radiation, and our food and water. We are also exposed to an additional 0.4 millisieverts through various medical procedures (see \href{http://www.unscear.org/docs/reports/gareport.pdf}{here} for details).

% Activity and half-life are alternate ways to quantify the speed of nuclear decay.

As was mentioned in Lecture \ref{ch:quantum-mechanics}, natural radiation is a quantum mechanical effect. The electrostatic repulsion of the protons increase as the distances decrease, but once we get within the size of the nucleus, the strong force overwhelms the electric force and pulls the whole thing together. So there is a potential energy barrier that holds the nucleus in place. Since the wave functions of the most energetic nuclear material extend beyond this barrier, there is a small probability that a particle will manifest outside. Thus the nuclear material is pushed away and radiation is the result.

So the actual emission of radiation is an event based on probability. This probability is independent of time, so at any one moment the percentage of nuclei actually radiating is fixed. This probability is called the \jargon{decay constant}, $\lambda$ for the material. Thus, the rate of disintegrations\footnote{One disintegration per second is called a becquerel. Another common unit is disintegrations per minute or bpm.} is given by
\begin{equation} \label{radioactive-activity}
\frac{\Delta N}{\Delta t} = -\lambda N
\end{equation}
This quantity is called the \jargon{activity} of the material. From this it follows that the amount of substance left after a particular time period is
\begin{equation} \label{radioactive-amount}
N = N_0 \exp(-\lambda t)
\end{equation}
It can be shown from this equation that the mean life-time $\tau$ of a particle is equal to $1/\lambda$. The \jargon{half-life} of the material is the amount of time it takes for half of the initial substance to disintegrate and we see that
\begin{equation} \label{half-life}
T_{1/2} = \frac{\ln 2}{\lambda} = \tau \ln 2
\end{equation}
The half-life of \href{http://en.wikipedia.org/wiki/Carbon-14}{carbon-14} is 5730 years, so its decay constant $\lambda$ is \sci{3.84}{-12}.

Radiocarbon dating works by comparing the amount of carbon-14 to carbon-12 in a substance. Natural carbon-14 is created by cosmic rays interacting with the nitrogen gas in the atmosphere. A dynamic equilibrium exists between the radioactive decay and this cosmic generation which fixes the amount of carbon-14 in the atmosphere. As such, living creatures breathe and consume both carbon-12 and carbon-14 in a fixed ratio. 

When a plant or animal dies, the level of carbon-14 becomes depleted over time. By measuring the radioactive activity in a specimen we can use equation \eqref{radioactive-activity} to determine the amount of carbon-14 currently present. Measuring the amount of carbon-12 gives us a way to estimate the original amount of carbon-14. Using equation \eqref{radioactive-amount} we can get to an approximate time of death:
\begin{equation} \label{radiocarbon-dating}
t = \frac{1}{\lambda} \ln \left( \frac{N_0}{N} \right)
\end{equation}
where $N$ is the current amount of carbon-14 inferred from the measured activity of the sample and $N_0$ is the original amount of carbon-14 inferred from the amount of carbon-12 in the sample.

% Induced nuclear reactions split or combine the nucleus, releasing potential energy.

So far in this lecture we have focused on natural forms of radioactivity and transmutation. We now turn to consider how we can use this information to induce various nuclear interactions. The most important item to consider in this context is the nuclear binding energy curve in Figure \ref{fig:binding-energy}. This curve represents the net energy needed to break apart stable nuclei into their component parts. 

\pics[]{binding-energy}{
\includegraphics[scale=0.13]{images/binding_energy_curve.png}
}{Nuclear binding energy curve (image credit \href{http://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Binding_energy_curve_-_common_isotopes.svg/2000px-Binding_energy_curve_-_common_isotopes.svg.png}{here})}

%\pics[full]{binding-energy}{
%\includegraphics[scale=0.2]{images/binding_energy_curve.png}
%}{Nuclear binding energy curve (image credit \href{http://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Binding_energy_curve_-_common_isotopes.svg/1000px-Binding_energy_curve_-_common_isotopes.svg.png}{here})}

Note that this is not the energy required to overcome the strong nuclear force and break apart the nucleus (the ``activation energy'' to use the chemical term). If this barrier energy is overcome, electrostatic repulsion will create kinetic energy pushing apart the protons to infinity. The binding energy is the attractive energy from the strong force minus the repulsive energy from the electrostatic force and represents the average energy level of the nuclear material in the nucleus. \href{http://en.wikipedia.org/wiki/Iron-56}{Iron-56} is the most stable of all nuclei with a binding energy of 8.8 MeV per nucleon.\footnote{A \jargon{nucleon} is a catch-all term to describe both protons and neutrons.} The high binding energy for helium-4 (at 7.1 MeV per nucleon) explains why heavy radioactive nuclei tend to decay using alpha particles rather than tritium or lithium-6 or some other combination of protons and neutrons.

Using Figure \ref{fig:binding-energy} we can calculate the energy involved in various nuclear reactions. \jargon[nuclear fusion]{Nuclear fusion} occurs when we combine nuclei to generate a larger composite (we called this an inelastic collision in Lecture \ref{ch:momentum}). The fact that the binding curve goes up initially indicates that fusion in exothermic: more energy is released when the end products combine than required to break apart the beginning nuclei. This is the kind of nuclear process that powers the sun.

The binding curve increases up to iron-56 after which fusion is endothermic: it requires a net expenditure of energy to create these nuclei. But this also implies that the reverse process, \jargon{nuclear fission}, can be used as an energy source. This is the kind of nuclear process used in nuclear power plants today. 

% The energy binding the nucleus together is manifest in a mass smaller than its parts.

In either nuclear fusion or fission, we can use the binding energy curve to calculate the net energy requirements for the process. However, there is an easier way using the so-called \jargon{mass defect}. This is a statement of the fact that the mass on the two sides of a nuclear reaction do not balance. The difference is simply a consequence of $E = mc^2$ and the binding energy involved. Every difference of one atomic mass unit corresponds to 931.5 MeV of energy. When one takes into account the ``mass'' of the binding energy, the equations balance.

For example, let's calculate the binding energy of the helium atom. We have two protons, two neutrons, and two electrons. The atomic masses of these particles are in Table \ref{tbl:atomic-masses}. The total of all six particles is 4.032~980 atomic mass units while the helium atom is only 4.002~602. This is mass deficit of 0.030~378 atomic mass units, so the helium-4 atom has a binding energy of 28.3 MeV.

\tbl[side]{atomic-masses}{cc}{
Electron & 0.000~549 amu \\
Proton & 1.007~276 amu\\
Neutron & 1.008~665 amu \\
}{Atomic masses of the three particles that make up the atom}

The atomic masses of the isotopes are readily available (\href{http://physics.nist.gov/cgi-bin/Compositions/stand_alone.pl}{here} for example, or look up the wikipedia article ``\href{http://en.wikipedia.org/wiki/Isotopes_of_helium}{isotopes of helium}'', etc.). In order to figure out the energy released in a particular nuclear reaction, we simply calculate the difference in mass and convert it to energy via $E = mc^2$.

The first man-made fission reaction involved bombarding uranium-235 with neutrons. One possible reaction (\href{http://hyperphysics.phy-astr.gsu.edu/hbase/nucene/fisfrag.html\#c1}{of many}) is the following:
$${}^{235}_{\phantom{1}92}\text{U} + {}^1_0 n 
\rightarrow 
{}^{144}_{\phantom{1}56}\text{Ba} + {}^{89}_{36}\text{Kr} + 3{}^1_0 n$$
The atomic masses for \href{http://en.wikipedia.org/wiki/Isotopes_of_uranium}{uranium-235}, \href{http://en.wikipedia.org/wiki/Isotopes_of_barium}{barium-144}, and \href{http://en.wikipedia.org/wiki/Isotopes_of_krypton}{krypton-89} are 235.043~930, 143.922~953, and 88.917~636 respectively. The total mass on the left-hand side of this reaction is 236.052~590 and the right-hand side is 235.866~580, which leaves a mass defect of 0.186~010 atomic mass units. This means that each fission reaction generates 173 MeV of energy.

% Due to the huge energies involved, most nuclear chain reactions are uncontrolled.

On average, the fission of uranium-235 yields 215 MeV of energy with 2.4 neutrons as a byproduct. These extra neutrons are typically too energetic to initiate a secondary reaction unless the concentration of uranium-235 (relative to uranium-238) is in excess of 90\%---which is called weapons-grade uranium.\footnote{Plutonium-239 will also support a chain reaction and can be generated by bombarding uranium-238 with neutrons.} However, a moderator (like graphite) can be used to slow the neutrons down in order to create a controlled chain-reaction. Nuclear reactors work this way with a smaller concentration around 20\% and harness the energy through a high-efficiency steam engine. The amount of energy generated by the fission of one kilogram of uranium-235 could easily provide the energy needs of one person for a lifetime.

% As an energy source fusion is preferable to fission, but no one has been able to control it.

The problem with nuclear fission as an energy source is the radioactive waste products. On the other end of the scale we have fusion which powers the sun. Fusion packs more power per kilogram of fuel which can be seen by comparing the slopes on the left and right of the binding energy curve in Figure \ref{fig:binding-energy}. One of the most promising nuclear reactions for fusion on earth is the combination of deuterium (hydrogen-2, atomic mass of 2.014~102) and tritium (hydrogen-3, atomic mass of 3.016~049):
$${}^{2}_{1}\text{H} + {}^{3}_{1}\text{H} 
\rightarrow 
{}^{4}_{2}\text{He} + {}^1_0 n$$
The mass on the left-hand side of this reaction is 5.030~151 and the right-hand side is 5.011~267, for a mass deficit of 0.018~884 atomic mass units. This reaction produces 17.6 MeV of energy, or 3.52 MeV per nucleon. The fission of uranium-235 was about 0.915 MeV per nucleon, so pound-for-pound this reaction is almost four times more powerful---with helium as the main waste product.

There are two problems with this approach. The first is the fuel: deuterium is relatively plentiful and could be extracted from sea water, but tritium has a half-life of about 12 years (decay product is helium-3). So there is not much around---it would have to be generated (by bombarding lithium-6 with neutrons). This would take some work, but is possible.

The real problem is that no one has yet been able to control these fuels with enough precision to consistently overcome the ``activation barrier'' to release the fusion energy. This high level of energy requires the hydrogen isotopes to be in a plasma with a temperature over 450 million kelvin. These temperatures have been reached---the problem is constricting this plasma to create some sort of \jargon{magnetic confinement fusion}. Plasma is electromagnetically active which makes it extremely unstable and unwieldy. The \href{http://en.wikipedia.org/wiki/Tokamak}{tokamak} uses a toroidal (donut) shaped magnetic field to perform the necessary confinement. Several experimental tokamaks have been constructed with some success and research is ongoing in order to produce a workable structure.

Another approach to the problem is called \jargon{inertial confinement fusion}. Essentially \href{http://en.wikipedia.org/wiki/Inertial_confinement_fusion}{the idea} is to fire a high-energy laser or electron beam at a small pellet of the deuterium/tritium fuel. The beam burns off the outer layer explosively which drives an implosion of the inner layer. If a critical density and temperature can be reached the fusion reaction will take place---just like a tiny atomic bomb.

% Next week

Next week we finish off the course by investigating the very edge of what is known in physics. The decay of the neutron is our stepping off point to talk about the strong and weak nuclear interactions. We will find that protons and neutrons are made of quarks and we will discover we have overlooked the neutrino in our previous discussions. Quarks will help us make sense out of the ``particle zoo'' in high energy physics.

This is the ``standard model'' of elementary particles and our two nuclear interactions involve the exchange of new physical properties in the context of quantum field theory. If we have time, we may even be able to talk about why people think there is something beyond the standard model and whether string theory is that final answer.
========
30:high-energy
--------
High Energy Physics
--------
Read section 32.6--32.7 and review Lecture \ref{ch:quantum-mechanics}
--------
Our humble neutron, which appeared as an add-on to the structure of the atom, turns out to play a central role in both the creation of nuclear fuel and the unleashing of nuclear energy. We will start this final lecture addressing one loose end from the previous one: neutron decay.

With regard to neutron decay, I left out an important fact from Lecture \ref{ch:nuclear-energy}. When the neutron decays three particles are produced not two. The extra particle is called a \jargon{neutrino} because it has no electric charge and is nearly massless.\footnote{Originally, the neutrino was assumed to be massless. The phenomena of \href{http://en.wikipedia.org/wiki/Neutrino_oscillation}{neutrino oscillation} measured from the sun in 1998 proves that the neutrino must have some mass. The current upper bound is 0.3 eV, or about 1500 times lighter than the electron.}

We now seek an explanation in terms of quantum field theory for the decay of the neutron. We can do this by considering some key Feynman diagrams. We postulate the existence of a new boson to mediate the interaction that controls this decay. The reason for this is that each vertex in a Feynman diagram always forms a triad with two fermion lines and one boson. We cannot have a fermion decaying directly into other fermions. Since this is called the weak nuclear interaction, we call this new particle the \jargon{weak boson} (see Figure \ref{fig:neutron-decay}).

\pics[side]{neutron-decay}{
\vspace{1pt}
\begin{tikzpicture}[scale=2]
\node (a1) [actual,label=0:{$n$}] at (-0.5,-0.8) {};
\node (a2) [actual,label=0:{$p^+$}] at (-0.5, 0.8) {};
\node (b1) [actual,label=0:{$\bar{\nu}$}] at ( 0.3, 0.8) {};
\node (b2) [actual,label=0:{$e^-$}] at ( 0.8, 0.8) {};
\node (a3) [virtual] at (-0.2,-0.1) {};
\node (b3) [virtual] at ( 0.5, 0.1) {};
\node at ($(a3)!0.5!(b3)$) [below=1mm] {$W^-$};
\path (a1) edge [electron] (a3);
\path (a3) edge [photon] (b3);
\path (b3) edge [electron] (b2);
\path (a3) edge [electron] (a2);
\path (b1) edge [electron] (b3);
\end{tikzpicture}
}{Feynman diagram for neutron decay. The weak boson creates valid vertexes for the interaction.}

We know a few of things about this boson. First, it is short-range which means it is massive---about 80 GeV/c$^2$. It can be shown that equation \eqref{klein-gordon} yields the potential formula 
\begin{equation} \label{yukawa-potential}
V \propto \frac{\exp(-r/a)}{r}
\end{equation}
where $a = \hbar/mc$ represents the range of this potential. In QED the range is infinite because the mass of the photon is zero. Based on the mass of the $W$-boson, the range of its influence is on the order of $10^{-17}$ meters. Second, it decays with a very short time-frame---about $10^{-25}$ seconds which is a consequence of its large mass. In this case, the $W$-boson decays into an electron and an anti-neutrino. Finally, it is charged since it converts a neutral object (the neutron) into a charged one (the proton). This means it has an anti-particle twin with the opposite charge.

If Figure \ref{fig:neutron-decay} were a diagram from QED, we would interpret the decay of the weak boson as a matter-antimatter creation event. This is why the neutrino is labeled as its anti-particle. But the new characteristic of this diagram is that it pairs different particles together: the neutron with the proton and the electron with the neutrino. There is more to this story, but we first need to develop some ideas on the strong nuclear interaction to pull it all together.

The fact that the neutron can decay seems to imply that there is still some substructure to be found. But we know from Lecture \ref{ch:quantum-mechanics} that the creation of matter from pure energy cannot be ruled out. However, there is more direct evidence of substructure: the neutron has a magnetic moment.

A magnetic moment is generated by a rotating charge (see Lecture \ref{ch:dc-and-magnetism}). It is possible for an object with a net charge of zero to have a magnetic moment if the charge is distributed across the object (like a dipole). This seems to imply that there are little charged parts tied together to form the neutron. This is, in fact, the case---they are called \jargon{quarks}.\footnote[-0.5in]{If this seemingly endless substructure seems silly to you, you are not alone. When first proposed in the late 1960s, physicists were \href{http://en.wikipedia.org/wiki/Quark\#History}{reluctant} to accept the quark theory. But when predicted particles were found in the following decade (1974 to be precise), the theory carried the day.}

The theory works if we assume the neutron is composed of three quarks: one ``up'' and two ``down''. Don't put too much thinking into the names: they are intended to merely distinguish the two as opposites.\footnote{This is a common theme in particle physics: an appalling lack of imagination in naming things. We've already seen this in the ``strong'' and ``weak'' nuclear forces.} These quarks have a charge of $+2/3$ and $-1/3$ respectively. If we combine two ``up'' quarks and one ``down'' quark we get the proton. And like the way electromagnetism is mediated by the exchange of photons, the strong interaction holds these triplets together by exchanging bosons called \jargon{gluons} (seriously\ldots I'm not making this up). 

The force that hold the nucleus together is actually the residual force left over from this strong quark interaction. Much like the way a magnet sticks to a refrigerator or a balloon sticks to the wall via static electricity, the fields from the bound quarks interact to hold the composite protons and neutrons together.

The Feynman diagrams for the exchange of gluons look just like those in QED, but to explain the three-way nature of the strong interaction requires some work: we need a three-valued ``charge''. This three-valued charge is called \jargon{colour}. Of course, the quarks are not actually red or green or blue, but there is some logic to this name. The basic rule of thumb is that quarks always combine to be colour-less or to create ``white''.

So the opposite of the red quark colour is green and blue together, and so on. You can imagine that the mathematics required to explain this is a bit complicated (this is why the \href{http://en.wikipedia.org/wiki/Gell-Mann_matrices}{SU(3) group} is associated with colour). Figure \ref{fig:colour-triplet} shows a schematic of what is happening. Remember, in quantum field theory you should imagine that all of these interactions are occurring simultaneously and continuously.

\pics[]{colour-triplet}{
\begin{tikzpicture}
\tikzstyle {quark} = [draw,circle,text height=1.5ex,text depth=.25ex]
\def\nudge{3.3}

\begin{scope}[xshift=0*\nudge cm]
\foreach \i/\c in {0/g,1/r,2/b} \node (\i) [quark] at (90+120*\i:0.9) {$\text{\c}$};
\path (0) -- (1) node [pos=0.5,sloped,above=-2mm] {$\xrightarrow{\text{r}}\xleftarrow{\text{g}}$};
\draw [dotted] (-1.4,-1.2) rectangle (1.4,1.6);
\node at (0,-1.6) {$t=0$};
\end{scope}

\begin{scope}[xshift=1*\nudge cm]
\foreach \i/\c in {0/r,1/g,2/b} \node (\i) [quark] at (90+120*\i:0.9) {$\text{\c}$};
\path (2) -- (0) node [pos=0.5,sloped,above=-2mm] {$\xrightarrow{\text{r}}\xleftarrow{\text{b}}$};
\draw [dotted] (-1.4,-1.2) rectangle (1.4,1.6);
\node at (0,-1.6) {$t=1$};
\end{scope}

\begin{scope}[xshift=2*\nudge cm]
\foreach \i/\c in {0/b,1/g,2/r} \node (\i) [quark] at (90+120*\i:0.9) {$\text{\c}$};
\path (1) -- (2) node [pos=0.5,sloped,above=-2mm] {$\xrightarrow{\text{g}}\xleftarrow{\text{r}}$};
\draw [dotted] (-1.4,-1.2) rectangle (1.4,1.6);
\node at (0,-1.6) {$t=2$};
\end{scope}

\end{tikzpicture}
}{How the exchange of colour holds the proton and neutron together.}

\pics[side]{colour-exchange}{
\vspace{1pt}
\begin{tikzpicture}[scale=2]
\node (a1) [actual,label=0:{$Q_\text{b}$}]  at (-0.6,-0.8) {};
\node (b1) [actual,label=0:{$Q_\text{r}$}]  at ( 0.6,-0.8) {};
\node (a2) [actual,label=0:{$Q_\text{r}$}]  at (-0.4, 0.8) {};
\node (b2) [actual,label=0:{$Q_\text{b}$}]  at ( 0.8, 0.8) {};

\node (a3) [virtual] at (-0.2, 0.1) {};
\node (b3) [virtual] at ( 0.4,-0.1) {};
\path (a3) -- (b3) node [pos=0.4,below=1mm] {$G_{\text{r}\bar{\text{b}}}$};

\path (a1) edge [electron] (a3)
      (a3) edge [electron] (a2);
\path (b1) edge [electron] (b3)
      (b3) edge [electron] (b2);
\path (a3) edge [photon] (b3);
\end{tikzpicture}
}{A fundamental diagram for the strong interaction showing the colour exchange between quarks.}

Let's look in a little more detail at the Feynman diagram for a single colour exchange. In Figure \ref{fig:colour-exchange} the $Q$ represents a quark of any kind and $G$ is the gluon mediating the colour exchange. In this diagram, blue is on the left and red is on the right. The quark on the right emits the gluon which exchanges these colors. It takes red away and brings blue. But since the blue travels backward in time, we say the gluon is carrying red and anti-blue.

The idea of ``anti-color'' brings the last piece of the puzzle into play: anti-quarks. With this same construct we can bind a quark and an anti-quark together. In this case, the anti-quark actually carries anti-colour, so they can combine in a colour-neutral way by being red and anti-red, for example.

These two ways of combining quarks explain the so-called \jargon{particle zoo}. In the decades before the theory of quarks was developed, many high energy collisions experiment were performed. Frequently new particles were formed in the collision of electrons or protons. Over time, this continual discovery of new particles stirred up quite a bit of discomfort among physicists. Around 1930, it seemed that the world could be explained with only three fundamental particles---now there were over 70 ``fundamental'' particles. Clearly something needed some explaining!

The current list of particles can be accounted for through the existence of six quarks. The triplet bound states are called \jargon{hadrons} and the doublet bound states are called \jargon{mesons}. Dozens of combinations have yet to be discovered, but all known particles are combinations of the fundamental six quarks in Table \ref{fig:six-quarks}.

\pics[side]{six-quarks}{
\begin{tikzpicture}
\tikzstyle {quark} = [draw,circle,minimum width=8mm,text height=1.5ex,text depth=.25ex]
\node at (-2,1) {\begin{minipage}{1cm} \centering EM \\ charge \end{minipage}};
\node at (-2,0) {$+\tfrac{2}{3}$};
\node at (-2,-1) {$-\tfrac{1}{3}$};
\node at (-1,0.8) {1};
\node (u) [quark] at (-1,0) {$u$};
\node (d) [quark] at (-1,-1) {$d$};
\node at (0,1.4) {\underline{Generation}};
\node at (0,0.8) {2};
\node (c) [quark] at (0,0) {$c$};
\node (s) [quark] at (0,-1) {$s$};
\node at (1,0.8) {3};
\node (t) [quark] at (1,0) {$t$};
\node (b) [quark] at (1,-1) {$b$};
\node at (2,1) {\begin{minipage}{1cm} \centering Weak \\ isospin \end{minipage}};
\node at (2,0) {$+\half$};
\node at (2,-1) {$-\half$};
\draw [->] (-1,-1.8) -- +(2,0) node [pos=0.5,below] {Mass};
\end{tikzpicture}
}{The six fundamental quarks: up, down, charm, strange, top and bottom.}

The way this table is arranged is not random. The more massive ones are on the right and will decay through the weak interaction into the the less massive ones on the left. The quarks in the top row are said to have a weak isospin of $+1/2$ while those in the bottom row are $-1/2$. Each vertical pair is called a ``generation'' and the most likely decay path is within these generations (i.e., top to bottom, charm to strange, and down to up). It's also possible for the decay to skip to the next generation and even less likely to skip two. The one thing that cannot happen is a direct decay across the table. These facts are nicely summarized in Figure \ref{fig:quark-decay}.

\pics[side]{quark-decay}{
\includegraphics[scale=0.15]{images/1000px-Weak_decay_diagram_svg.png}
}{Possible quark decay paths via the weak interaction (image credit \href{http://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Weak_decay_diagram.svg/1000px-Weak_decay_diagram.svg.png}{here})}

So we come full circle. The quark composition of the neutron is $udd$ while the proton is $uud$. So, when the neutron decays, this is really the decay of the internal $d$ quark.\footnote{You may wonder why then doesn't the proton decay into a $uuu$ combination? The answer is that the way the quantum spin of the quarks interact with the strong interaction requires this symmetric state to align all three spin states. This is possible (named the $\Xi$ hadron), but the energy involved is higher than the proton. This makes the proton the least massive of all the hadrons.} While manifesting the $u$ quark, the weak boson carries away a full unit of negative electric charge and a full unit of negative weak isospin. Shortly afterward, the weak boson is mostly likely to decay using its least massive vertex: the electron/anti-neutrino pair.

Once again, it looks like we've got a theory that explains the facts. But nature is still not done. We've left out a particle called the \jargon{muon}. For all intents and purposes, the muon is nothing but a very massive electron (about 200 times greater). The redundancy is so striking that when it was first discovered (in 1937) \href{http://en.wikipedia.org/wiki/I._I._Rabi}{Rabi} famously joked, ``Who ordered that?''

The muon has its own neutrino and in 1975 a third twin was discovered with its own neutrino. The new particle is called the \jargon{tauon} and is nearly 3500 times the mass of the electron. This particle is so massive that it can actually decay into hadrons (protons and neutrons), though it is more likely to decay into a muon or an electron.

These three pairs are called \jargon{leptons} and fall into three generations not unlike the quarks. In parallel with Figure \ref{fig:six-quarks} we have our six leptons in Figure \ref{fig:six-leptons}. They decay through the weak interaction in a way that is similar to the quarks, but do not participate in the strong interaction at all.

\pics[side]{six-leptons}{
\vspace{0.1in}
\begin{tikzpicture}
\tikzstyle {quark} = [draw,circle,minimum width=8mm,text height=1.5ex,text depth=.25ex]
\node at (-2,1) {\begin{minipage}{1cm} \centering EM \\ charge \end{minipage}};
\node at (-2,0) {$-1$};
\node at (-2,-1) {$0$};
\node at (-1,0.8) {1};
\node (u) [quark] at (-1,0) {$e$};
\node (d) [quark] at (-1,-1) {$\nu_e$};
\node at (0,1.4) {\underline{Generation}};
\node at (0,0.8) {2};
\node (c) [quark] at (0,0) {$\mu$};
\node (s) [quark] at (0,-1) {$\nu_\mu$};
\node at (1,0.8) {3};
\node (t) [quark] at (1,0) {$\tau$};
\node (b) [quark] at (1,-1) {$\nu_\tau$};
\node at (2,1) {\begin{minipage}{1cm} \centering Weak \\ isospin \end{minipage}};
\node at (2,0) {$-\half$};
\node at (2,-1) {$+\half$};
\draw [->] (-1,-1.8) -- +(2,0) node [pos=0.5,below] {Mass};
\end{tikzpicture}
}{The six fundamental leptons: electron, muon, tauon each with a neutrino.}

So let's summarize. The world is divided into two groups: bosons and fermions. Bosons mediate the three fundamental interactions. We have the photon, the weak bosons, and the gluons. The fermions form matter and are also divided into two groups: quarks and leptons. There are three pairs of quarks which participate in all three interactions. These quarks combine in doublets and triplets called mesons and hadrons. Ultimately, the proton is the only stable quark combination though the neutron is pretty close. The leptons also come in three pairs. All participate in the weak interaction, the electrons-like particles participate in the electromagnetic interaction and none participate in the strong interaction. Although the quarks can decay across generations through the weak interaction, the leptons do not (although the neutrinos do oscillate between the generations).

Of the three, the weak interaction is the most complicated. Every particle participates but in different ways. There is no single rule to how it works, although a pattern is there. And on top of it all, theory predicts the weak bosons to be massless. I couldn't break this news to you earlier. Technically, the theory of the weak interaction is DOA.

In 1967 a solution was discovered that involves two independent concepts. The first is the unification of the electromagnetic and weak interactions into a single one called the \jargon{electroweak interaction}. In this electroweak theory we have four bosons ($W^+$, $W^-$, $W^0$, and $B^0$) all of which are initially massless. Not much help so far.

The second concept is called the \jargon{Higgs mechanism} which postulates the existence of yet another entity called the Higgs field. The idea runs like this. At very high temperatures the four electroweak boson and the Higgs field exist in a kind of equilibrium. But when the energy level of the temperature drops below the mass of the weak bosons ($kT = 80\unit{GeV/c$^2$}$ or $T = 10^{15}$ kelvin), this equilibrium go unstable and the quantum symmetries ``break''\footnote[-0.5in]{This \href{http://en.wikipedia.org/wiki/Spontaneous_symmetry_breaking}{spontaneous symmetry breaking} can be understood by example: consider what happens when a liquid freezes. As a liquid the molecules are oriented in all directions with no preference. But as the temperature drops, the molecules line up in a crystal structure and breaks the symmetry. Now, it is possible for a liquid to go into an unstable \href{http://en.wikipedia.org/wiki/Supercooling}{supercooled state}. Some sort of asymmetric trigger is required to break the symmetry. But the point is that the preferred direction is not inherent in the physical laws governing the material. When the system moves to an unstable region (through lower temperature) the smallest trigger will lock the whole system in place.} and the Higgs field ``mixes'' with the electroweak bosons. 

This mixing causes the $W^+$ and $W^-$ bosons to acquire mass and the $B^0$ boson becomes the photon. We also have two other residual particles: the $Z$ boson which is what is left of the original $W^0$ boson and the Higgs boson which is what is left of the original Higgs field. The $Z$ boson has been observed (about 92 GeV/c$^2$) and acts like a heavy photon (it doesn't carry electric charge or weak isospin, so it doesn't change the nature of the particle). The Higgs boson has yet to be observed---this is one of the main objectives of the \href{http://en.wikipedia.org/wiki/Large_Hadron_Collider}{Large Hadron Collider}.\footnote{There may be ways to break the electroweak symmetry without the Higgs boson. See \href{http://en.wikipedia.org/wiki/Higgsless_model}{here} for details.}

This approach may look convoluted and unmotivated. It is inspired by the BCS theory of superconductivity. Electrons pair up in a superconductor and act like bosons which gives the superconductor its non-classical behavior. A superconductor is a system involving massive ``bosons'' about which we know quite a bit. So it makes sense that this theory might act as a template to understand the weak boson.

\tbl[]{weak-boson-mass}{ccc}{
Boson & Measured & Predicted \\
\hline
$W$ & 80.398  $\pm$ 0.025  & 80.390  $\pm$ 0.018  \\
$Z$ & 91.1876 $\pm$ 0.0021 & 91.1874 $\pm$ 0.0021 \\
}{The observed masses of the weak bosons match well with those predicted by the electroweak theory (taken from \href{http://en.wikipedia.org/wiki/Standard_Model\#Tests_and_predictions}{here})}

%\tbl[side]{weak-boson-mass}{cc}{
%\multicolumn{2}{c}{$W$ boson mass (GeV/c$^2$)} \\ 
%Measured & 80.398 $\pm$ 0.025 \\
%Predicted & 80.390 $\pm$ 0.018 \\
%\hline
%\multicolumn{2}{c}{$Z$ boson mass (GeV/c$^2$)} \\ 
%Measured & 91.1876 $\pm$ 0.0021 \\
%Predicted & 91.1874 $\pm$ 0.0021 \\
%}{The observed masses of the weak bosons match well with those predicted by the electroweak theory (taken from \href{http://en.wikipedia.org/wiki/Standard_Model\#Tests_and_predictions}{here})}

Nonetheless, I don't think anyone would call the theory ``pretty''. But it does work, and from a bottom-line perspective that's enough (see Table \ref{tbl:weak-boson-mass}). The physicists working this out in the decades prior to 1980 or so seem to have expected this complexity to disappear in some overarching ``theory of everything''. As such, the combination of the electroweak theory and the strong interaction now goes by the unimpressive name of the \jargon{Standard Model} of particle physics. Figure \ref{fig:standard-model} shows our new periodic chart for elementary particles.

\pics[full]{standard-model}{
\begin{tikzpicture}

\begin{scope}[xshift=-42mm,yshift=-30mm]
\node (legend) [table-box]                               {\ep{Electron}{$e$}{0.511}};
\node (label)  [above]      at (legend.north)      {\textbf{Legend}};
\node (symbol) [left]       at (legend.west)       {\tiny Symbol}; 
\node (name)   [above left] at (symbol.north east) {\tiny Name};
\node (mass)   [below left] at (symbol.south east) {\tiny Mass}; 
\end{scope}

\node (home)     [table-nix]                               {};
\node (electron) [table-box,below=1mm] at (home.south)     {\ep{Electron}{$e$}{0.511}}; %0.511
\node (neutrino) [table-box,below]     at (electron.south) {\ep{Neutrino}{$\nu_e$}{$> 0$}};
\node (d quark)  [table-box,below]     at (neutrino.south) {\ep{Quark}{$d$}{4.8}}; %4.8
\node (u quark)  [table-box,below]     at (d quark.south)  {\ep{Quark}{$u$}{2.4}}; %2.4

\node (muon)     [table-box,left]      at (electron.west)  {\ep{Muon}{$\mu$}{106}}; %105.7
\node (neutrino) [table-box,below]     at (muon.south)     {\ep{Neutrino}{$\nu_\mu$}{$> 0$}};
\node (s quark)  [table-box,below]     at (neutrino.south) {\ep{Quark}{$s$}{100}}; %104
\node (c quark)  [table-box,below]     at (s quark.south)  {\ep{Quark}{$c$}{1300}}; %1270

\node (tauon)    [table-box,left]      at (muon.west)      {\ep{Tauon}{$\tau$}{1800}}; %1777
\node (neutrino) [table-box,below]     at (tauon.south)    {\ep{Neutrino}{$\nu_\tau$}{$> 0$}};
\node (b quark)  [table-box,below]     at (neutrino.south) {\ep{Quark}{$b$}{4200}}; %4200
\node (t quark)  [table-box,below]     at (b quark.south)  {\ep{Quark}{$t$}{170000}}; %171200

\node (spin half) [above] at (muon.north) {
\begin{minipage}{36mm}
\centering
Spin 1/2 particles \\ (Fermions)
\end{minipage}
};

\node (photon)   [table-box,right=1mm] at (home.east)      {\ep{Photon}{$\gamma$}{0}};
\node (e charge) [table-box,below=1mm] at (photon.south)   {\ep{}{$-1$}{}};
\node (n charge) [table-box,below]     at (e charge.south) {\ep{}{$0$}{}};
\node (d charge) [table-box,below]     at (n charge.south) {\ep{}{$-\tfrac{1}{3}$}{}};
\node (u charge) [table-box,below]     at (d charge.south) {\ep{}{$+\tfrac{2}{3}$}{}};

\node (gluon)    [table-box,right]     at (photon.east)    {\ep{Gluon}{$g$}{0}};
\node (e color)  [table-box,below=1mm] at (gluon.south)    {\ep{}{0}{}};
\node (n color)  [table-box,below]     at (e color.south)  {\ep{}{0}{}};
\node (d color)  [table-box,below]     at (n color.south)  {\ep{}{$g$}{}};
\node (u color)  [table-box,below]     at (d color.south)  {\ep{}{$g$}{}};

\node (weak)     [table-box,right]     at (gluon.east)     {\ep{Weak}{$W$}{$\sim 80000$}};
\node (e flavor) [table-box,below=1mm] at (weak.south)     {$-\half$};
\node (n flavor) [table-box,below]     at (e flavor.south) {$+\half$};
\node (d flavor) [table-box,below]     at (n flavor.south) {$-\half$};
\node (u flavor) [table-box,below]     at (d flavor.south) {$+\half$};

%\draw [<->] ($(e flavor.center)+(-0.2,0)$) -- +(0.4,0) |- ($(n flavor.center)+(-0.2,0)$);
%\draw [<->] ($(u flavor.center)+(-0.2,0)$) -- +(0.4,0) |- ($(d flavor.center)+(-0.2,0)$);

\draw [decorate,decoration={brace}] ($(e flavor.north east)+(0.2,0)$) 
-- node [right=1mm] {Leptons} ($(n flavor.south east)+(0.2,0)$);
\draw [decorate,decoration={brace}] ($(d flavor.north east)+(0.2,0)$) 
-- node [right=1mm] {Quarks}  ($(u flavor.south east)+(0.2,0)$);

\node (spin half) [above] at (gluon.north) {
\begin{minipage}{36mm}
\centering 
Spin 1 particles \\ (Bosons)
\end{minipage}
};
%\node (couplings) [below] at (u color.south) {Couplings};

\end{tikzpicture}
}{The elementary particles according to the Standard Model. (Inspired by a similar chart in Feynman's book \textit{\href{http://en.wikipedia.org/wiki/QED:_The_Strange_Theory_of_Light_and_Matter}{QED: The Strange Theory of Light and Matter}}.)}

The Standard Model is an extremely successful theory: one that has yet to make a prediction that is incompatible with experiment. Yet physicists continue to talk about the ``next'' theory. Why? 

The short answer is that the model appears incomplete. Clearly we need to incorporate gravity yet it is not clear how this can be done. The Higgs particle has yet to be found---what if it's not there? Also, there are things that happen in nature that the original model does not anticipate like \href{http://hyperphysics.phy-astr.gsu.edu/hbase/quantum/parity.html}{parity violation}\footnote{This parity violation implies that nature makes a slight distinction between matter and anti-matter. This could explain the apparent imbalance in the universe between the two.} and \href{http://en.wikipedia.org/wiki/Neutrino_oscillations}{neutrino oscillation}. These features can be ``bolted'' on to the model to match experiment by tweaking and fine tuning the formulas, but a complete theory really ought to predict these features naturally. And then there are other things that you would expect the theory to explain that it does not. For example, is there a pattern to the particle masses?\footnote{Note that the periodic table does offer an explanation for each atomic mass.} How did the weak symmetry break and why did it fall out in this particular way? Why are there three generations of particles---are there more?\footnote{Neutrino oscillation provides evidence that there are only three kinds of neutrinos, but it does not explain why.} Finally there are suspicious coincidences: Why three generations of both quarks and leptons? Why is the charge of the electron and proton exactly the same?

It's these last two questions that have motivated physicists to postulate some sort of ``supersymmetry'' between the leptons and fermions which unifies the strong and electroweak interactions. Inspired by the success of the electroweak theory and even the memory of the unification of the electric and magnetic forces these models are called \jargon{grand unified theories} (GUT). None work. The main problem that they all have is that they predict the decay of the proton: just as the weak interaction decays the quarks and leptons down the three generations into less massive particles, so should this ``supersymmetry'' decay the proton down into electrons and neutrinos. No one has ever witnessed the decay of the proton---the current lower bound on the half-life of the proton is \href{http://hyperphysics.phy-astr.gsu.edu/hbase/particles/proton.html\#c2}{$10^{33}$ years} and growing every day.

And then there is gravity\ldots. This is where \jargon{string theory} enters the picture. But before I explain these speculations let's be very clear: we are deep in the wilderness here and the forest is very dark.\footnote{It is a bit of a pet peeve of mine that the hypothetical fringe of physics is often represented as fact. For example, there is no evidence for a ``graviton''---it's just a guess that a quantum theory of gravity might have them. The unification of forces going back to the Big Bang is another: the ``\href{http://hyperphysics.phy-astr.gsu.edu/hbase/astro/planck.html\#c5}{inflation phase}'' of the early universe is a way of solving the \href{http://en.wikipedia.org/wiki/Horizon_problem}{horizon problem}, but this presupposes unification rather than providing evidence for it.} We are still waiting to see if we understand the electroweak unification correctly and we know that unifying the strong interaction has fundamental problems. The ``Hail Mary'' approach of string theory is a long shot indeed.

Nonetheless, the approach has prestigious roots: \href{http://en.wikipedia.org/wiki/Einstein\#Unified_field_theory}{Einstein} spent the last decades of his life working on it. He was inspired by the \href{http://en.wikipedia.org/wiki/Kaluza-Klein_theory}{quirky observation} that if one expands general relativity to five dimensions, Maxwell's equations pop out. There are problems, of course. There are no fermions, there are unobserved extra bosons, and it doesn't say anything about the strong and weak interactions. Einstein appears to have hoped to see an explanation for quantum mechanics come out of the theory, but it never did work.

But the ``extra-dimension'' seed had been planted and fifty years later string theory blossomed. Many theoretical facts about quantum strings vibrating in 10 dimensions were uncovered which yield supersymmetry with a new boson to mediate the force of gravity. The mathematics is obscure but in the end there appears to be five different options for a viable string theory. In the mid-1990's a single 11-dimensional version based on vibrating membranes was developed which incorporates the five as special cases. Currently much speculation (and controversy) is focused on this ``\href{http://en.wikipedia.org/wiki/Theory_of_everything\#String_theory_and_M-theory}{M-theory}'' as the final unification of fundamental physics.

That's it. In Lecture \ref{ch:overview} we began without even knowing how to define physics. Now we are at the very edge of what we know (and a bit beyond). It's been quite a ride and I hope you learned a bit in the process. Study hard and fare well.
========
